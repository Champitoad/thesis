\setchapterpreamble[u]{\margintoc}
\chapter{Symmetric Bubble Calculi}
\labch{bubbles-symm}

In this chapter, we explore to what extent the bubble calculus of
\refch{bubbles} can be made more \emph{symmetric}, by relaxing the restriction
that solutions must contain at most one conclusion. At a surface level, our
approach is similar to that of Gentzen, who went from his single-conclusion
sequent calculus \sys{LJ} to the multi-conclusion calculus \sys{LK}. Like him,
we will uncover beautiful dualities that were hidden by the asymmetry of the
initial calculus. But by sticking unwaveringly to intuitionism, we will be led
to the exotic territory of \emph{bi-intuitionistic} logic, an intermediate logic
that conservatively extends intuitionistic logic, but does not prove the law of
excluded middle. An underlying thread of our investigation will be the quest for
a \emph{fully iconic} proof system, where all logical connectives can be
replaced by appropriate (new) kinds of bubbles. This will lead us to rediscover
many principles already studied in the deep inference literature, with
topological intuitions of the bubble metaphor shedding a new light on them. We
will end up with two symmetric bubble calculi, each with their own tradeoffs on
the properties satisfied by inference rules. In particular, their ability to
\emph{factorize} both forward and backward proof steps might prove useful to
build concise proofs, all through direct manipulation.

The chapter is organized as follows: in \refsec{non-determinism} we motivate our
quest for a system where all introduction rules for logical connectives are
\emph{invertible}, to reduce non-determinism in proof search and enable a fully
\emph{iconic} approach to proof building. To that effect, we relax in
\refsec{branching} the restriction to single-conclusion solutions, which
requires a new distinction between \emph{closed} and \emph{open} solutions. This
gives rise in \refsec{colors} to an extension of the syntax of solutions, where
bubbles can themselves be \emph{polarized}. In \refsec{design-props} we identify
key properties that will guide the design of inference rules, some of which were
already aimed for implicitly through the evolution of our concept of bubble. In
\refsec{symmetric-calculus} we introduce a core \emph{symmetric bubble calculus}
for classical logic called ``system \sys{B}'', in reference to the symmetric
system \sys{L} of Herbelin \sidecite[10em]{herbelin_duality_nodate}. Then in
\refsec{bubbles-soundness} we prove the soundness of system \sys{B}, and show
that by removing selectively among inference rules that define the
\emph{porosity} of polarized bubbles, one gets intuitionistic,
dual-intuitionistic and bi-intuitionistic logic as fragments. In
\refsec{bubbles-completeness} we support this claim by showing that the
bi-intuitionistic fragment is not only sound, but also \emph{cut-free complete}
with respect to the cut-free nested sequent calculus \sys{DBiInt} of Postniece
\cite{postniece_deep_2009}. Finally in \refsec{invertible-calculus}, we
introduce a fully invertible variant of system $\sysB$ that we conjecture to be
complete, and present a canonical way to search for proofs in this system.
Unfortunately, invertibility does not entail the full iconicity of the system,
and we reflect on the fundamental reasons that might prevent any variant of
system $\sysB$ from being fully iconic.

% In \refsec{invertible-calculus} we present a fully invertible variant of system
% \sys{B}, whose completeness follows naturally from the proof of
% \refsec{bubbles-completeness}. Despite the invertibility of introduction rules,
% it turns out that this variant does not satisfy the \emph{decomposability}
% property. We fix this defect in \refsec{decomposable-calculus} with another
% variant of the system conjectured complete, finally achieving full iconicity.

\begin{remark}
  Although we include rules for quantifiers, in this thesis we only treat the
soundness and completeness of bubble calculi for \emph{propositional} logic.
Indeed quantifiers would make the algebraic semantics more involved when proving
soundness, and during our literature review we found very few proof systems for
bi-intuitionistic logic supporting them, at least none suitable for our
syntactic completeness proof. More generally, bi-intuitionistic logic has
received less attention in the first-order setting, probably because it is
\emph{not} a conservative extension of intuitionistic predicate logic, but only
of \emph{constant-domain} predicate logic (see \cite{crolard_subtractive_2001}
and \cite{aschieri_natural_2018}).
\end{remark}

\section{Non-determinism and iconicity}\labsec{non-determinism}

In all known sequent calculus formulations of intuitionistic logic, there are at
least two rules which are invariably \emph{non-invertible}:
\begin{enumerate}
  \item a left introduction rule for $\limp$ (there might be many ones, as in
  the calculus \sys{LJT} of \sidecite{dyckhoff_contraction-free_1992});
  \item the right introduction for either:
    \begin{itemize}
      \item $\lor$ when sequents have at most or exactly one conclusion;
      \item $\limp$ when sequents have multiple conclusions, e.g. in the
        multi-succedant variant of \sys{LJT} in
        \cite{dyckhoff_contraction-free_1992}.
    \end{itemize}
\end{enumerate}
In \sys{BJ}, this means that click actions on blue $\hypo{\limp}$ and red
$\conc{\lor}$ need to be performed in a specific order to be able to complete
proofs.

In his thesis \cite{guenot_nested_2013}, Guenot introduced a specific kind of
nested sequent system, where like in \sys{BJ} inference rules can be expressed
as rewriting rules. An interesting feature of these systems is that they satisfy
a \emph{decomposability} property: all introduction rules for connectives are
\emph{invertible}, and formulas can be completely decomposed with them until
atoms are reached, before applying other rules. Thus introduction rules are
\emph{admissible} in these systems, because every formula can be translated into
an equivalent pure nested sequent with the same number of atoms\sidenote{As far
as we know, the admissibility of introduction rules is not proved, let alone
mentioned in \cite{guenot_nested_2013}. This is our own observation which lacks
a proper formal proof, and is thus subject to caution.}. Non-determinism then
arises in the choice of atoms that are to be connected in axioms, as well as the
choice of sub-sequents to be duplicated for reuse.

In our graphical setting, this would translate to an interface where all click
actions are redundant. Although we already considered this possibility in
\refsec{dnd-completeness}, here it goes further by making even \emph{logical
connectives} superfluous, since all other rules work purely on the structure of
sequents. This means that all logical connectives could be replaced by
metaphorical constructs like bubbles, which suggest \emph{physically} the
possible transformations on the proof state. We call this property of a proof
system \emph{iconicity}, following a terminology introduced by C. S. Peirce in
his \emph{semiotics} \sidecite{noth_peircean_1999}, which he also applied to his
diagrammatic proof system of \emph{existential graphs}
\sidecite{10.7551/mitpress/3633.001.0001}. Unfortunately, the systems in
\cite{guenot_nested_2013} only handle classical logic, and the implicative
fragment of intuitionistic logic. Thus began our quest for a bubble calculus in
the style of Guenot capturing full intuitionistic logic\sidenote{Other nested
sequent systems for full intuitionistic logic exist (\cite{postniece_deep_2009},
\cite{fitting-nested-2014}), but they are based on tree-shaped proofs, and thus
ignore the whole \emph{raison d'être} of our concept of bubble.}.


\section{Conclusions and branching}\labsec{branching}

The first direction we followed was to relax the constraint that solutions must
be single-conclusion. Indeed as already noted in \refsec{sfl-backtracking}, a
notable property of sequent calculi with multiple conclusions is that their
right introduction rule for $\lor$ is invertible.

The main difficulty lies in the way one should interpret a multi-conclusion
solution $S$ as a formula $\sint{S}$. If we just take the asymmetric
interpretation (\refdef{ainterp}) and group conclusions disjunctively instead of
conjunctively, we get
$$
\sint{\Gamma \piq{\cS} \Delta} =
\bigwedge \Gamma \limp \bigvee \Delta \land \bigwedge_{S \in \cS}{\sint{S}}
$$
But this interpretation breaks on the 0-ary case when $\Delta$ is empty: instead
of seeing $\Gamma \piq{\cS}$ as a node of the proof tree with hypotheses
$\Gamma$ and subgoals $\cS$, it trivializes it to $\sint{\Gamma
\piq{\cS}} = \bigwedge \Gamma \limp \bot$, i.e. a goal where one has to
find a contradiction in $\Gamma$; which is obviously not what we have in mind.

\begin{marginfigure}
  $$
  \R[\land R*]
    {\Gamma \seq A, \Delta}
    {\Gamma \seq B, \Delta}
    {\Gamma \seq A \land B, \Delta}
  $$
  \caption{Multi-conclusion right introduction rule for conjunction}
  \labfig{multi-and-intro}
\end{marginfigure}

A key observation was that in the rules of multi-conclusion sequent calculi, one
usually distributes the context $\Delta$ of conclusions in all premisses: this
restores a perfect symmetry with respect to the context of hypotheses $\Gamma$,
as illustrated by the {\rnm{\land R*}} rule (\reffig{multi-and-intro}). Then our
idea was that instead of implementing distribution/sharing of conclusions inside
inference rules, we could do it implicitly in the interpretation of solutions.
This is already what happens in the asymmetric interpretation for hypotheses
(\refdef{ainterp}); indeed the context $\Gamma$ is shared among subgoals,
because:
\begin{enumerate}
  \item it appears on the left of an implication $\limp$
  \item bubbles are joined conjunctively, and
  \item implication distributes over conjunction thanks to the equivalence $A
  \limp B \land C \semequiv (A \limp B) \land (A \limp C)$.
\end{enumerate}
But what does it mean precisely to share conclusions among subgoals? If we
consider the two following solutions:
\begin{equation}\label{eq:concdistr}
\underbrace{\bubble{\hypo{A}~~~\conc{B}}~~~\bubble{\hypo{C}~~~\conc{D}}~~~\conc{E}}_{S} \qquad\qquad
\underbrace{\bubble{\hypo{A}~~~\conc{B}~~~\conc{E}}~~~\bubble{\hypo{C}~~~\conc{D}~~~\conc{E}}}_{T}
\end{equation}
we would like to have $\sint{S} \semequiv \sint{T} \semequiv (A \limp B
\lor E) \land (C \limp D \lor E)$. Since disjunction distributes over
conjunction, a first naive try would give the following interpretation, where we
just replaced $\land$ by $\lor$ compared to the previous attempt:
$$
\sint{\Gamma \piq{\cS} \Delta} =
\bigwedge{\Gamma} \limp \bigwedge_{S \in \cS}{\sint{S}} \lor \bigvee \Delta
$$
But this immediately fails whenever $\cS = \emptyset$, because it
trivializes to $\bigwedge \Gamma \limp \top \lor \bigvee \Delta \semequiv \top$
instead of $\bigwedge \Gamma \limp \bigvee \Delta$. The only way we found around
this defect was to internalize \emph{syntactically} a distinction between two
kinds of solutions, by assigning them one of two \emph{statuses}\sidenote{In the
terminology of Martin-Löf, we could say that we now have two distinct forms of
\emph{judgment}.}:
\begin{itemize}
  \item \emph{closed} solutions $\Gamma \piq{\cS} \Delta$ correspond
  to branching nodes in the proof tree, or to closed leaves when $\cS =
  \emptyset$ (i.e. solved subgoals). Thus it becomes sensical to have
  $\sint{\Gamma \piq{} \Delta} = \top$. In the asymmetric interpretation,
  closed solutions were encoded by solutions with no conclusions;
  \item \emph{open} solutions $\Gamma \seq \Delta$ correspond to open leaves
  in the proof tree (i.e. unsolved subgoals). In the asymmetric interpretation,
  they were encoded by solutions with one conclusion.
\end{itemize}
Then we keep the last proposed interpretation for closed solutions, and
interpret open solutions like usual sequents:
$$\sint{\Gamma \seq \Delta} = \bigwedge{\Gamma} \limp \bigvee{\Delta}$$ To be
able to abstract from the particular kind of solution at hand, we reframe the
syntax of solutions with so-called \emph{branching} operators $\J$:
\begin{align*}
  S, T, U &\Coloneq \Gamma \J \Delta \\
  \J, \JB &\Coloneq {\seq} \mid \piq{\cS}
\end{align*}
Graphically, closed solutions with no bubbles can be distinguished from open
solutions by painting their \emph{background} on the proof canvas in green, the
intent being to suggest that they have already been solved. A pathological
example is the distinction between the closed empty bubble
$\bbubble{\phantom{a}}$ and the open empty bubble $\bubble{\phantom{a}}$, who
are interpreted respectively by $\sint{\piq{\piq{}}} = \top$ and
$\sint{\piq{\seq}} = \bot$.

Now coming back to our target example,
% we must explicitly assign a status to each subsolution:
% $$
% \underbrace{\bsheet{\bubble{\hypo{A}~~~\conc{B}}~~~\bubble{\hypo{C}~~~\conc{D}}~~~\conc{E}}}_{S}
% \qquad\qquad
% \underbrace{\bsheet{\bubble{\hypo{A}~~~\conc{B}~~~\conc{E}}~~~\bubble{\hypo{C}~~~\conc{D}~~~\conc{E}}}}_{T}
% $$
% However
the interpretation still fails, because we associate two non-equivalent
formulas to $S$ and $T$. To show this, let us try to derive the equivalence
through some algebraic developments:
\begin{align}
  \sint{S} &= \top \limp ((A \limp B) \land (C \limp D)) \lor E \nonumber\\
              &\semequiv ((A \limp B) \land (C \limp D)) \lor E \nonumber\\
              &\semequiv ((A \limp B) \lor E) \land ((C \limp D) \lor E) \nonumber\\
              &\semequiv (A \limp B \lor E) \land (C \limp D \lor E) \labeq{grishin}\\
              &\semequiv ((A \limp B) \land (C \limp D)) \lor E \nonumber\\
  \sint{T} &= \top \limp ((A \limp B \lor E) \land (C \limp D \lor E)) \lor \bot \nonumber
\end{align}
Wait, we did manage to prove it! The trick resides in \refeq{grishin}, which
uses twice the equivalence $(A \limp B) \lor C \semequiv A \limp (B \lor C)$. It
turns out that this equivalence is true in classical logic, but \emph{not} in
intuitionistic logic. More precisely, it is the implication $G \defeq (A \limp
(B \lor C)) \limp ((A \limp B) \lor C)$ which is not provable
intuitionistically, since it can easily be shown equivalent to the law of
excluded middle\sidenote{This was already noticed in
\cite{clouston-annotation-free-2013}, with the linear version $(A \multimap (B
\parr C)) \multimap ((A \multimap B) \parr C)$ of $G$ called Grishin (a) and its
converse Grishin (b). More precisely, it is affirmed that while Grishin (b) is
valid in \sys{FILL}, the restriction of the classical multiplicative linear
logic \sys{MLL} to single-conclusion sequents, adding Grishin (a) makes
\sys{FILL} collapse to \sys{MLL}.}. Thus according to this interpretation, $S$
entails $T$ but $T$ does not entail $S$, which means that it is not able to
account for the \emph{factorization} of common conclusions in distinct subgoals.

To remedy this situation, we opted for a different strategy: instead of finding
a logical formula capturing the distributive semantics of conclusions over
subgoals, we hardcode the latter by defining the interpretation function on
closed solutions through \emph{non-structural} recursion. This gives the
following final definitions:

\begin{definition}[Mix operator]\labdef{mixop}
  The commutative \emph{mix operator} $\mix$ on solutions is defined by:
  \begin{align*}
    (\Gamma \J \Delta) \mix (\Gamma' \seq \Delta') &=
      \Gamma, \Gamma' \J \Delta, \Delta' \\
    (\Gamma \piq{\cS} \Delta) \mix (\Gamma' \piq{\mathcal{S'}} \Delta') &=
      \Gamma, \Gamma' \piq{\cS \sep \mathcal{S'}} \Delta, \Delta' \\
  \end{align*}
\end{definition}

\begin{definition}[Symmetric interpretation]\labdef{sinterp}
  The \emph{symmetric interpretation} of a solution is defined recursively by:
  \begin{align*}
    \sint{\Gamma \piq{\cS} \Delta} &=
      \bigwedge_{S \in \cS} \sint{S \mix (\Gamma \seq \Delta)} \\
    \sint{\Gamma \seq \Delta} &=
      \bigwedge \Gamma \limp \bigvee \Delta
  \end{align*}
\end{definition}

This is the right approach for interpreting solutions with multiple conclusions,
as will be demonstrated formally in \refsec{bubbles-soundness}.

\section{Coloring bubbles}\labsec{colors}

\subsection{Red bubbles}

\begin{marginfigure}
  $$
  \R[\mathsf{{\limp}{+}c}]
    {\Gamma, A \J B, \Delta}
    {\Gamma \J A \limp B, \Delta}
  $$
  \caption{Classical multi-conclusion version of ${\limp}{+}$}
  \label{wrong-imp-pos}
\end{marginfigure}

With our new symmetric interpretation, we can start generalizing the rules of
\sys{BJ} to multiple conclusions. While for most rules one just has to replace
single-conclusion (resp. no-conclusion) solutions with open (resp. closed) ones
(more details will be given in the next section), the ${\limp}{+}$ rule stands
out as particularly problematic. Indeed if we content ourselves with the natural
generalization {\rnmsf{{\limp}{+}c}} of \reffig{wrong-imp-pos}, then we can
easily build a proof of the excluded middle like in \reffig{lk-tnd}, and thus
collapse to classical logic. This fact is well-known in the literature on
multi-conclusion intuitionistic sequent calculi, and the solution is usually to
discard the context of conclusions $\Delta$, as in the {\rnm{{\limp}R*i}} rule
of \reffig{multi-imp-intro}. But this would make our rule both non-local and
non-invertible.

\begin{marginfigure}
  $$
  \begin{array}{rclr}
    \hypo{A}~~~\cbubble{\color{black}S} &\step &\cbubble{\hypo{A}~~~\color{black}S} &\mathsf{f}{-}{+}{\da} \vspace{1em}\\
    % \conc{A}~~~\cbubble{\color{black}S} &\step &\cbubble{\conc{A}~~~\color{black}S} &\mathsf{f}{+}{+}{\da} \\
  \end{array}
  $$
  \caption{$\mathbb{F}$-rule for red bubbles}
  \labfig{flow-red-bubbles}
\end{marginfigure}

A better solution comes from the nested sequent systems of Fitting
\sidecite{fitting-nested-2014} and Clouston et al.
\sidecite{clouston-annotation-free-2013}, where sequents can appear as
\emph{conclusions} of other sequents. In our chemical metaphor, this corresponds
to having \emph{red bubbles}. Then the key idea is to allow hypotheses to flow
into sequents that appear as conclusions\sidenote{This corresponds to the
{\rnm{Lift}} rule of \cite{fitting-nested-2014} and {\rnm{pl_1}} rule of
\cite{clouston-annotation-free-2013}.}, but \emph{not other conclusions}.
Graphically, this means that blue items can enter red bubbles (rule
{\rnmsf{f{-}{+}}} of \reffig{flow-red-bubbles}), but red items cannot: this is
reminiscent of the electromagnetic phenomemon of \emph{repulsion} between
objects charged with the same polarity.

\begin{figure*}
  \input{figures/bubbles-grishin.tex}
  \caption{Proof attempts for Grishin (a) and Grishin (b)}
  \labfig{bubbles-grishin}
\end{figure*}

To illustrate why this works, let us consider how one can manipulate with red
bubbles the classical equivalence $ (A \limp B) \lor C \semequiv A \limp (B \lor
C)$, that we already stumbled upon in the previous section. The begginings of
the proofs for both directions of the equivalence are depicted parallely in
\reffig{bubbles-grishin}. Indeed both proofs have a very similar structure:
\begin{enumerate}
  \item the first step is to decompose the conclusion with the new version of
  the rules {\rnm{{\lor}{+}}} and {\rnm{{\limp}{+}}}. While the former simply
  splits disjunctions in two, the latter encapsulates the antecedant and
  consequent of implications in a red bubble: the goal is to forbid the use of
  the antecedant to prove conclusions other than the consequent, as will become
  apparent later;
  \item then in both cases we want to apply the hypothesis $\hypo{A}$ in a
  forward step, either with $\hypo{A \limp B}$ or $\hypo{A \limp (B \lor C)}$.
  To do so, we need to bring the two hypotheses together in the same solution.
  And since items are trapped within bubbles, the only way to go is to move the
  blue $\hypo{A}$ inside the red bubble with the {\rnmsf{f{-}{+}}} rule;
  \item this time we decompose the hypothesis with the new version of the rules
  {\rnm{{\lor}{-}}} and {\rnm{{\limp}{-}}}. They are basically a local variant
  of those of \sys{BJ}: we encapsulate both subformulas in separate bubbles, but
  without touching to the conclusions of the ambient solution;
  \item now that all formulas have been decomposed, it only remains to bring
  together dual atoms for annihilation, and pop all empty bubbles. In Grishin
  (b) this is easy, because all necessary movements (indicated by green arrows)
  are valid: they only cross gray bubbles inward. In Grishin (a) this works for
  $\hypo{A}$ and $\conc{B}$, but not for $\conc{C}$ (orange dotted arrow): it
  would cross the red bubble, which is expressedly forbidden.
\end{enumerate}
Thus in order to prove Grishin (a) and recover classical logic, it suffices
either to add the {\rnmsf{f{+}{+}}} rule allowing red items to enter red bubbles
(\reffig{flow-red-bubbles}), or to use the {\rnmsf{{\limp}{+}c}} rule which
avoids red bubbles altogether. In the following we will settle for the first
option: we find it more elegant, because it explains the distinction between
intuitionistic and classical logic as a kind of \emph{physical law} independent
of logical connectives.

\subsection{Blue bubbles}

Now it is only natural to wonder: since bubbles can be colored in red, or
charged positively, would it also make sense to have \emph{blue} bubbles charged
\emph{negatively}? The answer is \emph{yes}, but we need to broaden our logical
view and consider more exotic beasts: the adequately named
\emph{dual-intuitionistic} logic, and \emph{bi-intuitionistic logic}.

\begin{marginfigure}
  $$
  \begin{array}{rclr}
    \conc{A}~~~\hbubble{\color{black}S} &\step &\hbubble{\conc{A}~~~\color{black}S} &\mathsf{f}{+}{-}{\da} \vspace{1em}\\
    % \hypo{A}~~~\hbubble{\color{black}S} &\step &\hbubble{\hypo{A}~~~\color{black}S} &\mathsf{f}{-}{-}{\da} \\
  \end{array}
  $$
  \caption{$\mathbb{F}$-rule for blue bubbles}
  \labfig{flow-blue-bubbles}
\end{marginfigure}

But for now let us stay at a purely syntactic level. The idea is very simple,
and can be summarized in two words: \emph{color swap}. Thus the law that ``blue
items can enter red bubbles, but red items cannot'' becomes a new law that ``red
items can enter blue bubbles, but blue items cannot'', which is enforced by
allowing only the use of the {\rnmsf{f{+}{-}}} rule in
\reffig{flow-blue-bubbles}. Well this is neat, but will not be of much use if
there is no way to spawn blue bubbles. Be it as it may: we can just craft a new
logical connective! Since red bubbles are produced by the implication connective
$A \limp B$, we define a dual \emph{exclusion} connective $A \lsub B$ (read
``$A$ excludes $B$''\sidenote{We ask for the reader's leniency regarding our
choice of symbol and terminology: in set theory this would be total nonsense,
since $A \subset B$ would read ``$A$ is included in $B$''. Even worse, in the
boolean algebra induced by set operations, $A \subset B$ is interpreted as $A$
\emph{implies} $B$\ldots~But all the arrow symbols were already taken, and we
want to emphasize the duality between exclusion and implication by mirroring the
symbol, as it is traditionally done with conjunction $\land$ and disjunction
$\lor$.}), whose heating rules are those of $\limp$ with swapped colors
(\reffig{heating-exclusion}).

\begin{marginfigure}
  $$
  \begin{array}{rclr}
    \hypo{A \lsub B} &\step &\hbubble{\hypo{A}~~~\conc{B}} &{\lsub}{-}\vspace{1em}\\
    \conc{A \lsub B} &\step &{\bubble{\conc{A}}}~~~\bubble{\hypo{B}} &{\lsub}{+}
  \end{array}
  $$
  \caption{$\mathbb{H}$-rules for exclusion $\lsub$}
  \labfig{heating-exclusion}
\end{marginfigure}

Not very surprisingly, the exclusion connective has already been studied in the
literature on intuitionistic logic, starting with the seminal paper of Rauszer
on \emph{Heyting-Brouwer logic}, i.e. intuitionistic logic to which we add
exclusion \sidecite{Rauszer1974-RAUSAA}. In this paper, exclusion was called
\emph{pseudo-difference}, to evoke its close connection with set-theoretical
difference. Indeed given two sets $A$ and $B$, one can define the set $A
\setminus B$ by comprehension as $\{x \mid x \in A \land x \not\in B\}$, which
is the set $A$ from which all elements of $B$ have been \emph{excluded}. With an
interpretation in boolean algebras, this corresponds to the classical connective
defined by the truth table of $A \land \neg B$, which is dual to the truth table
of $\neg A \lor B$ defining material implication.

While the first paper of Rauszer \cite{Rauszer1974-RAUSAA} belongs to the Polish
tradition of algebraic logic, she also explored in later works the
proof-theoretic \sidecite{rauszer_formalization_1974} and model-theoretic
\sidecite{rauszer_applications_1977} sides of the question. Many authors have
then deepened the proof theory of exclusion, whether in isolation from
implication in \emph{dual-intuitionistic} logic
\sidecite{urbas_dual-intuitionistic_1996}\sidecite{gore_dual_2000}, or with both
connectives in \emph{bi-intuitionistic} logic as in Rauszer's original
work\sidenote{Crolard \cite{crolard_subtractive_2001} and Aschieri
\cite{aschieri_natural_2018} have also explored the computational counterpart of
exclusion through the Curry-Howard correspondence, which is claimed by the first
author to be a typing operator for \emph{first-class coroutines}.}
\sidecite{postniece_proof_2010}\sidecite{pinto_relating_2011}. In particular, we
are going to rely in \refsec{bubbles-completeness} on the deep inference
calculus developed by Postniece to get completeness and cut admissibility of our
symmetric bubble calculus introduced in the next section.

\subsection{Polarized interpretation}

Let us now extend the formal definition of bubbles so that they can be colored:

\begin{definition}[Bubble]\labdef{pol-bubble}
  A \emph{bubble} is a solution enclosed in a membrane, which can be either
  unpolarized (neutral), charged positively, or charged negatively.
\end{definition}

Neutral bubbles are the usual ones depicted in gray, while positive and negative
bubbles correspond respectively to red and blue bubbles. We also update the
definition of solutions, which can now be open or closed:

\begin{definition}[Solution]\labdef{pol-solution}
  
  A \emph{solution} is a multiset of ions and bubbles. Its \emph{status} is
  either \emph{closed} or \emph{open}, and open solutions cannot contain neutral
  bubbles. Solutions $S$ can be represented textually with the following syntax:
  \begin{align*}
    S, T, U &\Coloneq \Gamma \J \Delta &
    \cS &\Coloneq S_1 \sep \ldots \sep S_n \\
    I, J, K &\Coloneq A \mid S &
    \Gamma, \Delta &\Coloneq I_1, \ldots, I_n \\
    \J, \JB &\Coloneq {\seq} \mid {\piq{\cS}} &&
  \end{align*}
\end{definition}

Note that in the textual syntax, bubbles are identified with \emph{subsolutions}
(\refdef{subsolution}), and their polarity is determined by their position
relative to branching operators; that is, for any solutions $S, T, U$ such that
$T \subsol U$, $S$ is either:
\begin{itemize}
  \item \emph{neutral} if $T = \Gamma \piq{\cS} \Delta$ and $S \in
  \cS$;
  \item \emph{positive} if $T = \Gamma \J \Delta$ and $S \in \Delta$;
  \item \emph{negative} if $T = \Gamma \J \Delta$ and $S \in \Gamma$.
\end{itemize}

Then we need to split our symmetric interpretation accordingly, so that positive
bubbles are mapped to implications, and negative bubbles to
exclusions\sidenote{Here we took inspiration from the work of Clouston et al. on
nested sequents for \sys{FILL} \cite{clouston-annotation-free-2013}.}:

\begin{definition}[Polarized symmetric interpretation]\labdef{pol-sinterp}
  The \emph{positive} and \emph{negative symmetric interpretations} of solutions
  $\psint{-}$ and $\nsint{-}$ are defined by mutual recursion as
  follows:
  \begin{align*}
    \psint{A} &= A &
    \nsint{A} &= A \\
    \psint{\Gamma \piq{\cS} \Delta} &=
      \bigwedge_{S \in \cS} \psint{S \mix \Gamma \seq \Delta} &
    \nsint{\Gamma \piq{\cS} \Delta} &=
      \bigvee_{S \in \cS} \nsint{S \mix \Gamma \seq \Delta} \\
    \psint{\Gamma \seq \Delta} &=
      \nsint{\Gamma} \limp \psint{\Delta} &
    \nsint{\Gamma \seq \Delta} &=
      \nsint{\Gamma} \lsub \psint{\Delta} \\
    \psint{\Gamma} &= \bigvee_{I \in \Gamma}{\psint{I}} &
    \nsint{\Gamma} &= \bigwedge_{I \in \Gamma}{\nsint{I}}
  \end{align*}
\end{definition}

One can easily check that the interpretation of a solution that has no negative
(resp. positive) subsolution will not contain any occurrence of the exclusion
(resp. implication) connective. This will be crucial later to represent proofs
of both intuitionistic, dual-intuitionistic and bi-intuitionistic logic in the
same system.

\section{Designing for properties}\labsec{design-props}

With our new syntax and interpretation of solutions at hand, we can design a new
proof calculus including the rules previously discussed for manipulating
polarized bubbles. The rich structure of solutions offers many possibilities in
the precise formulation of rules, depending on the properties we expect from the
calculus. We identified \emph{six} of these properties, whose consequences range
from aesthetic and theoretical considerations on paper, to concrete usability
matters in a graphical proof-building interface. Let us summarize them in order
of priorization relatively to the latter:
\begin{description}
  \item[Invertibility]
    A rule is invertible when it could in principle be applied in the converse
    direction, while staying logically sound\sidenote{The \textit{``in
    principle''} part is important: more often than not, adding the converse of
    a rule only brings unnecessary complexity in proof search, especially in a
    user interface that aims for simplicity.}. In other words, it corresponds to
    a logical \emph{equivalence}: when all rules in a (bubble) calculus are
    invertible, we get that $S \step T$ implies $\sint{S} \semequiv
    \sint{T}$. This entails in particular that a user can apply the rule
    without fear of turning a provable goal into an unprovable
    one\sidenote{Assuming that the calculus is \emph{complete}
    (\refsec{bubbles-completeness}).}, eliminating an important source of
    non-determinism in proof search: the need for
    \emph{backtracking}\sidenote{See also \refsec{sfl-backtracking} for a
    discussion on this matter.}.
  \item[Decomposability]
    We already mentioned this property in \refsec{non-determinism} as one of the
    main motivations for this chapter: the ability to decompose all logical
    connectives ``for free'', and thus reason solely on solutions that comprise
    only bubbles and atomic formulas. As far as we know, it has never been
    identified explicitly in the literature before, although it can loosely be
    seen as an extension of the decomposition procedures of existing deep
    inference systems\sidenote{One could argue that more ``semantic'' approaches
    in proof theory have achieved connective-free explanations of proofs, like
    strategies in game semantics or the combinatorial proofs of D. Hughes
    \cite{heijltjes_intuitionistic_2019}. But this is more of a side effect than
    a goal of these approaches, which intentionally abstract from the syntactic
    process of building proofs. A notable exception is the Girardian line of
    works starting from Ludics \cite{girard_locus_2001} and culminating in
    Transcendental Syntax \cite{eng_exegesis_2023}, where both frameworks are
    founded upon the syntactic mechanisms of proof search (focusing in sequent
    calculus, and unification in the resolution algorithm of Robinson,
    respectively). Here the aim to rid proofs of connectives is greatly
    emphasized by Girard, but the focus is again on \emph{proofs} and not
    \emph{proof states}. Also Girard embraces the full space of incomplete but
    also \emph{incorrect} proofs, while we still want a framework where proofs
    are correct by construction.}. One reason is that logical connectives are
    widely considered as \emph{primitive} in the tradition of mathematical
    logic: they \emph{are} the objects of the reasoning activity, rather than a
    tool for representing and structuring arguments. Thus the idea of an
    alternative does not even occur. But even if it does, it is not clear that
    it would bring any interesting viewpoint on the problems usually studied in
    proof theory. In our case, it was brought by a very concrete application:
    making formal proofs accessible to a broader audience, by replacing symbolic
    and linguistic means of representation by iconic and directly manipulable
    ones.
  \item[Factorizability]
    We say that a proof calculus is \emph{factorizable} when it makes it easier
    to avoid duplicating arguments in subproofs. In \refsec{bubbles-pba}, we
    already remarked that the ability to share hypotheses between subgoals in
    \sys{BJ} enables the factorization of \emph{forward} reasoning steps at any
    stage of the proof construction. With our new symmetric interpretation of
    multi-conclusion solutions, we will now be able to factorize \emph{backward}
    reasoning steps as well, which was in fact the main motivation behind
    Example \ref{eq:concdistr} in \refsec{branching}.
  \item[Locality]
    There does not seem to be a general consensus on what it means precisely for
    an inference rule to be \emph{local}. This terminology has been employed by
    various authors in proof theory, in ways that are often hard to compare. For
    instance in \sidecite{negri_structural_2001}, sequent rules are said to be
    local because the contexts of hypotheses involved in a rule are located in
    the sequents of that rule, by opposition to natural deduction rules in their
    labelled presentation where hypotheses are located in arbitrary distant
    leaves of the derivation. In the setting of deep inference, local rules are
    those that can be applied without ``inspection of expressions of arbitrary
    size''\sidenote{Definition 2.1.1 in \cite{ESSLLI}. The same definition is
    used in \cite{tiu_local_2006}.}. Finally in his Transcendental Syntax,
    Girard evokes a related but more elusive notion, concerned with the
    \emph{genericity} of logical objects involved in a rule\sidenote{See the
    section \emph{Globality and locality in logical systems} in Chapter 6 of
    Boris Eng's thesis \cite{eng_exegesis_2023}.}.
    
    Our conception of locality is related to all the previous ones, although it
    is guided by the idea of direct manipulation of logical entities by humans,
    rather than purely proof-theoretical considerations. For instance, \sys{BJ}
    has some locality in the deep inference sense because all rules are
    applicable in arbitrary contexts; but we relax the \emph{atomicity}
    constraint that reduces $\mathbb{I}$-rules and $\mathbb{R}$-rules to their
    atomic version, because it would be unnecessarily restrictive for the
    purpose of building proofs manually. Still, we want to avoid as much as
    possible referring to generic objects that are not directly related to the
    manipulated data, in the spirit of Girard's locality. A typical example is
    the elimination rule for disjunction in natural deduction, corresponding to
    the {\rnmsf{{\lor}{-}}} rule of \sys{BJ} that involves an arbitrary
    conclusion $\Delta$. The benefits of locality from a UX point of view have
    already been discussed at the end of \refsec{bubbles-pba}.
  \item[Linearity] 
    We consider an inference rule to be \emph{linear} when it preserves the
    number of atomic formulas in solutions. This is a strong requirement, which
    for instance excludes the identity rules of \sys{BJ} since they can insert
    or remove (even numbers of) atoms. Thus we cannot achieve full linearity in
    that sense, but it is still interesting to maximize it. The first reason is
    \emph{methodological}: by the words of its creator A. Guglielmi,
    \textit{``[...] deep inference is obtained by applying some of the main
    concepts behind linear logic to the formalisms, i.e., to the rules by which
    proof systems are designed.''} \sidecite{DI}. The second reason is
    \emph{computational}: it can enable a measure on solutions that is strictly
    decreasing with the application of rules, avoiding infinite loops during
    proof search as in the calculus \sys{LJT} of R. Dyckhoff
    \cite{dyckhoff_contraction-free_1992}. The third reason is ergonomical: as
    already remarked by the authors of the Proof-by-Pointing
    paradigm\sidenote{Section 4.1 of \cite{PbP}.}, rules that systematically
    duplicate formulas can quickly overload the goal with useless copies, making
    it harder to read and navigate.
  \item[Symmetry] 
    In classical logic, both sequent calculi like \sys{LK} and deep inference
    systems like CoS are known for their very rich \emph{symmetries}. In fact,
    one of our ambitions with bubbles was to bring back the symmetry of
    classical logic in a constructive setting, without resorting to linear
    logic. This chapter stems in great part from our lack of satisfaction with
    the asymmetry at work in the \sys{BJ} calculus, which looked quite
    unnatural. Of course we will not be able to completely eliminate it, but it
    will be distilled into the flow rules governing the \emph{porosity} of
    bubbles that were hinted at in \refsec{colors}, rather than through the
    arbitrary restriction of sequents to one conclusion\sidenote{Whether it is
    enforced in the syntax of sequents themselves, or through restriction on
    rules that manipulate conclusions like contraction or the introduction rule
    for $\limp$.}. Our treatment of dual and bi-intuitionistic logic through
    blue bubbles is also motivated by this quest for symmetry. It should be
    noted that although we use naming conventions for rules that resemble those
    of CoS (e.g. with the identity rules), we do not aim for a perfect symmetry
    where one can get a complete calculus by simply taking the dual of each
    rule.
    % \sidenote{In fact it is not even clear what would be the dual of a
    % solution, but the {\rnmsf{i{\da}}} and {\rnmsf{i{\ua}}} rules
    % suggest that open and closed solutions may be dual to eachother.}
    Thus we will content ourselves with the hypothesis/conclusion symmetry
    coming from sequent calculus. Interestingly, the calculus \sys{ISgq} of Tiu
    for intuitionistic predicate logic does the opposite, by having a perfect
    dual system \sys{cISgq} but no symmetries among its switch rules (the
    equivalent of our flow rules) \cite{tiu_local_2006}.
\end{description}

In the next section we present a core calculus called ``system \sys{B}'' that
maximizes \emph{symmetry}, \emph{linearity} and \emph{locality}. In our opinion
this makes for a good proof-theoretical foundation, around which variant calculi
with different tradeoffs can be designed.

% In \refsec{invertible-calculus} we introduce such a variant that focuses on
% \emph{invertibility} at the cost of \emph{linearity}, and in
% \refsec{decomposable-calculus} on a refinement of the latter that achieves
% \emph{decomposability} and \emph{factorizability}, losing some of its
% \emph{locality} and \emph{symmetry} along the way.

\section{Symmetric calculus}\labsec{symmetric-calculus}

\input{sections/bubbles-symmetric-calculus}

\section{Soundness}\labsec{bubbles-soundness}

\input{sections/bubbles-soundness.tex}

\section{Completeness}\labsec{bubbles-completeness}

\input{sections/bubbles-completeness.tex}

\section{Invertible calculus}\labsec{invertible-calculus}

\input{sections/bubbles-invertible.tex}


% \section{Decomposable calculus}\labsec{decomposable-calculus}

% \begin{figure*}
%   \input{figures/sequent-B-dec.tex}
%   \caption{Rules for the decomposable bubble calculus \sys{B_{dec}}}
%   \labfig{sequent-B-dec}
% \end{figure*}

% \todo{Talk about factorizability}

% \todo{ Tradeoff between perfectly local rules, where many are restricted to
%   open solutions, and factorizing rules that are uniformly applicable to any
%   kind of solution, but are neither local nor linear (because they rely on
%   duplicating the abstract proof in all subgoals) }

% \todo{IDEA: add (duplicating variants of) the {\rnm{pl_2}} and {\rnm{pr_2}}
% rules of \cite{clouston-annotation-free-2013} into the calculus. Indeed, they
% allow taking red items outside of red bubbles: thus if the proof can be made
% outside with a smaller context, it is more general and immediately solves all
% subgoals, improving \emph{factorizability}.}
