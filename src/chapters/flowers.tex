\setchapterpreamble[u]{\margintoc}
\chapter{Flower Calculus}
\labch{flowers}

\epigraph{In a certain flower garden, each flower was either red, yellow, or
blue, and all three colors were represented. A statistician once visited the
garden and made the observation that whatever three flowers you picked, at least
one of them was bound to be red. A second statistician visited the garden and
made the observation that whatever three flowers you picked, at least one was
bound to be yellow. Two logic students heard about this and got into an ar-
gument. The first student said: "It therefore follows that whatever three
flowers you pick, at least one is bound to be blue, doesn't it?" The second
student said: "Of course not!". Which student was right, and why?
}{\textbf{Raymond Smullyan}, \textit{The Flower Garden}, 1985}

We introduce the \emph{flower calculus}, a novel proof system for intuitionistic
predicate logic based on syntactic objects called \emph{flowers}. We start by
explaining how flowers stem from considerations in graphical logic, and more
specifically from a constructivization of the \emph{existential graphs}
(thereafter ``EG'') of C. S. Peirce proposed by A. Oostra
\sidecite[12.5em]{oostra_graficos_2010}. Then we present our inductive syntax
for flowers, reminiscent at the same time of the nested sequents of deep
inference proof theory, and the geometric formulas of categorical logic. A
salient feature of our calculus inherited from EG, is that it is \emph{fully
iconic}: it dispenses completely with the traditional notion of symbolic
formula, operating instead as a rewriting system on flowers containing only
atomic predicates. We also propose a notion of proof geared towards analyticity
results à la Gentzen, suggesting new rules absent from other works on
existential graphs. This allows us to prove admissibility theorems for many
structural rules, including Peirce's erasure rule which is a variant of
Gentzen's cut rule. These results are obtained as a consequence of our soundness
and completeness proofs with respect to Kripke semantics, in the spirit of the
\emph{normalization-by-evaluation} technique \sidecite{NbE}. Furthermore, the
kernel of rules targetted by completeness is fully invertible, a desirable
property in both automated and interactive proof search.

The chapter is organized as follows: in \refsec{EG}, we give a brief
presentation of the original diagrammatic system \sys{Alpha} of EG for classical
propositional logic, together with a reformulation as a rewriting system on
arbitrary (finite) trees. In \refsec{Flowers}, we explain how to obtain the
intuitionistic variant of EG put forth by A. Oostra \cite{oostra_graficos_2010}
through a subtle topological distinction in the graphical representation, which
can be illustrated metaphorically by drawing the graphs as \emph{flowers}. In
\refsec{Quantification}, we explain quickly the original mechanism of
\emph{lines of identity} used by Peirce to handle quantifiers and equality in
his \sys{Beta} system, and show how to recast it in a more traditional syntax
based on binders and variables. In \refsec{Calculus}, we introduce the full set
of inference rules of the flower calculus as well as our notion of proof, and
prove a few syntactic properties, including a deduction theorem. In
\refsec{Semantics}, we give a direct Kripke semantics to flowers, avoiding the
need for translations to and from formulas. In \refsec{Soundness}, we show that
the rules of the flower calculus are valid with respect to our Kripke semantics,
and in \refsec{Completeness} we identify a complete fragment of the system where
all rules are \emph{invertible}. This entails the admissibility of the rest of
the rules, and as a consequence the \emph{analyticity} of the system. We exploit
these properties in \refsec{flowers-search} by describing an algorithm for fully
automated proof search in the propositional fragment, that we conjecture to be
complete. Then in \refsec{flowers-prover} we give an overview of the Flower
Prover, a prototype of GUI in the Proof-by-Action paradigm whose actions map
directly to the rules of the flower calculus, and which integrates nicely with
our search procedure. In \refsec{flowers-curryhoward}, we briefly sketch some
ideas for a Curry-Howard correspondence, where flowers and actions for
manipulating them are identified respectively with \emph{normal} and
\emph{neutral} terms of the $\lambda$-calculus. We conclude in
\refsec{Conclusion} by a comparison with some related works, and a discussion of
future works and applications that we envision.

\todo{IDEA (where should we put it?): \emph{superposition of polarities} in
existential graphs. While a cut in bubble calculi is the insertion of \emph{two}
occurrences of the same formula with \emph{distinct} polarities, the insertion
rule only introduces \emph{one} occurrence of the formula, which plays either a
negative role when it is iterated, or a positive role when it is deiterated}

% \section{Introduction}

% \subsection{Interactive proof building}

% Given a sufficiently expressive logic, the problem of finding a formal proof of
% a given statement in that logic is notoriously hard. Not only because of
% undecidability, but because proof calculi are very rigid, and expose too many
% details compared to the informal proofs that mathematicians are used to write.

% One way to tackle this limitation is to design search procedures for interesting
% fragments of the logic under consideration. This is the approach undertaken by
% automated theorem provers such as SMT solvers, or more specialized decision
% procedures such as Coq's \texttt{lia} tactic for linear integer arithmetic.
% Still, large-scale proofs of complex theorems currently require a human in the
% loop to provide the overall structure of arguments, but also of the theories
% built up from definitions and lemmas.

% This is where proof assistants come in, by providing a set of tools to make the
% whole process of formalizing mathematical developments easier. This includes
% languages to specify definitions and statements conveniently, but also
% interfaces to build proofs interactively without having to fill in all the
% details. The dominant paradigm for these interfaces is that of \emph{tactic
% languages} \sidecite{doi:10.1098/rsta.1984.0067}: the user is exposed with a set of
% \emph{goals} that remain to be proved, also called the \emph{proof state}, and
% modifies these goals through textual commands called \emph{tactics} until there
% is no goal left. This is currently what is implemented in mainstream proof
% assistants such as Coq \sidecite{the_coq_development_team_2022_7313584}, Isabelle
% \sidecite{nipkow2002isabelle} and Lean \sidecite{10.1007/978-3-030-79876-5_37}.

% \subsection{Graphical interfaces}

% In recent years, there have been many efforts to replace or complement textual
% tactic languages with modern \emph{graphical user interfaces} \sidecite{PbP}
% \sidecite{langbacka-tkwinhol-1995} \sidecite{Chaudhuri2013} \sidecite{edukera}
% \sidecite{zhan-design-2019} \sidecite{ayers_graphical_2021}. The hope is to make proof
% assistants more intuitive and accessible to beginners and non-specialists, but
% also to some extent more productive and ergonomic for experts. 

% The initial motivation for this work was to design a proof calculus well-suited
% to \emph{direct manipulation} in such a graphical setting. The idea is that the
% user should be able to interact directly with the graphical representation of
% the proof state, using a pointing device such as a mouse or fingers on a touch
% screen. In previous work \sidecite{10.1145/3497775.3503692}, we proposed a way to
% synthesize complex logical inferences through \emph{drag-and-drop} actions
% between two items of the current goal. Since goals are represented as
% \emph{sequents} $\Gamma \vdash C$, the items involved were traditional logical
% formulas, either two hypotheses in $\Gamma$ or one hypothesis and the conclusion
% $C$.

% \subsection{Non-symbolic reasoning}

% In this work we show that sequents and formulas built from binary connectives
% and quantifiers are unnecessary for representing the proof state. We speculate
% that they actually get in the way of a natural flow of information in the proof,
% and do not capture accurately the way mathematicians organise hypotheses and
% conclusions in their reasoning. A similar argument has been made by E. Ayers in
% his thesis \sidecite{ayers_thesis}, where his solution is to design a nested goal
% data structure called \texttt{Box} on which reasoning can be performed directly
% without relying on formulas.

% % TODO: reference precise chapter of Ayers thesis

% We introduce a closely related structure for goals, but inspired instead by an
% early invention in the history of graphical logic: the \emph{existential graphs}
% of C. S. Peirce \sidecite{Roberts+1973} (thereafter written ``EG'').
% We noticed that our structure could be drawn and manipulated metaphorically in
% the form of nested \emph{flowers}, and thus decided to name \emph{flower
% calculus} the proof system that we built around it. Our focus in this work will
% be to study the fundamental properties of the flower calculus, mainly through
% the lens of modern structural proof theory. We only hint at some ways the
% calculus could be used as a foundation for a graphical theorem proving
% interface, and leave a more systematic proposal for future work.

\subsection*{TODO}

\begin{description}
  \item[Explanatory prose] The remaining content of this draft is essentially a
  terse, self-contained definition of the flower calculus, together with a
  relatively detailed proof of completeness. Already written sections will
  benefit from additional text explaining and motivating various definitions,
  lemmas and theorems.
  
  \item[Graphical exposition] The first three sections, which shall expose the
  origins and graphical intuitions behind the flower calculus, remain to be
  written. The `Syntax' section is only temporary, and will ultimately be
  merged/scattered throughout these first three sections.

  \item[Soundness] We have a detailed proof of soundness on paper, which still
  remains to be typeset in \LaTeX.
  
  \item[Conclusion] The conclusion section also remains to be written. Precise
  related works and lines of future research have not been chosen yet, although
  we have a good pool of candidates.
\end{description}

\todo{Make all usages of notations consistent with \reftab{letters}}


\section{Existential graphs}\labsec{EG}

\todo{ give a brief presentation of the original diagrammatic system \sys{Alpha}
of EG for classical propositional logic, together with a reformulation as a
rewriting system on arbitrary (finite) trees.}

Peirce is famous for his contributions to symbolic logic, including among others
his eponymous law for classical logic, and his pioneering work on the algebra of
relations and quantification \sidecite{peirce_algebra_1885}. But far less
widespread are his achievements in the realm of graphical logic, or \emph{iconic
logic} as Shin calls it \sidecite{10.7551/mitpress/3633.001.0001}. He dedicated
a large chunk of his life investigating diagrammatic systems, starting in 1882
with the \emph{entitative graphs} and culminating with the \emph{existential
graphs}, which he developed from 1896 until his death in 1914
\sidecite{Roberts+1973}. Interestingly, Peirce perceived EG as his
\textit{``chef d'oeuvre''}, and that they \textit{``ought to be the logic of the
future''}\sidenote{Both citations are sourced in page 11 of
\cite{Roberts+1973}.}.

Recent works have started to realize this vision: for example Sowa based his
conceptual graphs for computerized knowledge representation on EG
\sidecite{sowa_conceptual_1976}, Brady, Trimble
\sidecite{brady_categorical_2000}\sidecite{brady_string_nodate} and Haydon,
Sobociński \sidecite{pietarinen_compositional_2020} proposed various
reconstructions of EG through the lens of \emph{topology} and \emph{category
theory}, and Melliès and Zeilberger \sidecite{mellies_bifibrational_2016}
refined the interpretation of Brady and Trimble by making further connections
with \emph{linear logic}\sidenote{We also know through private communication
that N. Haydon is actively working on more explicit links between linear logic
and the original formulation of EG by Peirce.} \sidecite{girard-linear-1987}.
The full story has yet to be told, but we hope that our work will constitute one
more step towards the vision Peirce had in mind.

\subsection{\sys{Alpha} graphs}

Peirce designed in total three systems of EG, which he called respectively
\sys{Alpha}, \sys{Beta} and \sys{Gamma}. They were invented chronologically in
that order, which also captures their relationship in terms of complexity:
\sys{Alpha} is the foundation on which the other systems are built, and can
today be understood as a diagrammatic calculus for classical
\emph{propositional} logic. As we will see in \refsec{Quantification},
\sys{Beta} corresponds to a variable-free representation of \emph{predicate}
logic without function symbols, and with primitive support for \emph{equality}.
The last system \sys{Gamma} is more experimental, with various unfinished
features that have been interpreted as attempts to capture \emph{modal}
\sidecite{zeman_graphical_1964} and \emph{higher-order} logics\sidenote{A less
known fact is that at the end of his life, Peirce pushed his experimentations
beyond the scope of \emph{logic} in the contemporary sense of the word (it was
already the case for modal logic in his time), with so-called \emph{tinctured
existential graphs} (Chapter 6 in \cite{Roberts+1973}). Roughly, the idea was to
represent a variety of \emph{modes of expression} with different background
shades on the canvas where sentences are scribed, not unlike our graphical
depiction of the \emph{status} of solutions in \reffig{graphical-B}. In addition
to the usual act of asserting the truth of a proposition, one could for instance
express a \emph{subjective} or \emph{objective} possibility, or signify an
interrogative or imperative mood, all by using different colors. For print in
publications, he would in fact use \emph{heraldic tinctures} instead of colors,
hence the ``tinctured'' qualificative. The precise meaning and purpose of
tinctured EG remains elusive to this day, and might constitute the most esoteric
part of his work. We see a possible connection with the type-theoretical concept
of \emph{judgment}, which was rehabilitated by Martin-Löf from the philosophy of
Kant \cite{Martin-Lof1996-MAROTM-7}, who was of great influence on Peirce's own
philosophy \cite{sep-peirce}.}.

The most fundamental concept of \sys{Alpha} is the \emph{sheet of assertion},
denoted by $\SA$ thereafter. It is the space where statements are scribed by the
reasoner, typically a sheet of paper or a blackboard. In a proof assistant, this
would either be the buffer of a text editor holding the theory the user is
developing, or the proof view displaying goals to be proved, depending on who
the reasoner is (the user or the computer, respectively). This last analogy
suggests an important property of $\SA$: it must offer a \emph{virtually
infinite} amount of space, so that one can perform as much reasoning as needed.
Just like a Turing machine has an infinite tape, so that one can perform as much
computation as needed.

As its name indicates, scribing a statement on $\SA$ amounts to \emph{asserting
its truth}. Thus very naturally, the empty $\SA$ where nothing is scribed will
denote vacuous truth, traditionally symbolized by the formula
$\top$\sidenote{Peirce had an \emph{externalist} conception of truth, where the
assertions made by the \process{Graphist}, i.e. the person scribing on $\SA$,
refer to the world \emph{outside} of the sheet (the universe of discourse). By
not scribing anything, the \process{Graphist} thus refrains from asserting
anything about the world, only assuming implicit truths. This is illustrated by
the following quote from \cite{Roberts+1973}, reminiscent of an interaction
between a proof assistant (the \process{Graphist}) and her user (\process{the
Interpreter}): \textit{``One of the parties, called the Graphist, is responsible
for scribing the original graphs at the beginning of the investigation or
discussion; the other, called the Interpreter, draws inferences from these
graphs by changing them in accordance with the permissions of the system. The
[...] sheet, before anything is scribed on it, represents whatever is taken for
granted at the outset by the Graphist and Interpreter.''}.}.

As we know from natural deduction, asserting the truth of the conjunction $P
\land Q$ of two propositions $P$ and $Q$, amounts to asserting the truth of $P$
and the truth of $Q$. In EG, there is no need to introduce the symbolic
connective $\land$, since one can just write both $P$ and $Q$ at distinct
locations of $\SA$:
$$P~~~Q$$
More generally, one might consider any two portions $G$ and $H$ of $\SA$, and
interpret their \emph{juxtaposition} $G~H$ as signifying that we assert the
truth of their conjunction. This leads us to formulate the first fundamental
principle of EG:
$$\text{\emph{Any portion of $\SA$ is a graph.}}$$

Asserting the truth of the negation $\neg P$ of a proposition $P$, amounts to
\emph{denying} the truth of $P$. Using the original notation of Peirce, this is
done in EG by \emph{enclosing} $P$ in a closed curve like so:
$$\ppcut{P}$$
Peirce called such curves \emph{cuts}\sidenote{Not to be confused with the name
given to instances of the \emph{cut rule} in sequent calculus. Although there is
a connection, since in \sys{LK}, one occurrence of the cut formula in the
premisses of the rule is negated.}, because they ought to be seen as literal
cuts in the paper sheet that embodies $\SA$. Note that they do not need to be
circles: all that matters is that $P$ is in a separate area from the rest of
$\SA$. This is precisely the content of the \emph{Jordan curve theorem} in
topology, and thus we can take cuts to be arbitrary Jordan curves. This entails
in particular that cuts cannot intersect each other, but can be freely nested
inside each other. Then as for juxtaposition, one can replace $P$ by any graph
$G$, i.e. any portion of $\SA$, as long as the cut does not intersect other cuts
in $G$.

With just these two \emph{icons}, juxtaposition and cuts, one can therefore
assert the truth of any proposition made up of conjunctions and negations, and
built from atomic propositions. Importantly, the only symbols needed for doing
so are the letters $P, Q, R\ldots$ denoting atomic propositions.

Now, it is well-known that $\{\land,\neg\}$ is \emph{functionally complete},
meaning that any boolean truth function can be expressed as the composition of
boolean conjunctions and negations. In particular, the symbolic definitions of
falsehood $\bot \defeq \neg\top$, classical disjunction $A \lor B \defeq
\neg(\neg A \land \neg B)$ and classical implication $A \limp B \defeq \neg (A
\land \neg B)$ can be expressed by the following three graphs\sidenote{Note the
resemblance with the translation of formulas as solutions in
\reffig{bubbles-native}, in particular for negative disjunctions.}:
\begin{mathpar}
  \ppcut{\phantom{A}}
  \and
  \ppcut{\ppcut{A}~~~\ppcut{B}}
  \and
  \ppcut{A~~~\ppcut{B}}
\end{mathpar}
Thus one can easily encode any propositional formula into a classically
equivalent graph. Conversely, one can translate a graph into a classically
equivalent formula, as has been shown for instance in
\sidecite{10.7551/mitpress/3633.001.0001}. In fact, there are usually many
possible formula readings of a given graph: this is because juxtaposition of
graphs is a \emph{variadic} operation, as opposed to conjunction of formulas
which is \emph{binary}. Also, because of the topological nature of $\SA$,
juxtaposition is naturally \emph{associative} and \emph{commutative}: the
locations of two juxtaposed graphs do not matter, as long as they live in the
same area delimited by cuts. Hence, graphs can be seen as an
associative-commutative normal form for propositional formulas built from atoms
with $\{\land,\neg\}$\sidenote{In a first version of EG called \emph{entitative
graphs}, Peirce used juxtaposition to denote \emph{disjunction} instead of
conjunction. Although $\{\lor,\neg\}$ is also functionally complete, Peirce
quickly grew unsatisfied with these entitative graphs, stating that EG formed
``a far preferable system on the whole'' (Ms 280, pp. 21-22). I find it
interesting that more contemporary works in logic have also made the choice to
take conjunction and negation as their primitive operations, like the tensorial
logic of Melliès \cite{mellies_micrological_2017}, or the realizability
constructions for linear logic in Girard's transcendental syntax
\cite{eng_stellar_2020}.}.

\subsection{Illative transformations}

In order to have a proof system, one needs a collection of \emph{inference
rules} for deducing true statements from other true statements. In EG, inference
rules are implemented by what Peirce called \emph{illative transformations} on
graphs. In modern terminology, they correspond to \emph{rewriting} rules that
can be applied to any subgraph/portion of $\SA$. By measuring the depth of a
subgraph as the number of cuts in which it is enclosed, we thus have that the
rules of EG are applicable on subgraphs of arbitrary depth. This makes EG
deserving of the title of \emph{deep} inference system.

\begin{marginfigure}
  $$\npcut{A~~~\ppcut{\npcut{B}~~~C}}$$
  \caption{Peirce's notation for emphasizing negative areas}
  \labfig{peirce-neg-areas}
\end{marginfigure}

\begin{marginfigure}
  $$\ncut{A~~~\pcut{\ncut{B}~~~C}}$$
  \caption{Our notation for emphasizing negative areas}
  \labfig{our-neg-areas}
\end{marginfigure}

Before introducing the rules, let us make a small change in the way we depict
the graphs. The idea is that we want to visualize more clearly the
\emph{polarity} of any subgraph $G$, understood as the \emph{parity} of the
number of cuts (negations) enclosing $G$. In one of his unpublished manuscripts
(Ms 514), Peirce did this by \emph{shading} negative areas --- those enclosed in
an odd number of cuts --- in gray, as illustrated in \reffig{peirce-neg-areas}
\sidecite{sowa_peirces_2011}. Unconstrained by hand-drawing, we will adopt an
even more iconic notation, where negative areas are \emph{literally} drawn like
a negative in photography, by inverting white and black. Thus the example of
\reffig{peirce-neg-areas} will be drawn as in \reffig{our-neg-areas}. A nice
advantage of both Peirce's and our notation, is that it removes the need to
count manually the number of cuts starting from the top-level of $\SA$: the
information is immediately apparent in the subgraph, and thus completely
\emph{local}\sidenote{A similar device is used in the deep inference system
\sys{ISp} of Tiu \cite{tiu_local_2006}, where the polarities of substructures
are attached to them as explicit labels.}.

\begin{remark}
  Whereas in bubble calculi the concept of polarity was understood as a property
  of \emph{objects} --- i.e. utterances of propositions --- by assigning them
  opposite colors (blue and red), the previous notations for EG suggest that it
  is instead a property of the \emph{space} in which objects reside. This is
  more natural from the point of view of \emph{game semantics}: for instance in
  a game of chess, the two players can easily exchange their roles by switching
  places or rotating the board by 180°, rather than by repainting painstakingly
  each piece in the opposite color.
\end{remark}

Quite surprisingly, Peirce showed that one only needs $5$ inference rules to get
a \emph{strongly complete} system, in the sense that if the truth of a graph $G$
entails the truth of another graph $H$, then $G$ can always be rewritten into
$H$ by applying exclusively instances of these $5$ rules\sidenote{Of course
Peirce did not show completeness formally in the sense of modern model theory,
although Sowa argues in \cite{sowa_peirces_2011} (Section 4) that he had started
to develop his own model theory equivalent to Tarski's (but closer to the
\emph{game-theoretical semantics} of Hintikka \cite{Hintikka1973-HINLLA}). One
can find a modern categorical treatment of completeness with respect to Boolean
algebras, based on a rigorous formalization of the geometry and algebra of EG,
in \cite{brady_categorical_2000}.}. A nice way to understand the rules of EG is
as \emph{edition principles}, like the most basic actions one executes
pervasively when editing text on a computer\sidenote{Even though computers did
not exist yet in Peirce's time! In fact, Martin Irvine argues in
\cite{irvine_semiotics_2022} that Peirce anticipated many developments in
computer science and information technologies, such as the use of electrical
switches to compute boolean functions, whose invention is usually attributed to
Claude Shannon.}. The first two rules are the most powerful and mysterious of
EG, and can be applied in areas of any polarity:
\begin{itemize}
  \item[\textbf{Iteration} \textit{(Copy \& Paste)}]
    A graph $G$ may be duplicated at any depth inside of a juxtaposed graph $H$.
    Using our notation for holed contexts from previous chapters, this can be
    represented schematically like so:
    \begin{mathpar}
      G~~~H\select{\phantom{G}} ~~~\step~~~ G~~~H\select{G}
      \and
      \nsheet{G~~~H\select{\phantom{G}} ~~~\step~~~ G~~~H\select{G}}
    \end{mathpar}
    In particular, $H$ can be taken to be any empty portion of $\SA$ in the same
    area as $G$, giving that $G ~\step~ G~G$.
  \item[\textbf{Deiteration} \textit{(Factorization)}]
    Formally, this is the converse of \rsf{Iteration}:
    \begin{mathpar}
      G~~~H\select{G} ~~~\step~~~ G~~~H\select{\phantom{G}}
      \and
      \nsheet{G~~~H\select{G} ~~~\step~~~ G~~~H\select{\phantom{G}}}
    \end{mathpar}
    Its interpretation as an edit action is a bit trickier, but it can be
    understood as a form of \emph{sharing} of information. Indeed, it roughly
    says that a subgraph $G$ can be erased if it already occurs ``higher'' on
    $\SA$. Also this does precisely the opposite of copy-pasting, which is known
    in software engineering as \emph{factorization}\sidenote{This is closely
    related to the kind of factorization at work in bubble calculi. In
    particular, the fact that the factorizing occurence is higher and usually
    outside of a cut is very reminiscent of the \emph{outward} flow rules of
    system $\sysB$ (those whose name ends with $\uparrow$ in
    \reffig{sequent-B}); and the deduplicating effect makes \rsf{Deiteration}
    even closer to the variant of the same rules in \sys{B_{inv}}
    (\reffig{sequent-B-inv}).}.
\end{itemize}
The applicability of the next two rules depends on the polarity of the
subgraph's area:
\begin{itemize}
  \item[\textbf{Insertion}]
    Any graph $G$ may be inserted in a negative area:
    $$\nsheet{~~~\step~~~ G}$$
    This is akin to a \emph{weakening} rule, stating that if a proposition is
    known to be true, one might add (useless) hypotheses at will. The closest
    equivalent we found in the deep inference literature is indeed the weakening
    rule \rsf{wl{\downarrow}} of \sys{ISp} in \sidecite{tiu_local_2006}.
  \item[\textbf{Erasure} \textit{(Deletion)}]
    Any graph $G$ occurring in a positive area may be erased:
    $$G ~~~\step~~~$$
    This is exactly the dual of \rsf{Insertion}, stating that if a proposition
    is known to be true, then one might as well refrain from asserting it.
    % It is strongly related to the cut rule of sequent calculus, as will be
    % demonstrated shortly.
\end{itemize}
The last rule is more of a \emph{space management} principle that works as an
\emph{isotopy}, i.e. a bidirectional topological deformation:
\begin{itemize}
  \item[\textbf{Double-cut}]
    A \emph{double-cut} may be inserted or erased around any graph $G$:
    \begin{mathpar}
      \ncut{\pcut{G}} ~~~\leftrightarrow~~~ G
      \and
      \nsheet{\pcut{\ncut{G}} ~~~\leftrightarrow~~~ G}
    \end{mathpar}
    The bidirectional arrow $\leftrightarrow$ expresses that the rule can be
    applied in both directions\sidenote{We could have merged \rsf{Iteration} and
    \rsf{Deiteration} in this way, but chose to follow the original presentation
    of the rules by Peirce instead, as exposed in \cite{Roberts+1973}.}.
    Logically, this corresponds to the classical equivalence $\neg\neg A
    \semequiv A$, where in particular the erasure direction $\neg\neg A \limp A$
    is not true intuitionistically. Topollogically, the double-cut forms a
    \emph{ring}, that separates $G$ from the rest of $\SA$ while preserving its
    polarity. Then the two directions of the rules can be understood as the
    following dual \emph{homotopies}:
    \begin{itemize}
      \item[\textbf{Contraction}] The ring is created by cutting $\SA$ around
      $G$, and then \emph{contracting} the inner area where $G$ resides on
      itself. This effectively ``pulls apart'' $G$ from the rest of the sheet,
      leaving apparent in the empty space of the ring whatever lies behind
      $\SA$. Peirce thought of positive and negative areas as being the
      \emph{recto} and \emph{verso} of $\SA$, respectively. Thus in the positive
      version of the rule (on the left), the ring would represent negative empty
      space on the verso of $\SA$.
      \item[\textbf{Expansion}] The ring is erased by \emph{expanding} the inner
      area where $G$ resides towards the outer border of the ring. Unfolding the
      metaphor to its conclusion, the inner area is then ``glued back'' to the
      rest of $\SA$\sidenote{This is reminiscent of the \emph{absorption} rules
      $\{\rsf{a},\rsf{a{-},\rsf{a{+}}}\}$ of system $\sysB$, as is very clear in
      their graphical presentation (\reffig{graphical-B}).}.
    \end{itemize}
\end{itemize}
A remarkable feat of Peirce's rules, on which he insisted very much, is that
they are only expressed in terms of \emph{insertions} and \emph{omissions} of
graphs on $\SA$. He thought that those were the \emph{smallest} steps in which
reasoning could be dissected, making his system extremely appropriate for
\emph{analytical} purposes\sidenote{See Section 7.11 of \cite{Roberts+1973}.}.
We already considered this question of decomposing logical inferences into their
most elementary operations, when reflecting on the graphical presentation of
\sys{BJ} at the end of \refsec{bubbles-graphical-rules}. In this setting, the
most basic insertions and omissions we could find were not logically
\emph{sound}, whereas in EG they are. This is quite promising, and prompts us to
reevalute our conception of \emph{atomicity} in logical reasoning.

\reffig{peirce-law-eg} shows a derivation of Peirce's law with the rules of EG.
Note that the direction of arrows has been reversed compared to the above
presentation: as usual, we prefer to read rules from conclusion to premiss,
starting from the goal to prove --- here the graph associated to the formula
$((P \limp Q) \limp P) \limp P$ --- that we reduce to the empty goal,
represented by the empty $\SA$. Also, the reader unfamiliar with EG might find
it hard to convince herself that all the steps followed in the derivation are
\emph{sound} logically. For lack of space, we will not provide a general proof
of soundness for the rules, which requires a bit of work (especially in the case
of \rsf{Iteration} and \rsf{Deiteration}). We suggest the reader to either:
\begin{enumerate*}
  \item build a \emph{syntactic} intuition by practicing the rules with various
  tautologies of propositional logic;
  \item read up the existing literature on the subject, for instance in Appendix
  4 of \cite{Roberts+1973};
  \item wait for the proof of soundness of our flower calculus with respect to
  Kripke semantics in \refsec{Soundness}.
\end{enumerate*}

\todo{Draw proof of Peirce's law}

Lastly, let us give an example of how to \emph{simulate} a rule from natural
deduction in EG. Rather than reducing the graph associated to a formula to the
empty $\SA$, we want to reduce the graph associated to the conclusion of the
rule into the graph associated to its premisses. \reffig{eg-seq-cut} shows how
to proceed in the case of the elimination rule for $\limp$, or \emph{modus
ponens}. A crucial step is the use of the \rsf{Erasure} rule, which allows to
create a positive occurrence of $A$ out of thin air. This is the main source of
non-analyticity in EG, in the sense of the \emph{subformula property} of
Gentzen. We will show in \refsec{Completeness} that the equivalent of
\rsf{Erasure} in our flower calculus is admissible. This derivation also makes
clear that it is the positive $A$ that justifies the negative one with the
\rsf{Deiteration} rule, and not the other way around. Indeed, the presence of
the cut around the negative $A$ makes it deeper than the positive $A$ on $\SA$,
preventing the \rsf{Deiteration} rule from being applicable in the other
direction. This is a manifestation of the inherent dissymmetry in \emph{proof
substitution}: the erasure of the negative $A$ can be interpreted as the
operation $\subst{\pi_A}{\pi_B}{x}$, which substitutes every occurrence of the
associated hypothesis $x$ in the proof $\pi_B$ of $B$ by the proof $\pi_A$ of
the positive $A$. We elaborate further on this computational aspect of EG in
\refsec{flowers-curryhoward}.

\todo{Draw simulation of modus ponens $A \land (A \limp B) \limp B$}

% \todo{ Then compare sequent and EG derivations of the example on p. 111 of
% \cite{Roberts+1973}, where the latter exposes a lot less steps. Thus, which
% should be considered more atomic? We will not fret too much over this question,
% our goal in the end being to hide trivial reasoning steps from the user. We will
% see in \refsec{flowers-prover} that this is not incompatible with the analytic
% aspect of EG. }

\subsection{As a rewriting system}

\todo{Mention the Tree Existential Graphs (TEG) of \cite{Roberts+1973}, but that
we could not find any associated publication, and that it might have stayed a
WIP. Brady and Trimble also propose to see an alpha graph as a rooted tree, but
they choose to work with a more abstract combinatorial description based on the
operation of \emph{substitution} of a graph at a given point.}


\section{Intuitionistic logic}\labsec{Flowers}

\todo{ explain how to obtain the intuitionistic variant of EG put forth by A.
Oostra \cite{oostra_graficos_2010} through a subtle topological distinction
added to the graphical representation, which reflects in the inductive syntax. A
harmless modification to the way of drawing the intuitionistic graphs then
justifies the metaphorical terminology of our calculus.}

\subsection{The n-ary scroll}

\subsection{Flowers}

\todo{Mention Oostra's extended (de)iteration rule, that allows to
duplicate/merge identical petals. But it is not \emph{deep} (``Cualquier lazo
puede iterarse adherido \emph{al mismo corte}'', p. 46 of
\cite{oostra_graficos_2010}), and thus seems a bit arbitrary.}


\section{Quantification}\labsec{Quantification}

\todo{ illustrate quickly the original mechanism of \emph{lines of identity}
used by Peirce to handle quantifiers and equality in his \sys{Beta} system, and
show how to recast it in a more traditional binder-based syntax. Although some
interesting low-level proof dynamics are lost, it greatly simplifies both the
inductive formulation, and the graphical representation when the proof state
gets larger.}

\subsection{Lines of identity}

\subsection{Gardens}

\section*{Syntax}

\todo{What should be done with this section?}

\begin{definition}[First-order signature]
  A \emph{first-order signature} is a triplet $\mathcal{\Sigma} = (
  \fsymbs, \psymbs, \arity )$, where $\fsymbs$ and $\psymbs$ are
  respectively the countable sets of \emph{function} and \emph{predicate}
  symbols of $\Sigma$, and $\arity : \fsymbs \cup \psymbs \to \nats$ gives an
  \emph{arity} to each symbol.
\end{definition}

In the following, we assume given a denumerable set of variables $\vars$
and a first-order signature $\Sigma$.

\begin{definition}[Terms]
  The set of terms $\terms$ is defined inductively as follows:
  \begin{itemize}
    \item{\textbf{(Variable)}} If $x \in \vars$ then $x \in \terms$;
    \item{\textbf{(Application)}} If $f \in \fsymbs$ and $\tvec{t}
    \in \terms^{\arity(f)}$, then $f(\tvec{t}) \in \terms$.
  \end{itemize}
\end{definition}

\begin{definition}[Flowers]\labdef{flowers}
  The sets of \emph{flowers} $\flowers$ and \emph{gardens} $\gardens$ are
  defined mutually inductively as follows:
  \begin{itemize}
    \item{\textbf{(Atom)}} If $p \in \psymbs$ and $\tvec{t} \in
    \terms^{\arity(p)}$, then $p(\tvec{t}) \in \flowers$;
    \item{\textbf{(Garden)}} If $\mathbf{x} \subset \vars$ is a finite set and $\Phi
    \subset \flowers$ a finite multiset, then $\garden{\mathbf{x}}{\Phi} \in
    \gardens$;
    \item{\textbf{(Flower)}} If $\gamma \in \gardens$ and $\Delta \subset \gardens$
    is a finite multiset, then $\flower{\gamma}{\Delta} \in \flowers$.
  \end{itemize}
\end{definition}

Any finite set $\mathbf{x} \subset \vars$ of variables is called a
\emph{sprinkler}, finite multiset $\Phi \subset \flowers$ of flowers a
\emph{bouquet}, and finite multiset $\Gamma \subset \gardens$ of gardens a
\emph{corolla}. We will often write gardens as $\garden{x_1, \ldots,
x_n}{\phi_1, \ldots, \phi_m}$, where the $x_i$ are called \emph{binders}; and
non-atomic flowers as $\flower{\gamma}{\delta_1 \sep \ldots \sep \delta_n}$,
where $\gamma$ is the \emph{pistil}, and the $\delta_i$ are called
\emph{petals}. We write $\fset{i}{n}{E_i}$ to denote a finite (multi)set of
size $n$ with elements $E_i$ indexed by $1 \leq i \leq n$. We also omit
writing the empty (multi)set, accounting for it with blank space as is done in
sequent notation or in Peirce's EG; in particular, $\garden{{}}{{}}$ stands for
the empty garden $\garden{\emptyset}{\emptyset}$, $\flower{\gamma}{{}}$ for the
flower with no petals $\flower{\gamma}{\emptyset}$, and
$\flower{\gamma}{\garden{{}}{{}}}$ for the flower with one empty petal.

Note that the order of precedence of operators is
$\mathop{,} < \garden{{}}{{}} < \mathop{;} < \mathop{\flower{}{}}$
so that for instance, the string
$$\flower{\garden{x_1, x_2}{\phi_1, \phi_2}}{\garden{y_1}{\psi, (\flower{\gamma}{\Delta})} \sep \garden{y_2}{\Phi}}$$
is parsed as the flower
$$\left(\flower{\left(\garden{\{x_1, x_2\}}{\{\phi_1,
\phi_2\}}\right)}{\{\left(\garden{\{y_1\}}{\{\psi,
\left(\flower{\gamma}{\Delta}\right)\}}\right) \sep
\left(\garden{\{y_2\}}{\Phi}\right)\}}\right)$$ where constructed finite
(multi)sets are delimited with $\{\}$, and constructed flowers/gardens are
delimited with $()$.

\todo{ Introduce convention that $\garden{{}}{\Phi}$ is shortened into $\Phi$,
and apply it everywhere to save some space and improve readability. }

\begin{remark}
  In some places the choice of letter for meta-variables will be important to
  disambiguate the kind of syntactic object we denote. \reftab{letters}
  summarizes our chosen notational conventions in this respect.
\end{remark}

\begin{marginfigure}
  \centering
  \begin{tabular}{|c|c|}
    \hline
    \bfseries Kind & \bfseries Letters \\
    \hline
    Variables ($\vars$) & $x, y, z$ \\
    Terms ($\terms$) & $t, u, v$ \\
    Flowers ($\flowers$) & $\phi, \psi, \xi$ \\
    Gardens ($\gardens$) & $\gamma, \delta$ \\
    Sprinklers & $\mathbf{x}, \mathbf{y}, \mathbf{z}$ \\
    Term vectors & $\tvec{t}, \tvec{u}, \tvec{v}$ \\
    Substitutions & $\sigma, \tau$ \\
    Bouquets & $\Phi, \Psi, \Xi$ \\
    Corollas & $\Gamma, \Delta$ \\
    Contexts & $\Phi\hole, \Psi\hole, \Xi\hole$ \\
    Theories & $\mathcall{T}, \mathcall{U}$ \\
    \hline
  \end{tabular}
  \caption{Notational conventions for meta-variables}
  \labtab{letters}
\end{marginfigure}

\begin{definition}[Free variables]\labdef{fv}
  The sets of \emph{free variables} $\fv(-)$ of a term, flower or garden are
  defined mutually inductively as follows:
  \begin{align*}
    \fv(x) &= \{x\} \\
    \fv(f(\tvec{t})) &= \bigcup_{t \in \tvec{t}}{\fv(t)} \\
    \fv(p(\tvec{t})) &= \bigcup_{t \in \tvec{t}}{\fv(t)} \\
    \fv(\garden{\mathbf{x}}{\Phi}) &= \bigcup_{\phi \in \Phi}{\fv(\phi)} \setminus \mathbf{x} \\
    \fv(\flower{\garden{\mathbf{x}}{\Phi}}{\Delta}) &= \fv(\garden{\mathbf{x}}{\Phi}) \cup \bigcup_{\garden{\mathbf{y}}{\Psi} \in \Delta}{\fv(\garden{\mathbf{x}, \mathbf{y}}{\Psi})}
  \end{align*}
  We say that a term, flower or garden is \emph{closed} when its set of free
  variables is empty. The sets of closed terms, flowers and gardens are denoted
  respectively by $\closed{\terms}$, $\closed{\flowers}$ and $\closed{\gardens}$.
\end{definition}

\begin{definition}[Bound variables]
  % The set of \emph{bound variables} $\bv(\Phi\hole)$ of a context $\Phi\hole$ is defined
  % inductively as follows:
  % \begin{align*}
  %   \bv(\Psi, \hole) &= \emptyset \\
  %   \bv(\Psi, (\flower{\garden{\mathbf{x}}{X}}{\Delta})) &= \mathbf{x} \cup \bv(X) \\
  %   \bv(\Psi, (\flower{\garden{\mathbf{x}}{\Phi}}{\garden{\mathbf{y}}{X} \sep \Delta})) &= \mathbf{x} \cup \mathbf{y} \cup \bv(X)
  % \end{align*}
  The set of bound variables $\bv(\phi)$ (resp. $\bv(\gamma)$) of a
  flower $\phi$ (resp. garden $\gamma$) is defined by mutual induction as
  follows:
  \begin{align*}
    \bv(p(\tvec{t})) &= \emptyset \\
    \bv(\garden{\mathbf{x}}{\Phi}) &= \mathbf{x} \cup \bigcup_{\phi \in \Phi}{\bv(\phi)} \\
    \bv(\flower{\gamma}{\Delta}) &= \bv(\gamma) \cup \bigcup_{\delta \in \Delta}{\bv(\delta)}
  \end{align*}
\end{definition}

\begin{definition}[Function update]
  Let $A, B$ be two sets, $f, g : A \to B$ two functions and $R \subseteq A$
  some subset of their domain. The \emph{update} of $f$ on $R$ with $g$ is the
  function defined by:
  $$
  \update{f}{R}{g}(x) =
  \begin{cases}
    g(x) &\text{if $x \in R$} \\
    f(x) &\text{otherwise}
  \end{cases}
  $$
  $\update{-}{-}{-}$ is obviously associative, that is
  $\update{f}{R}{(\update{g}{S}{h})} = \update{(\update{f}{R}{g})}{S}{h}$. Also
  if $f$ or $g$ is the identity function $\idsubst$ we omit writing it, i.e.
  $\update{f}{R}{} = \update{f}{R}{\idsubst}$ and $\update{}{R}{g} =
  \update{\idsubst}{R}{g}$.
\end{definition}

\begin{definition}[Substitution]
  A \emph{substitution} is a function $\sigma : \vars \to \terms$ with a finite
  \emph{support} $\dom(\sigma) = \compr{x}{\sigma(x) \not= x}$. By abuse of
  notation, we will write $\sigma : \mathbf{x} \to \terms$ to denote a
  substitution $\sigma$ whose support is $\mathbf{x}$.
  The domain of substitutions is extended to terms, flowers and gardens
  inductively as follows:
  \begin{align*}
    \sigma(f(\tvec{t})) &= f(\sigma(\tvec{t})) \\
    \sigma(p(\tvec{t})) &= p(\sigma(\tvec{t})) \\
    \sigma(\garden{\mathbf{x}}{\Phi}) &=
      \garden{\mathbf{x}}{\restr{\sigma}{\mathbf{x}}(\Phi)} \\
    \sigma(\flower{\garden{\mathbf{x}}{\Phi}}{\Delta}) &=
      \flower{\sigma(\garden{\mathbf{x}}{\Phi})}{\restr{\sigma}{\mathbf{x}}(\Delta)}
  \end{align*}
\end{definition}


\section{Calculus}\labsec{Calculus}

\todo{ introduce formally the full set of inference rules of the flower calculus
as well as our notion of proof, both motivated by analyticity concerns. We also
prove a few useful syntactic properties of our system, including a deduction
theorem.}

\begin{definition}[Context]
  A \emph{context} $\Phi\hole$ is a bouquet such that there is a unique flower
  $\phi \in \Phi\hole$ which contains exactly 1 distinguished 0-ary atom $\hole$
  called the \emph{hole} of $\Phi\hole$. This hole can always be \emph{filled}
  (substituted) with any other bouquet $\Psi$ or context $\Xi\hole$, producing a
  new bouquet $\cfill{\Phi}{\Psi}$ or context $\cfill{\Phi}{\Xi\hole}$. In
  particular, filling with the empty bouquet will yield a bouquet
  $\cfill{\Phi}{\phantom{\Phi}}$, which is just $\Phi\hole$ with its hole removed.
\end{definition}

\begin{definition}[Parity]
  The \emph{parity} $\parity{\Phi\hole}$ of a context $\Phi\hole$ is defined inductively by:
  \begin{align*}
    \parity{\Psi, \hole} &= 0 \\
    \parity{\Psi, (\flower{\garden{\mathbf{x}}{\Phi\hole}}{\Delta})} &= \parity{\Phi\hole} + 1 \\
    \parity{\Psi, (\flower{\gamma}{\garden{\mathbf{x}}{\Phi\hole} \sep \Delta})} &= \parity{\Phi\hole}
  \end{align*}
\end{definition}

\begin{definition}[Polarity]
  We say that a context $\Phi\hole$ is \emph{positive} if $\parity{\Phi\hole}$ is even, and
  \emph{negative} otherwise. We denote positive and negative contexts
  respectively by $\Phi^+\hole$ and $\Phi^-\hole$.
\end{definition}

\begin{definition}[Hypothesis]
  We say that a flower $\phi$ is a \emph{hypothesis} of a context $\Phi\hole$, written
  $\chyp{\phi}{\Phi\hole}$, when there exist a bouquet $\Psi$ with $\phi \in \Psi$ and
  contexts $\Xi\hole$ and $\Xi_0\hole$ such that either:
  \begin{itemize}
    \item $\Phi\hole = \cfill{\Xi}{\Psi, \Xi_0\hole}$;
    \item $\Phi\hole =
    \cfill{\Xi}{\flower{\garden{\mathbf{x}}{\Psi}}{\garden{\mathbf{y}}{\Xi_0\hole}
    \sep \Delta}}$ for some $\mathbf{x}, \mathbf{y}, \Delta$.
  \end{itemize}
  A bouquet $\Psi$ is said to be \emph{available} in $\Phi\hole$, written
  $\chyp{\Psi}{\Phi\hole}$, if $\chyp{\psi}{\Phi\hole}$ for all $\psi \in \Psi$.
\end{definition}

To avoid reasoning about $\alpha$-equivalence, we adopt in this work the
so-called \emph{Barendregt convention} that all variable binders are distinct,
both among themselves and from eventual free variables. Formally, we assume that
for any flower $\phi$, the two following conditions hold:
\begin{enumerate}
  \item computing $\bv(\phi)$ as a multiset gives the same result as computing
  it as a set;
  \item $\bv(\phi) \cap \fv(\phi) = \emptyset$.
\end{enumerate} 
% To preserve this convention, in this paper we will only consider
% \emph{non-circular} substitutions $\sigma$ where $x \not\in \fv(\sigma(x))$ for
% all $x \in \dom(\sigma)$.

The central device studied in this work, the \emph{flower calculus}, can be
described as a \emph{rewriting system} on bouquets. That is, one has a finite
number of rewrite rules which are families (schemas) of pairs of bouquets, and
these can be applied and composed in a directed way to derive new bouquets.
Intuitively, a rewriting step $\Phi \rightarrow \Psi$ should be understood as an
act of \emph{backward inference}: starting from the goal $\Phi$ that I want to
prove, I transform it into a new goal $\Psi$ which is a sufficient justification
of $\Phi$, and hopefully simpler to prove.

\begin{figure*}
  \begin{framed}
  {\textsc{Nature} $\Nature$}
  \vspace{1.5em}
  \begin{mathpar}
    \R[\textsf{poll}{\downarrow}]
      {\cfill{\Xi}{\phantom{\Phi}}}
      {\cfill{\Xi}{\Phi}}
    \and
    \R[\textsf{poll}{\uparrow}]
      {\cfill{\Xi}{\Phi}}
      {\cfill{\Xi}{\phantom{\Phi}}}
    % \R[\textsf{wpol}\downarrow]
    %   {\Psi, \cfill{\Xi}{\phantom{\Phi}}}
    %   {\Psi, \cfill{\Xi}{\Psi}}
    % \and
    % \R[\textsf{wpol}\uparrow]
    %   {\Psi, \cfill{\Xi}{\Psi}}
    %   {\Psi, \cfill{\Xi}{\phantom{\Phi}}}
    % \\
    % \R[\textsf{spol}\downarrow]
    %   {\garden{\mathbf{x}}{\Phi, \Psi} \csup \cfill{\Xi}{\phantom{\Phi}} \sep \Delta}
    %   {\garden{\mathbf{x}}{\Phi, \Psi} \csup \cfill{\Xi}{\Psi} \sep \Delta}
    % \and
    % \R[\textsf{spol}\uparrow]
    %   {\garden{\mathbf{x}}{\Phi, \Psi} \csup \cfill{\Xi}{\Psi} \sep \Delta}
    %   {\garden{\mathbf{x}}{\Phi, \Psi} \csup \cfill{\Xi}{\phantom{\Phi}} \sep \Delta}
    \\\\
    % \R[\textsf{epis}\downarrow\textsf{pis}]
    %   {\flower{\garden{\mathbf{x}, \mathbf{y}}{\Psi, \Phi}}{\Delta}}
    %   {\flower{\garden{\mathbf{x}}{(\flower{\garden{{}}{{}}}{\garden{\mathbf{y}}{\Psi}}),
    %   \Phi}}{\Delta}}
    % \and
    % \R[\textsf{epis}\downarrow\textsf{pet}]
    %   {\flower{\gamma}{\garden{\mathbf{x}, \mathbf{y}}{\Psi, \Phi} \sep \Delta}}
    %   {\flower{\gamma}{\garden{\mathbf{x}}{(\flower{\garden{{}}{{}}}{\garden{\mathbf{y}}{\Psi}}), \Phi}
    %   \sep \Delta}}
    % \and
    \R[\textsf{fence}]
      {\flower{\garden{{}}{{}}}{\garden{{}}{\Phi}}}
      {\Phi}
    \\\\
    \R[\textsf{epet}]
      {}
      {\flower{\gamma}{\garden{{}}{{}} \sep \Delta}}
    \and
    \R[\textsf{srep}]
      {\flower{\garden{\mathbf{x}}{\Phi}}{\garden{{}}{\fset{i}{n}{\flower{\gamma_i}{\Delta}}}}}
      {\flower{\garden{\mathbf{x}}{\Phi, (\flower{\garden{{}}{{}}}{\fset{i}{n}{\gamma_i}})}}{\Delta}}
    \\\\
    \R[\textsf{ipis}]
      {(\flower{\garden{\mathbf{x}}{\sigma(\Phi)}}{\sigma(\Delta)}), (\flower{\garden{\mathbf{x}, \mathbf{y}}{\Phi}}{\Delta})}
      {\flower{\garden{\mathbf{x}, \mathbf{y}}{\Phi}}{\Delta}}
    \and
    \R[\textsf{ipet}]
      {\flower{\gamma}{\garden{\mathbf{x}}{\sigma(\Phi)} \sep \garden{\mathbf{x}, \mathbf{y}}{\Phi} \sep \Delta}}
      {\flower{\gamma}{\garden{\mathbf{x}, \mathbf{y}}{\Phi} \sep \Delta}}
  \end{mathpar}

  \vspace{3em}

  {\textsc{Culture} $\Culture$}
  \vspace{1.5em}
  \begin{mathpar}
    \R[\textsf{grow}]
      {\cfill{\Xi^+}{\Phi}}
      {\cfill{\Xi^+}{\phantom{\Phi}}}
    \and
    \R[\textsf{crop}]
      {\cfill{\Xi^-}{\phantom{\Phi}}}
      {\cfill{\Xi^-}{\Phi}}
    \\\\
    \R[\textsf{pull}]
      {\cfill{\Xi^+}{\flower{\gamma}{\Delta}}}
      {\cfill{\Xi^+}{\flower{\gamma}{\delta \sep \Delta}}}
    \and
    \R[\textsf{glue}]
      {\cfill{\Xi^-}{\flower{\gamma}{\delta \sep \Delta}}}
      {\cfill{\Xi^-}{\flower{\gamma}{\Delta}}}
    \\\\
    \R[\textsf{apis}]
      {\cfill{\Xi^+}{\flower{\garden{\mathbf{x}, \mathbf{y}}{\Phi}}{\Delta}}}
      {\cfill{\Xi^+}{\flower{\garden{\mathbf{x}}{\sigma(\Phi)}}{\sigma(\Delta)}}}
    \and
    \R[\textsf{apet}]
      {\cfill{\Xi^-}{\flower{\gamma}{\garden{\mathbf{x}, \mathbf{y}}{\Phi} \sep \Delta}}}
      {\cfill{\Xi^-}{\flower{\gamma}{\garden{\mathbf{x}}{\sigma(\Phi)} \sep \Delta}}}
  \end{mathpar}

  \vspace{3em}

  In the rules \rnmsf{poll{\downarrow}} and \rnmsf{poll{\uparrow}}, we assume that
  $\chyp{\Phi}{\Xi\hole}$.
  
  In the rules \rnmsf{ipis}, \rnmsf{ipet}, \rnmsf{apis}, \rnmsf{apet}, we assume
  some substitution $\sigma : \mathbf{y} \to \terms$.
  \end{framed}
  \caption{Rules of the flower calculus}
  \labfig{flower-calculus}
\end{figure*}

\todo{Graphical version of \reffig{flower-calculus}}

To emphasize this viewpoint, the calculus is presented in
\reffig{flower-calculus} as a set of unary \emph{inference rules}: when read
\emph{top-down}, they correspond to usual inferences from premiss to conclusion,
and will be justified by the soundness theorem of \refsec{Soundness}.
% This gives them a \emph{static}, \emph{a posteriori} meaning, since this is
% typically how you would check the validity of an established inference
% \emph{after the fact}.
But the more interesting direction, and the one around which the calculus has
been designed, is when you read the rules \emph{bottom-up}: then they are indeed
rewrite rules, telling you the different ways in which you can choose to
simplify a goal.

\begin{definition}[Derivation]
  Given a set of rules $\mathsf{R}$, we write $\Phi \step_{\mathsf{R}} \Psi$ to
  indicate a rewrite \emph{step} in $\mathsf{R}$, that is an instance of some
  $\mathsf{r} \in \mathsf{R}$ with $\Psi$ as premiss and $\Phi$ as conclusion.
  The rules of the flower calculus are divided into two sets: the \emph{natural}
  rules $\Nature$, and the \emph{cultural} rules $\Culture$. We just write $\Phi
  \step \Psi$ to mean $\Phi \step_{\Nature\cup\Culture} \Psi$. A
  \emph{derivation} $\Phi \nsteps{n}_{\mathsf{R}} \Psi$ is a sequence of rewrite
  steps $\Phi_0 \step_{\mathsf{R}} \Phi_1 \ldots \step_{\mathsf{R}} \Phi_n$ with
  $\Phi_0 = \Phi$, $\Phi_n = \Psi$ and $n \geq 0$. Generally the length $n$ of
  the derivation does not matter, and we just write $\Phi \steps_R \Psi$.
  Finally, natural derivations are closed under arbitrary contexts: for every
  context $\Xi\hole$, $\Phi \step_\Nature \Psi$ implies $\cfill{\Xi}{\Phi}
  \step_\Nature \cfill{\Xi}{\Psi}$.
\end{definition}

\todo{Use the $\lstep$ notation for local steps}

\begin{definition}[Proof]
  A \emph{proof} of a bouquet $\Phi$ is a derivation $\Phi \steps \emptyset$.
\end{definition}

In Peircean terms, the empty bouquet is the blank sheet of assertion, which as
we have seen in \refsec{EG} can be interpreted as the symbol of \emph{absolute
truth}. Then in our proof construction paradigm, proving a bouquet amounts to
erasing it completely from the sheet of assertion, thus reducing it to absolute
truth.

Now if we want to speak about \emph{relative} truth $\Psi \vdash \Phi$, i.e.
$\Phi$ is true under the assumption that $\Psi$ is, it turns out that the notion
of natural derivability $\Phi \steps_{\Nature} \Psi$ is too weak. Indeed as we
will see in \refsec{Soundness} and \refsec{Completeness}, the natural rules of
the flower calculus are both \emph{invertible} and \emph{complete} for
provability. A consequence of invertibility is that natural derivability is only
able to relate logically equivalent bouquets --- in fact not even all of them
--- which prevents the applicability of the \emph{deduction theorem}
\refthm{deduction}. That is, as soon as $\flower{\Psi}{\Phi}$ is provable but
the converse $\flower{\Phi}{\Psi}$ is not, it will necessarily follow that $\Phi
\not\steps_{\Nature} \Psi$. This problem does not arise if we consider full
derivability $\Phi \steps \Psi$, because of the powerful but non-invertible
cultural rules \rsf{grow} and \rsf{crop}, which correspond respectively to the
\emph{insertion} and \emph{erasure} rules of Peirce's EG. These rules are also
included in the intuitionistic EG system of Minghui and Pietarinen
\sidecite{minghui_graphical_2019}, and thus the authors are able to prove a
deduction theorem for their derivability relation.

A trivial way to circumvent this is to define directly $\Psi \vdash \Phi$ as
$\flower{\garden{{}}{\Psi}}{\garden{{}}{\Phi}} \steps \emptyset$. In fact this
is closer to what one would find in sequent calculus, where hypothetical proofs
are closed derivations of hypothetical sequents, not open derivations. The
difference is that sequents capture only the implicative structure of logic,
while flowers capture the full structure of first-order intuitionistic logic.
This allows for a nice generalization of the notion of hypothetical provability,
which will be useful in the completeness proof of \refsec{Completeness}. 

\begin{definition}[Hypothetical provability]
  Given two bouquets $\Phi, \Psi$, we say that $\Phi$ is \emph{hypothetically
  provable} from $\Psi$ in a fragment $\mathsf{R}$ of rules, written $\Psi
  \vdash_{\mathsf{R}} \Phi$, if for every context $\Xi\hole$ such that
  $\chyp{\Psi}{\Xi\hole}$, $\cfill{\Xi}{\Phi} \steps_{\mathsf{R}}
  \cfill{\Xi}{\phantom{\Phi}}$. We write $\Psi \vdash \Phi$ to denote
  hypothetical provability in the full flower calculus.
\end{definition}

\begin{lemma}[Reflexivity]\lablemma{reflexivity}
  For any bouquet $\Phi$, $\Phi \vdash \Phi$.
\end{lemma}
\begin{proof}
  For any context $\Xi\hole$ such that $\chyp{\Phi}{\Xi\hole}$, one has the following
  derivation:
  $$
  \cfill{\Xi}{\Phi} \step_{\mathsf{poll{\downarrow}}}
  \cfill{\Xi}{\phantom{\Phi}}
  $$
\end{proof}

There is a subtle but important shift here with respect to the standard notions
of hypothetical provability, as found in Gentzen systems or type theories: while
in these settings it is characterized as the existence of a proof for a
\emph{single} hypothetical judgment $\Gamma \vdash C$ which constrains the space
of derivations, here we have the stronger requirement that there exist proofs
for a \emph{class} of judgments $\cfill{\Xi}{\Phi}$, whose hypothetical shape
comes from the condition that $\chyp{\Psi}{\Xi\hole}$. In practice, the
pollination rules $\{\text{\rnmsf{poll{\downarrow}}},
\text{\rnmsf{poll{\uparrow}}}\}$ and the {\rnmsf{fence}} rule make this equivalent
to the existence of a proof for $\flower{\garden{{}}{\Psi}}{\garden{{}}{\Phi}}$. But
we conjecture that the {\rnmsf{fence}} rule might be admissible modulo the
addition of the following distributivity rule:
$$
\R[\textsf{wrep}]
  {\flower{\gamma}{\fset{i}{n}{\garden{\mathbf{x_i}}{\Phi_i, \Psi}}}}
  {(\flower{\gamma}{\fset{i}{n}{\garden{\mathbf{x_i}}{\Phi_i}}}), \Psi}
$$
Thus our stronger notion of hypothetical provability makes more sense in the
variant $\Nature \setminus \{\rsf{fence}\} \cup \{\rsf{wrep}\}$ of the flower
calculus, although it will still be useful in this work to make meta-theoretical
proofs slightly shorter. For now we allow the {\rnmsf{fence}} rule, which makes
the deduction theorem trivial:

\begin{theorem}[Deduction]\labthm{deduction}
  For any pair $\Phi, \Psi$ of bouquets, $\Psi \vdash_{\Nature} \Phi$ if and only if
  $\vdash_{\Nature} \flower{\garden{{}}{\Psi}}{\garden{{}}{\Phi}}$.
\end{theorem}
\begin{proof}
  Let $\Xi\hole$ be some context. If $\Psi \vdash_{\Nature} \Phi$, then in particular
  $\cfill{\Xi'}{\Phi} \steps_{\Nature} \cfill{\Xi'}{\phantom{\Phi}}$ for $\Xi'\hole :=
  \cfill{\Xi}{\flower{\garden{{}}{\Psi}}{\garden{{}}{\square}}}$. Thus we have:
  $$
  \cfill{\Xi}{\flower{\garden{{}}{\Psi}}{\garden{{}}{\Phi}}} \steps_{\Nature}
  \cfill{\Xi}{\flower{\garden{{}}{\Psi}}{\garden{{}}{}}} \step_{\mathsf{epet}}
  \cfill{\Xi}{\phantom{\Phi}}
  $$
  In the other direction, let $\Xi$ be some context such that
  $\chyp{\Psi}{\Xi\hole}$. If $\vdash_{\Nature}
  \flower{\garden{{}}{\Psi}}{\garden{{}}{\Phi}}$, then in particular
  $\cfill{\Xi}{\flower{\garden{{}}{\Psi}}{\garden{{}}{\Phi}}} \steps_{\Nature}
  \cfill{\Xi}{\phantom{\Phi}}$. Thus we have:
  $$
  \cfill{\Xi}{\Phi} \step_{\mathsf{fence}}
  \cfill{\Xi}{\flower{\garden{{}}{{}}}{\garden{{}}{\Phi}}} \step_{\mathsf{poll{\uparrow}}}
  \cfill{\Xi}{\flower{\garden{{}}{\Psi}}{\garden{{}}{\Phi}}} \steps_{\Nature}
  \cfill{\Xi}{\phantom{\Phi}}
  $$
\end{proof}


\section{Kripke Semantics}\labsec{Semantics}

\todo{ give a direct Kripke semantics to flowers, avoiding the need for
translations to and from traditional formulas. This will be crucial to get a
strong completeness theorem.}

\begin{definition}[First-order structure]
  A \emph{first-order structure} is a pair $( M, \interp{\cdot} )$
  where $M$ is a non-empty set, and $\interp{\cdot}$ is a map called the
  \emph{interpretation} that associates to each function symbol $f \in \fsymbs$
  a function $\interp{f} : M^{\arity(f)} \to M$, and to each predicate symbol $p
  \in \psymbs$ a relation $\interp{p} \subseteq M^{\arity(p)}$.
\end{definition}

\begin{definition}[Kripke structure]
  A \emph{Kripke Structure} is a triplet $\mathcal{K} = ( W, \access,
  (M_w)_{w \in W} )$, where $W$ is the set of \emph{worlds}, $\access$ is
  a pre-order on $W$ called \emph{accessibility}, and $(M_w)_{w \in W}$ is a
  family of first-order structures indexed by $W$. Furthermore, we require the
  following monotonicity conditions to hold whenever $w \access w'$:
  \begin{itemize}
    \item $M_w \subseteq M_{w'}$;
    \item for every $f \in \fsymbs$, $\interp{f}_w \subseteq
      \interp{f}_{w'}$;
    \item for every $p \in \psymbs$, $\interp{p}_w \subseteq
      \interp{p}_{w'}$.
  \end{itemize}
\end{definition}

\begin{definition}[$w$-evaluation]
  Given a Kripke structure $\mathcal{K}$ and a world $w$ in $\mathcal{K}$, a
  \emph{$w$-evaluation} is a function $e : \vars \to M_w$.
  % We write $e : \mathbf{x} \to M_w$ if $e(x) = \ast$ for every $x \not\in
  % \mathbf{x}$ and some distinguished element $\ast \in M_w$.
  The interpretation map of $M_w$ is extended to terms with respect to any
  evaluation $e$ as follows:
  \begin{align*}
  \interp{x}_e &= e(x) \\
  \interp{f(\tvec{t})}_e &= \interp{f}_w(\interp{\tvec{t}}_e)
  % \interp{p(t_1, \ldots, t_n)}_e &~\text{iff}~ (\interp{t_1}_e, \ldots, \interp{t_n}_e) \in \interp{p}_w \\
  \end{align*}
\end{definition}

\begin{definition}[Forcing]\labdef{forcing}

  Given some Kripke structure $\mathcal{K}$, the \emph{forcing} relation
  $\eforces{w}{\phi}{e}$ between a world $w$, a flower $\phi$ and a
  $w$-evaluation $e$ is defined by induction on $\phi$ as follows:
  \begin{itemize}
    \item $\eforces{w}{p(\tvec{t})}{e}$ iff $\interp{\tvec{t}}_e \in \interp{p}_w$;
    \item
    $\eforces{w}{\flower{\garden{\mathbf{x}}{\Phi}}{\fset{i}{n}{\garden{\mathbf{x}_i}{\Phi_i}}}}{e}$ iff for every $w' \geq
    w$ and every $w'$-evaluation $e'$, if
    $\eforces{w'}{\Phi}{\update{e}{\mathbf{x}}{e'}} $ then there is some $1
    \leq i \leq n$ and $w'$-evaluation $e''$ such that
    $\eforces{w'}{\Phi_i}{\update{\update{e}{\mathbf{x}}{e'}}{\mathbf{x}_i}{e''}}$;
    \item $\eforces{w}{\Phi}{e}$ iff $\eforces{w}{\phi}{e}$ for every $\phi \in
    \Phi$.
  \end{itemize}
  We write $w \forces \Phi$ if $\eforces{w}{\Phi}{e}$ for every $w$-evaluation
  $e$.
\end{definition}

\begin{lemma}\lablemma{closed-forcing}
  
  For any closed flower $\phi \in \closed{\flowers}$ and $w$-evaluations $e,
  e'$, if $\eforces{w}{\phi}{e}$ then $\eforces{w}{\phi}{e'}$.
\end{lemma}
\begin{proof}
  By a straightforward induction on $\phi$.
\end{proof}

% \begin{corollary}[Closed forcing]
  
%   For any closed flower $\phi \in \closed{\flowers}$, $w \forces \phi$ iff
%   $\eforces{w}{\phi}{e}$ for some $w$-evaluation $e$.
% \end{corollary}

\begin{definition}[Semantic entailment]
  Let $\mathcal{K}$ be a Kripke structure, and $\Phi, \Psi$ some bouquets. We
  say that $\Phi$ \emph{entails} $\Psi$ in $\mathcal{K}$, written $\Phi
  \vDash_{\mathcal{K}} \Psi$, when $\eforces{w}{\Phi}{e}$ implies
  $\eforces{w}{\Psi}{e}$ for every world $w \in W$ and $w$-evaluation $e$. This
  entailment is \emph{valid} if it holds for any Kripke structure $\mathcal{K}$,
  and in that case we simply write $\Phi \vDash \Psi$.
\end{definition}


\section{Soundness}\labsec{Soundness}

\todo{ show that all the rules of the flower calculus are valid with respect to
our Kripke semantics.}

\begin{lemma}[Natural soundness]
  If $\Phi \step_\Nature \Psi$, then $\Phi \sequiv \Psi$.
\end{lemma}


\section{Completeness}\labsec{Completeness}

\todo{ show that a restricted, invertible fragment of the flower calculus is
complete with respect to our Kripke semantics. Combined with soundness, this
gives us for free the admissibility of all the other rules, in particular the
ones corresponding to the \emph{insertion} and \emph{erasure} rules of Peirce's
EG. A corollary is that the flower calculus is \emph{analytic}, in a sense very
close to that coined by Gentzen.}

\todo{Reference literature on semantic cut-elimination (Completeness folder in
Zotero), with special props to Olivier Hermant \cite{hutchison_semantic_2005}
who gave us the main structure for the various definitions and lemmas exposed in
this section.}

\subsection{Theories}

\begin{definition}[Theory]\labdef{theory} 
  
  Any set $\tT \subseteq \flowers$ of flowers is called a \emph{theory}. In
  particular, a bouquet can be regarded as a finite theory, by forgetting the
  number of repetitions of its elements. We say that a bouquet $\Phi$ is
  \emph{provable from} a theory $\tT$, written $\tT \vdash \Phi$, if there exists a
  bouquet $\Psi \subseteq \tT$ such that $\Psi \vdash \Phi$. Given a Kripke
  structure $\mathcal{K}$, a world $w$ in $\mathcal{K}$ and a $w$-evaluation
  $e$, we say that $\tT$ is \emph{forced} by $w$ under $e$, written
  $\eforces{w}{\tT}{e}$, if $\eforces{w}{\phi}{e}$ for all $\phi \in \tT$. Then
  $\Phi$ is a \emph{consequence} of $\tT$, written $\tT \vDash_{\mathcal{K}} \Phi$,
  if $\eforces{w}{\tT}{e}$ implies $\eforces{w}{\Phi}{e}$ for every world $w$ in
  $\mathcal{K}$ and $w$-evaluation $e$.
\end{definition}

\begin{lemma}[Weakening]\lablemma{weakening}
  If $\tT \subseteq \tT'$ and $\tT \vdash \phi$, then $\tT' \vdash \phi$.
\end{lemma}
\begin{proof}
  This follows immediately from our definition of provability from a theory
  (\refdef{theory}).
\end{proof}

\begin{definition}[$\psi$-consistency]
  A theory $\tT$ is \emph{$\psi$-consistent} when $\tT \nvdash_\Nature \psi$.
\end{definition}

\begin{definition}[$\psi$-completeness]
  A theory $\tT$ is \emph{$\psi$-complete} when for all $\phi \in \flowers$,
  either $\tT, \phi \vdash_\Nature \psi$ or $\phi \in \tT$.
\end{definition}

% \begin{definition}[$\psi$-Henkin]
%   A theory $T$ is \emph{$\psi$-Henkin} when for all $\phi =
%   \flower{\garden{\mathbf{x}}{\Phi}}{\garden{\mathbf{x}_1}{\Phi_1} \sep \ldots
%   \sep \garden{\mathbf{x}_n}{\Phi_n}} \in T$ and $\sigma : \mathbf{x} \to
%   \closed{\terms}$, if $T, \sigma(\Phi) \nvdash \psi$ then there are some $1
%   \leq i \leq n$ and $\sigma_i : \mathbf{x}_i \to \closed{\terms}$ such that
%   $\sigma_i \circ \sigma(\Phi_i) \subseteq T$.
% \end{definition}

\subsection{Completion}

In the following, we suppose some enumeration $(\phi_n)_{n \in \nats}$ of
$\flowers$, which should be definable constructively given the
inductive nature of flowers (\refdef{flowers}).

Let $\psi \in \flowers$, and $\tT$ a $\psi$-consistent theory. We now
define a \emph{completion} procedure which constructs an extension
$\completion{\tT} \supseteq \tT$ with the property that $\completion{\tT}$ is
$\psi$-consistent and $\psi$-complete.

\begin{definition}[$n$-completion]
  The \emph{$n$-completion} $\ncompletion{\tT}{n}$ of $\tT$ is defined recursively
  as follows:
  \begin{align*}
    \ncompletion{\tT}{0} &= \tT \\
    \ncompletion{\tT}{n+1} &=
    \begin{cases}
      \ncompletion{\tT}{n} \cup \phi_n &\text{if $\ncompletion{\tT}{n} \cup \phi_n$ is $\psi$-consistent} \\
      \ncompletion{\tT}{n} &\text{otherwise}
    \end{cases}
  \end{align*}
\end{definition}

\begin{definition}[Completion]
  The \emph{completion} $\completion{\tT}$ of $\tT$ is the denumerable union of all
  $n$-completions:
  $$\completion{\tT} = \bigcup_{n \in \nats}{\ncompletion{\tT}{n}}$$
\end{definition}

\begin{lemma}\lablemma{completion-consistent}
  $\completion{\tT}$ is $\psi$-consistent.
\end{lemma}
\begin{proof}
  It is immediate by recurrence on $n$ that $\ncompletion{\tT}{n}$ is
  $\psi$-consistent. Then suppose that $\completion{\tT} \vdash_\Nature \psi$,
  that is there is some bouquet $\Phi \subseteq \completion{\tT}$ such that $\Phi
  \vdash_\Nature \psi$. For each $\phi \in \Phi$, there is some rank $n$ such
  that $\phi \in \ncompletion{\tT}{n}$. Let $m$ be the greatest such rank. Then
  $\Phi \subseteq \ncompletion{\tT}{m}$, and thus by weakening
  (\reflemma{weakening}) $\Phi \nvdash_\Nature \psi$. Contradiction.
\end{proof}


\begin{lemma}\lablemma{completion-complete}
  $\completion{\tT}$ is $\psi$-complete.
\end{lemma}
\begin{proof}
  Suppose that there is some $\phi$ such that $\completion{\tT}, \phi
  \nvdash_\Nature \psi$ and $\phi \not\in \completion{\tT}$, and let $\phi =
  \phi_n$. Then $\completion{\tT} \cup \phi_n$ is $\psi$-consistent, and thus by
  weakening (\reflemma{weakening}) so is $\ncompletion{\tT}{n} \cup \phi_n$. This
  entails that $\phi_n \in \ncompletion{\tT}{n+1} \subseteq \completion{\tT}$.
  Contradiction.
\end{proof}

\subsection{Adequacy}

We now define the so-called \emph{universal Kripke structure} $\rewolF{\psi}$
relative to a flower $\psi$, which will satisfy the property that $\Phi
\vDash_{\rewolF{\psi}} \Psi$ implies $\Phi \vDash \Psi$ for any $\psi$.

\begin{definition}[Universal Kripke structure]\labdef{kcanon}
  Let $\psi \in \flowers$. The \emph{universal Kripke structure}
  $\rewolF{\psi}$ has:
  \begin{itemize}
    \item The set of $\psi$-consistent and $\psi$-complete theories as its worlds;
    \item Set inclusion as its accessibility relation;
    \item For each world $\tT$, a first-order structure whose domain is the set of
    terms $\terms$, and whose interpretation map is given by:
      \begin{itemize}
        \item $\interp{f}(\tvec{t}) = f(\tvec{t})$
        \item $\interp{p} = \compr{\tvec{t}}{p(\tvec{t}) \in \tT}$
      \end{itemize}
  \end{itemize}
  One can easily check that the monotonicity conditions of Kripke structures
  hold for $\rewolF{\psi}$.
\end{definition}

% \newcommand{\ids}{\update{\idsubst}{\mathbf{x}}{\sigma}}
\begin{proposition}\labprop{inv-elem-flower}
  
  Let $\psi \in \flowers$, $\tT$ some $\psi$-consistent and $\psi$-complete
  theory, and $\phi = \flower{\garden{\mathbf{x}}{\Phi}}{\Delta}$ with $\Delta
  = \fset{i}{n}{\delta_i} = \fset{i}{n}{\garden{\mathbf{x}_i}{\Phi_i}}$ such
  that $\phi \in \tT$. Then for every substitution $\sigma : \mathbf{x} \to
  \terms$, either $\sigma(\Phi_i) \subseteq \tT$ for some $1 \leq i \leq n$, or $\tT
  \nvdash_\Nature \sigma(\Phi)$.
\end{proposition}
\begin{proof}
  Suppose the contrary, i.e. there is a substitution $\sigma$ such that $\tT
  \vdash_\Nature \sigma(\Phi)$ and for all $1 \leq i \leq n$, there is some
  \Hyp{$\phi_i \in \Phi_i$}~{\HOne} such that $\sigma(\phi_i) \not\in \tT$. Thus
  by $\psi$-completeness of $\tT$, we get $\tT, \sigma(\phi_i) \vdash_\Nature
  \psi$. So there are $\Psi \subseteq \tT$ and $\Psi_i \subseteq \tT \cup
  \sigma(\phi_i)$ such that \Hyp{$\Psi \vdash_\Nature \sigma(\Phi)$}~{\HTwo} and
  \Hyp{$\Psi_i \vdash_\Nature \psi$}~{\HThree}. Now it cannot be the case that
  $\Psi_i \subseteq \tT$, otherwise by weakening and $\psi$-consistency of $\tT$
  we would have $\Psi_i \nvdash_\Nature \psi$. So there must exist $\Psi_i'
  \subseteq \tT$ such that \Hyp{$\Psi_i = \Psi_i' \cup
  \sigma(\phi_i)$}~{\HFour}. Again by weakening and $\psi$-consistency of $\tT$,
  we get $\Psi, \bigcup_{i = 1}^{n}{\Psi_i'}, \phi \nvdash_\Nature \psi$. Now we
  derive a contradiction by showing $\Psi, \bigcup_{i = 1}^{n}{\Psi_i'}, \phi
  \vdash_\Nature \psi$. Let $\Xi$ be a context such that \Hyp{$\chyp{\Psi,
  \bigcup_{i = 1}^{n}{\Psi_i'}, \phi}{\Xi}$}~{\HFive}. Then $\cfill{\Xi}{\psi}
  \steps_\Nature \cfill{\Xi}{\phantom{\Phi}}$ with the following derivation:
  $$
  \begin{array}{rlll}
    \cfill{\Xi}{\psi}
    &\step_{\mathsf{fence}} &\cfill{\Xi}{\flower{\garden{{}}{{}}}{\garden{{}}{\psi}}} & \\
    &\step_{\mathsf{poll{\uparrow}}} &\cfill{\Xi}{\flower{\garden{{}}{\phi}}{\garden{{}}{\psi}}} &\text{(\HFive)} \\
    &\step_{\mathsf{ipis}} &\cfill{\Xi}{\flower{\garden{{}}{(\flower{\garden{}{\sigma(\Phi)}}{\sigma(\Delta)}), \phi}}{\garden{{}}{\psi}}} & \\
    &\step_{\mathsf{poll{\downarrow}}} &\cfill{\Xi}{\flower{\garden{{}}{(\flower{\garden{}{{}}}{\sigma(\Delta)}), \phi}}{\garden{{}}{\psi}}} &\text{(\HTwo, \HFive)} \\
    &\step_{\mathsf{srep}} &\cfill{\Xi}{\flower{\garden{{}}{\phi}}{\garden{{}}{\fset{i}{n}{\flower{\sigma(\delta_i)}{\garden{{}}{\psi}}}}}} & \\
    &= &\cfill{\Xi}{\flower{\garden{{}}{\phi}}{\garden{{}}{\fset{i}{n}{\flower{\garden{\mathbf{x}_i}{\sigma(\Phi_i)}}{\garden{{}}{\psi}}}}}} & \\
    &\nsteps{n}_{\mathsf{poll}{\downarrow}} &\cfill{\Xi}{\flower{\garden{{}}{\phi}}{\garden{{}}{\fset{i}{n}{\flower{\garden{\mathbf{x}_i}{\sigma(\Phi_i)}}{\garden{{}}{{}}}}}}} &\text{(\HOne, \HThree, \HFour, \HFive)} \\
    &\nsteps{n}_{\mathsf{epet}} &\cfill{\Xi}{\flower{\garden{{}}{\phi}}{\garden{{}}{{}}}} & \\
    &\step_{\mathsf{epet}} &\cfill{\Xi}{\phantom{\Phi}} &
    % &\steps_{\mathsf{ipis}} &\cfill{\Xi}{\flower{\garden{{}}{\phi}}{\garden{{}}{(\flower{\garden{}{\sigma_1 \circ \sigma(\Phi_1)}}{\garden{{}}{\psi}}), (\flower{\garden{\mathbf{x}_1}{\sigma(\Phi_1)}}{\garden{{}}{\psi}}), \ldots, \\
    % && \qquad\quad~~\, (\flower{\garden{{}}{\sigma_n \circ \sigma(\Phi_n)}}{\garden{{}}{\psi}}), (\flower{\garden{\mathbf{x}_n}{\sigma(\Phi_n)}}{\garden{{}}{\psi}})}}} \\
    % &\steps_{\mathsf{poll{\downarrow}}} &\cfill{\Xi}{\flower{\garden{{}}{\phi}}{\garden{{}}{(\flower{\garden{}{\sigma_1 \circ \sigma(\Phi_1)}}{\garden{{}}{\phantom{\Phi}}}), (\flower{\garden{\mathbf{x}_1}{\sigma(\Phi_1)}}{\garden{{}}{\psi}}), \ldots, \\
    % && \qquad\quad~~\, (\flower{\garden{{}}{\sigma_n \circ \sigma(\Phi_n)}}{\garden{{}}{{}}}), (\flower{\garden{\mathbf{x}_n}{\sigma(\Phi_n)}}{\garden{{}}{\psi}})}}} \\
  \end{array}
  $$
\end{proof}

\begin{proposition}\labprop{inv-deriv-flower}
  
  Let $\psi \in \flowers$, $\tT$ some $\psi$-consistent and $\psi$-complete
  theory, and $\phi = \flower{\garden{\mathbf{x}}{\Phi}}{\Delta}$ with $\Delta
  = \fset{i}{n}{\delta_i} = \fset{i}{n}{\garden{\mathbf{x}_i}{\Phi_i}}$ such
  that $\tT \nvdash_\Nature \phi$. Then for every $1 \leq i \leq n$ and substitution
  $\sigma : \mathbf{x_i} \to \terms$, there is some $\phi_i \in \Phi_i$ such
  that $\tT, \Phi \nvdash_\Nature \sigma(\phi_i)$.
\end{proposition}
\begin{proof}
  Suppose the contrary, i.e. there are some $1 \leq i \leq n$ and $\sigma :
  \mathbf{x}_i \to \terms$ such that $\tT, \Phi \vdash_\Nature \sigma(\Phi_i)$.
  Therefore there must exist $\Psi \subseteq \tT$ and \Hyp{$\Phi_0 \subseteq
  \Phi$}~{\HOne} such that \Hyp{$\Psi, \Phi_0 \vdash_\Nature
  \sigma(\Phi_i)$}~{\HTwo}. By hypothesis, for every $\Phi' \subseteq \tT$ there
  is a context $\Xi$ such that $\chyp{\Phi'}{\Xi}$ and $\cfill{\Xi}{\phi}
  \notsteps_\Nature \cfill{\Xi}{\phantom{\Phi}}$. We now derive a contradiction
  by showing $\cfill{\Xi}{\phi} \steps_\Nature \cfill{\Xi}{\phantom{\Phi}}$ for
  all $\Xi$ such that \Hyp{$\chyp{\Psi}{\Xi}$}~{\HThree}:
  $$
  \begin{array}{rlll}
    \cfill{\Xi}{\phi}
    &\step_{\mathsf{ipet}} &\cfill{\Xi}{\flower{\garden{\mathbf{x}}{\Phi}}{\garden{{}}{\sigma(\Phi_i)} \sep \Delta}} & \\
    &\step_{\mathsf{poll}{\downarrow}} &\cfill{\Xi}{\flower{\garden{\mathbf{x}}{\Phi}}{\garden{{}}{{}} \sep \Delta}} &\text{(\HOne, \HTwo, \HThree)} \\
    &\step_{\mathsf{epet}} &\cfill{\Xi}{\phantom{\Phi}} &
  \end{array}
  $$
\end{proof}

\begin{lemma}[Adequacy]\lablemma{adequacy}

  Let $\phi, \psi \in \flowers$, $\tT$ a $\psi$-consistent and $\psi$-complete
  theory, and $\sigma$ a subtitution such that $\fv(\sigma(x)) \cap \bv(\phi) =
  \emptyset$ for any variable $x$. Then
  \begin{enumerate*}
    \item $\sigma(\phi) \in \tT$ implies $\eforces{\tT}{\phi}{\sigma}$, and
    \item $\tT \nvdash_\Nature \sigma(\phi)$ implies $\neforces{\tT}{\phi}{\sigma}$
  \end{enumerate*}.
\end{lemma}
\begin{proof}
  By induction on $\phi$.
  \begin{itemize}
    \item Suppose $\phi = p(\tvec{t})$.
    \begin{enumerate}
      \item By definition of forcing (\refdef{forcing}) and $\rewolF{\psi}$
      (\refdef{kcanon}), $\eforces{\tT}{p(\tvec{t})}{\sigma}$ precisely when
      $\sigma(p(\tvec{t})) \in \tT$.
      \item Suppose that $\eforces{\tT}{\phi}{\sigma}$, that is $\sigma(\phi) \in
      \tT$. Then by weakening, we get $\sigma(\phi) \nvdash_\Nature \sigma(\phi)$.
      But this is impossible by reflexivity of $\vdash$
      (\reflemma{reflexivity}).
    \end{enumerate}
    \item Suppose $\phi =
    \flower{\garden{\mathbf{x}}{\Phi}}{\fset{i}{n}{\garden{\mathbf{x_i}}{\Phi_i}}}$.
    \begin{enumerate}
      \item Let $\tU \supseteq \tT$ be a $\psi$-consistent and $\psi$-complete
      theory. Obviously $\sigma(\phi) =
      \flower{\garden{\mathbf{x}}{\restr{\sigma}{\mathbf{x}}(\Phi)}}{\fset{i}{n}{\garden{\mathbf{x}_i}{\restr{\sigma}{\mathbf{x}
      \cup \mathbf{x}_i}(\Phi_i)}}} \in \tU$, and thus by
      \refprop{inv-elem-flower}, for every substitution $\tau$, either $
      \update{}{\mathbf{x}}{\tau} \circ \restr{\sigma}{\mathbf{x} \cup
      \mathbf{x}_i}(\Phi_i) =
      \update{\update{\sigma}{\mathbf{x}}{\tau}}{\mathbf{x}_i}{}(\Phi_i)
      \subseteq \tU$ for some $1 \leq i \leq n$, or $\tU \nvdash_\Nature
      \update{}{\mathbf{x}}{\tau} \circ \restr{\sigma}{\mathbf{x}}(\Phi) =
      \update{\sigma}{\mathbf{x}}{\tau}(\Phi)$. In the first case, we get
      $\eforces{\tU}{\Phi_i}{\update{\update{\sigma}{\mathbf{x}}{\tau}}{\mathbf{x}_i}{}}$
      by induction hypothesis. In the second case, we get
      $\neforces{\tU}{\Phi}{\restr{\sigma}{\mathbf{x}}\tau}$ by induction
      hypothesis. In other words,
      $\eforces{\tU}{\Phi}{\restr{\sigma}{\mathbf{x}}\tau}$ implies
      $\eforces{\tU}{\Phi_i}{\update{\update{\sigma}{\mathbf{x}}{\tau}}{\mathbf{x}_i}{}}$,
      that is $\eforces{\tT}{\phi}{\sigma}$.
      \item By \refprop{inv-deriv-flower}, for every $1 \leq i \leq n$ and
      substitution $\tau$, there is some $\phi_i \in \Phi_i$ such that $\tT,
      \restr{\sigma}{\mathbf{x}}(\Phi) \nvdash_\Nature
      \update{}{\mathbf{x}_i}{\tau} \circ \restr{\sigma}{\mathbf{x} \cup
      \mathbf{x}_i}(\phi_i) =
      \update{\update{\sigma}{\mathbf{x}}{}}{\mathbf{x}_i}{\tau}(\phi_i)$. By
      the completion procedure, we get a theory $\tU = \completion{\tT \cup
      \restr{\sigma}{\mathbf{x}}(\Phi)} \supseteq \tT \cup
      \restr{\sigma}{\mathbf{x}}(\Phi)$ which is both
      $\update{\update{\sigma}{\mathbf{x}}{}}{\mathbf{x}_i}{\tau}(\phi_i)$-consistent
      and
      $\update{\update{\sigma}{\mathbf{x}}{}}{\mathbf{x}_i}{\tau}(\phi_i)$-complete.
      Then by induction hypothesis,
      $\eforces{\tU}{\Phi}{\update{\sigma}{\mathbf{x}}{}}$ since
      $\update{\sigma}{\mathbf{x}}{}(\Phi) \subseteq \tU$, and
      $\neforces{\tU}{\phi_i}{\update{\update{\sigma}{\mathbf{x}}{}}{\mathbf{x}_i}{\tau}}$
      since $\tU$ is
      $\update{\update{\sigma}{\mathbf{x}}{}}{\mathbf{x}_i}{\tau}(\phi_i)$-consistent,
      that is $\neforces{\tT}{\phi}{\sigma}$.
    \end{enumerate}
  \end{itemize}
\end{proof}

\begin{lemma}\lablemma{completeness-contra}
  
  Let $\psi \in \closed{\flowers}$ and $\tT$ be a $\psi$-consistent closed theory,
  that is every $\phi \in \tT$ is closed. Then $\tT \nvDash \psi$.
\end{lemma}
\begin{proof}
  We show $\tT \nvDash_{\rewolF{\psi}} \psi$, and more specifically that there is
  some substitution $\sigma$ such that $\eforces{\completion{\tT}}{\tT}{\sigma}$ but
  $\neforces{\completion{\tT}}{\psi}{\sigma}$. Let $\sigma \triangleq
  \update{}{\bv(\psi)}{\cstsubst{z}}$ for some fresh variable $z \not\in
  \bv(\psi)$, where $\cstsubst{z}$ is the constant substitution that always maps
  to $z$.
  \begin{itemize}
    \item Let $\phi \in \tT$, and $\tau = \update{}{\bv(\phi)}{\cstsubst{z'}}$ for
    some fresh variable $z' \not\in \bv(\phi)$. It is obviously the case that
    $\tau(\phi) = \phi$ since $\phi$ is closed, and $\fv(\tau(x)) \cap \bv(\phi)
    = \emptyset$ for any variable $x$. Then $\phi \in \completion{\tT}$, thus by
    $\psi$-consistency (\reflemma{completion-consistent}) and
    $\psi$-completeness (\reflemma{completion-complete}) of the completion, one
    can apply adequacy (\reflemma{adequacy}) to get
    $\eforces{\completion{\tT}}{\phi}{\tau}$. Hence
    $\eforces{\completion{\tT}}{\phi}{\sigma}$ by \reflemma{closed-forcing}.
    \item By the same argument for $\tau$ transposed to $\sigma$, we can apply
    adequacy (\reflemma{adequacy}) to get
    $\neforces{\completion{\tT}}{\psi}{\sigma}$.
  \end{itemize}
\end{proof}

We get completeness as a direct corollary of \reflemma{completeness-contra}, in
the case where $\tT = \emptyset$:

\begin{theorem}[Completeness]
  For any closed flower $\phi$, $\vDash \phi$ implies $\vdash_\Nature \phi$.
\end{theorem}


\section{Automated proof search}\labsec{flowers-search}

\todo{ describe an algorithm for fully automated proof search in the
propositional fragment of the flower calculus, exploiting both its analyticity
and invertibility. The procedure is conjectured to be complete for provability.}


\section{The Flower Prover}\labsec{flowers-prover}

\todo{ give an overview of the Flower Prover, a prototype of GUI in the
Proof-by-Action paradigm whose actions map directly to the rules of the flower
calculus. We also explain how the user can opt in and out of various levels of
automation based on our search procedure, similarly to what was described for
the invertible bubble calculus of \refsec{invertible-calculus}.}


\section{Towards a Curry-Howard correspondence}\labsec{flowers-curryhoward}

\todo{ briefly sketch some ideas for a Curry-Howard correspondence, where
flowers and actions for manipulating them are identified respectively with
\emph{normal} and \emph{neutral} terms of the $\lambda$-calculus. }


\section{Conclusion}\labsec{Conclusion}

\todo{ conclude by a comparison with some related works, and a discussion of
future works and applications that we envision.}

\subsection{Related works}

\begin{description}
  \item[Focusing proof search]
    \begin{itemize}
      \item Iteration/Pollination rule = Absorption rule of focused sequent
        calculus \sidecite{andreoli_logic_1992}.
      \item Geometric formulas and synthetic rules (Sonia Marin)
    \end{itemize}
  \item[Normal forms of formulas]
    \begin{itemize}
      \item Geometric formulas (again)
      \item The exponential normal form of Ilik based on Tarski's highschool
  identities \sidecite{nannestad_intuitionistic_2019}. Notice the opposite
  tradeoff compared to the flower calculus: fully \emph{non}-invertible, but
  linear rules (and both are applicable deeply). The authors also noticed the
  connection with geometric formulas and deep inference.
    \end{itemize} 
\end{description}

It should be noted that Peirce did not think of EG as a calculus that could aid
in performing reasoning \emph{per se}, but rather as a tool for analysing the
finer structure of logical endeavor\sidenote{Citing \cite{Roberts+1973} pp.
110-111: \textit{``[...] the purpose which the system was designed to fulfill
was ``to enable us to separate reasoning into its smallest steps so that each
one may be examined by itself'' (Ms 455, p. 2). The aim was not to facilitate
reasoning, but to facilitate the study of reasoning.''}}.

\todo{ explain how we depart from this conception, i.e. by focusing on iteration
(and more generally invertible) rules instead of insertion/erasure rules (which
are even shown to be admissible!), and replacing lines of identity by the more
complex apparatus of substitution. Which explains why we believe \emph{the
opposite}, that EG \emph{can} form the basis for an ergonomic calculus.}

\subsection{Future works}

\begin{itemize}
  \item Strong deduction theorem for derivability in the full flower calculus.
  Combined with our completeness result (of the natural fragment, and a forciori
  of the full system), this would give strong completeness of the full system.
\end{itemize}