% !TEX root =index.tex
\setchapterpreamble[u]{\margintoc}
\chapter{Symmetric Bubble Calculi}
\labch{bubbles-symm}

\epigraph{Each city receives its form from the desert it opposes; and so the
camel driver and the sailor see Despina, a border city between two
deserts.}{\textbf{Italo Calvino}, \textit{Invisible Cities}, 1972}


\begin{scope}\knowledgeimport{bubble}


In this chapter, we explore to what extent the \kl{bubble calculus} of
\refch{bubbles} can be made more \emph{symmetric}, by relaxing the restriction
that \kl{solutions} must contain at most one conclusion. At a surface level, our
approach is similar to that of Gentzen, who went from his single-conclusion
\kl{sequent calculus} \kl{LJ} to the multi-conclusion calculus \kl{LK}. Like
him, we will uncover beautiful dualities that were hidden by the asymmetry of
the initial calculus. But by sticking unwaveringly to intuitionism, we will be
led to the exotic territory of \kl{bi-intuitionistic} logic, an intermediate
logic that conservatively extends \kl{intuitionistic} logic, but does not prove
the \kl{law of excluded middle}. An underlying thread of our investigation will
be the quest for a \emph{fully \kl{iconic}} \kl{proof system}, where all logical
connectives can be replaced by appropriate (new) kinds of bubbles. This will
lead us to rediscover many principles already studied in the \kl{deep inference}
literature, with topological intuitions of the \kl{bubble} \kl{metaphor}
shedding a new light on them. We will end up with two symmetric \kl{bubble
calculi}, each with their own tradeoffs on the properties satisfied by
\kl{inference rules}. In particular, their ability to \emph{factorize} both
\kl{forward} and \kl{backward} proof steps might prove useful to build concise
proofs, all through \kl{direct manipulation}.

The chapter is organized as follows: in \refsec{non-determinism} we motivate our
quest for a system where all \kl{introduction rules} for logical connectives are
\emph{\kl{invertible}}, to reduce non-determinism in proof search and enable a
fully \emph{\kl{iconic}} approach to proof building. To that effect, we relax in
\refsec{branching} the restriction to \kl{single-conclusion} \kl{solutions},
which requires a new distinction between \emph{\kl{saturated}} and \emph{\kl{unsaturated}}
\kl{solutions}. This gives rise in \refsec{colors} to an extension of the syntax
of \kl{solutions}, where \kl{bubbles} can themselves be \emph{\kl{polarized}}.
In \refsec{design-props} we identify key properties that will guide the design
of \kl{inference rules}, some of which were already aimed for implicitly through
the evolution of our concept of bubble. In \refsec{symmetric-calculus} we
introduce a core \emph{symmetric \kl{bubble calculus}} for \kl{classical} logic
called \kl{system~B}, in reference to the symmetric \kl{system L} of Herbelin
\sidecite[10em]{herbelin_duality_nodate}. Then in \refsec{bubbles-soundness} we
prove the soundness of \kl{system~B}, and show that by removing selectively
among \kl{inference rules} that define the \emph{porosity} of \kl{polarized}
bubbles, one gets \kl{intuitionistic}, \kl{dual-intuitionistic} and
\kl{bi-intuitionistic} logic as fragments. In \refsec{bubbles-completeness} we
support this claim by showing that the \kl{bi-intuitionistic} fragment is not
only sound, but also \emph{cut-free complete} with respect to the cut-free
nested \kl{sequent calculus} \kl{DBiInt} of Postniece
\cite{postniece_deep_2009}. Finally in \refsec{invertible-calculus}, we
introduce a fully \kl{invertible} variant of system $\sysB$ that we conjecture
to be complete, and present a canonical way to search for proofs in this system.
Unfortunately, invertibility does not entail the full \kl{iconicity} of the
system, and we reflect on the fundamental reasons that might prevent any variant
of system $\sysB$ from being fully \kl{iconic}.

% In \refsec{invertible-calculus} we present a fully invertible variant of system
% \kl{B}, whose completeness follows naturally from the proof of
% \refsec{bubbles-completeness}. Despite the invertibility of \kl{introduction rules},
% it turns out that this variant does not satisfy the \emph{decomposability}
% property. We fix this defect in \refsec{decomposable-calculus} with another
% variant of the system conjectured complete, finally achieving full iconicity.

\begin{remark}
  Although we include rules for quantifiers, in this thesis we only treat the
soundness and completeness of \kl{bubble calculi} for \emph{propositional}
logic. Indeed quantifiers would make the algebraic semantics more involved when
proving soundness, and during our literature review we found very few \kl{proof
systems} for \kl{bi-intuitionistic} logic supporting them, at least none
suitable for our syntactic completeness proof. More generally,
\kl{bi-intuitionistic} logic has received less attention in the setting of
\kl{FOL}, probably because it is \emph{not} a conservative extension of
\kl{intuitionistic} \kl{FOL}, but only of \emph{constant-domain}
\kl{intuitionistic} \kl{FOL} (see
\cite{crolard_subtractive_2001,aschieri_natural_2018}).
\end{remark}

\section{Non-determinism and iconicity}\labsec{non-determinism}

In all known \kl{sequent calculus} formulations of \kl{intuitionistic} logic,
there are at least two rules which are invariably \emph{non-\kl{invertible}}:
\begin{enumerate}
  \item a \kl{left introduction rule} for $\limp$ (there might be many ones, as in
  the calculus \kl{LJT} of \sidecite{dyckhoff_contraction-free_1992});
  \item the right introduction for either:
    \begin{itemize}
      \item $\lor$ when \kl{sequents} have at most or exactly one conclusion;
      \item $\limp$ when \kl{sequents} have multiple conclusions, e.g. in the
        multi-conclusion variant of \kl{LJT} in
        \cite{dyckhoff_contraction-free_1992}.
    \end{itemize}
\end{enumerate}
In \kl{BJ}, this means that click actions on blue $\hypo{\limp}$ and red
$\conc{\lor}$ need to be performed in a specific order to be able to complete
proofs.

In his thesis \cite{guenot_nested_2013}, Guenot introduced a specific kind of
\kl{nested sequent} system, where like in \kl{BJ} \kl{inference rules} can be
expressed as \kl{rewriting rules}. An interesting feature of these systems is
that they satisfy a \emph{decomposability} property: all \kl{introduction rules}
for connectives are \emph{\kl{invertible}}, and formulas can be completely
decomposed with them until atoms are reached, before applying other rules. Thus
\kl{introduction rules} are \emph{\kl{admissible}} in these systems, because
every formula can be translated into an equivalent pure \kl{nested sequent} with
the same number of atoms\sidenote{As far as we know, the admissibility of
\kl{introduction rules} is not proved, let alone mentioned in
\cite{guenot_nested_2013}. This is our own observation which lacks a proper
formal proof, and is thus subject to caution.}. Non-determinism then arises in
the choice of atoms that are to be connected in axioms, as well as the choice of
sub-sequents to be duplicated for reuse.

In our graphical setting, this would translate to an interface where all click
actions are redundant. Although we already considered this possibility in
\refsec{dnd-completeness}, here it goes further by making even \emph{logical
connectives} superfluous, since all other rules work purely on the structure of
sequents. This means that all logical connectives could be replaced by
\kl{metaphorical} constructs like bubbles, which suggest \emph{physically} the
possible transformations on the \kl{proof state}.
% We call this property of a proof system \emph{iconicity}, following a
% terminology introduced by C. S. Peirce in his \emph{semiotics}
% \sidecite{noth_peircean_1999}, which he also applied to his diagrammatic proof
% system of \emph{existential graphs} \sidecite{10.7551/mitpress/3633.001.0001}.
Unfortunately, the systems in \cite{guenot_nested_2013} only handle
\kl{classical} logic, and the implicative fragment of \kl{intuitionistic} logic.
Thus began our quest for a \kl{bubble calculus} in the style of Guenot capturing
full \kl{intuitionistic} logic\sidenote{Other \kl{nested sequent} systems for
full \kl{intuitionistic} logic exist
\cite{postniece_deep_2009,fitting-nested-2014}, but they are based on
tree-shaped proofs, and thus ignore the whole \emph{raison d'être} of our
concept of bubble.}.


\section{Conclusions and branching}\labsec{branching}

The first direction we followed was to relax the constraint that \kl{solutions}
must be \kl{single-conclusion}. Indeed as already noted in
\refsec{sfl-backtracking}, a notable property of \kl{sequent calculi} with
multiple conclusions is that their \kl{right introduction rule} for $\lor$ is
\kl{invertible}.

The main difficulty lies in the way one should interpret a multi-conclusion
\kl{solution} $S$ as a formula $\sint{S}$. If we just take the asymmetric
interpretation (\refdef{ainterp}) and group conclusions disjunctively instead of
conjunctively, we get
$$
\sint{\Gamma \piq{\cS} \Delta} =
\bigwedge \Gamma \limp \bigvee \Delta \land \bigwedge_{S \in \cS}{\sint{S}}
$$
But this interpretation breaks on the 0-ary case when $\Delta$ is empty: instead
of seeing $\Gamma \piq{\cS}$ as a node of the proof tree with hypotheses
$\Gamma$ and \kl{subgoals} $\cS$, it trivializes it to $\sint{\Gamma \piq{\cS}}
= \bigwedge \Gamma \limp \bot$, i.e. a \kl{goal} where one has to find a
contradiction in $\Gamma$; which is obviously not what we have in mind.

\begin{marginfigure}
  $$
  \R[\land R*]
    {\Gamma \seq A, \Delta}
    {\Gamma \seq B, \Delta}
    {\Gamma \seq A \land B, \Delta}
  $$
  \caption{Multi-conclusion \kl{right introduction rule} for conjunction}
  \labfig{multi-and-intro}
\end{marginfigure}

A key observation was that in the rules of multi-conclusion \kl{sequent
calculi}, one usually distributes the \kl(sequent){context} $\Delta$ of
conclusions in all premisses: this restores a perfect symmetry with respect to
the \kl(sequent){context} of hypotheses $\Gamma$, as illustrated by the
{\rnm{\land R*}} rule (\reffig{multi-and-intro}). Then our idea was that instead
of implementing distribution/sharing of conclusions inside \kl{inference rules},
we could do it implicitly in the interpretation of \kl{solutions}. This is
already what happens in the asymmetric interpretation for hypotheses
(\refdef{ainterp}); indeed the \kl(sequent){context} $\Gamma$ is shared among
\kl{subgoals}, because:
\begin{enumerate}
  \item it appears on the left of an implication $\limp$
  \item \kl{bubbles} are joined conjunctively, and
  \item implication distributes over conjunction thanks to the equivalence $A
  \limp B \land C \semequiv (A \limp B) \land (A \limp C)$.
\end{enumerate}
But what does it mean precisely to share conclusions among \kl{subgoals}? If we
consider the two following \kl{solutions}:
\begin{equation}\label{eq:concdistr}
\underbrace{\bubble{\hypo{A}~~~\conc{B}}~~~\bubble{\hypo{C}~~~\conc{D}}~~~\conc{E}}_{S} \qquad\qquad
\underbrace{\bubble{\hypo{A}~~~\conc{B}~~~\conc{E}}~~~\bubble{\hypo{C}~~~\conc{D}~~~\conc{E}}}_{T}
\end{equation}
we would like to have $\sint{S} \semequiv \sint{T} \semequiv (A \limp B
\lor E) \land (C \limp D \lor E)$. Since disjunction distributes over
conjunction, a first naive try would give the following interpretation, where we
just replaced $\land$ by $\lor$ compared to the previous attempt:
$$
\sint{\Gamma \piq{\cS} \Delta} =
\bigwedge{\Gamma} \limp \bigwedge_{S \in \cS}{\sint{S}} \lor \bigvee \Delta
$$
But this immediately fails whenever $\cS = \emptyset$, because it trivializes to
$\bigwedge \Gamma \limp \top \lor \bigvee \Delta \semequiv \top$ instead of
$\bigwedge \Gamma \limp \bigvee \Delta$. The only way we found around this
defect was to internalize \emph{syntactically} a distinction between two kinds
of \kl{solutions}, by assigning them one of two statuses\sidenote{In the
terminology of Martin-Löf, we could say that we now have two distinct forms of
\emph{\kl{judgment}}.}:
\begin{itemize}
  \item \emph{\kl{saturated}} \kl{solutions} $\Gamma \piq{\cS} \Delta$ correspond
  to branching nodes in the proof tree, or to closed leaves when $\cS =
  \emptyset$ (i.e. solved \kl{subgoals}). Thus it becomes sensical to have
  $\sint{\Gamma \piq{} \Delta} = \top$. In the asymmetric interpretation,
  \kl{saturated} \kl{solutions} were encoded by \kl{solutions} with no conclusions;
  \item \emph{\kl{unsaturated}} \kl{solutions} $\Gamma \seq \Delta$ correspond to
  open leaves in the proof tree (i.e. unsolved \kl{subgoals}). In the asymmetric
  interpretation, they were encoded by \kl{solutions} with one conclusion.
\end{itemize}

\begin{remark}
  The terminology of ``saturation'' is also inspired by \emph{chemistry}: in
  this context, a solution is saturated when it has reached \emph{equilibrium},
  meaning that the chemical reaction of \emph{dissolution} cannot happen
  anymore. The analogy applies to our logical setting: a \kl{solution} is
  \kl{saturated} when it has reached \emph{truth}, meaning that the logical
  reaction of \emph{\kl(dnd){backward} linking} cannot happen anymore.
  \emph{\kl(dnd){Forward}} linking is still possible though and may produce
  additional shared knowledge, akin to solid sugar accumulating at the bottom of
  a \emph{supersaturated} container of water.
\end{remark}

Then we keep the last proposed interpretation for \kl{saturated} \kl{solutions}, and
interpret \kl{unsaturated} \kl{solutions} like usual sequents:
$$\sint{\Gamma \seq \Delta} = \bigwedge{\Gamma} \limp \bigvee{\Delta}$$ To be
able to abstract from the particular kind of \kl{solution} at hand, we reframe the
syntax of \kl{solutions} with so-called \emph{branching} operators $\J$:
\begin{align*}
  S, T, U &\Coloneq \Gamma \J \Delta \\
  \J, \JB &\Coloneq {\seq} \mid \piq{\cS}
\end{align*}
Graphically, \kl{saturated} \kl{solutions} with no \kl{bubbles} can be distinguished from \kl{unsaturated}
\kl{solutions} by painting their \emph{background} on the proof canvas in green, the
intent being to suggest that they have already been solved. A pathological
example is the distinction between the \kl{saturated} empty \kl{bubble}
$\bbubble{\phantom{a}}$ and the \kl{unsaturated} empty \kl{bubble} $\bubble{\phantom{a}}$, who
are interpreted respectively by $\sint{\piq{\piq{}}} = \top$ and
$\sint{\piq{\seq}} = \bot$.

Now coming back to our target example,
% we must explicitly assign a status to each subsolution:
% $$
% \underbrace{\bsheet{\bubble{\hypo{A}~~~\conc{B}}~~~\bubble{\hypo{C}~~~\conc{D}}~~~\conc{E}}}_{S}
% \qquad\qquad
% \underbrace{\bsheet{\bubble{\hypo{A}~~~\conc{B}~~~\conc{E}}~~~\bubble{\hypo{C}~~~\conc{D}~~~\conc{E}}}}_{T}
% $$
% However
the interpretation still fails, because we associate two non-equivalent
formulas to $S$ and $T$. To show this, let us try to derive the equivalence
through some algebraic developments:
\begin{align}
  \sint{S} &= \top \limp ((A \limp B) \land (C \limp D)) \lor E \nonumber\\
              &\semequiv ((A \limp B) \land (C \limp D)) \lor E \nonumber\\
              &\semequiv ((A \limp B) \lor E) \land ((C \limp D) \lor E) \nonumber\\
              &\semequiv (A \limp B \lor E) \land (C \limp D \lor E) \labeq{grishin}\\
              &\semequiv ((A \limp B) \land (C \limp D)) \lor E \nonumber\\
  \sint{T} &= \top \limp ((A \limp B \lor E) \land (C \limp D \lor E)) \lor \bot \nonumber
\end{align}
Wait, we did manage to prove it! The trick resides in \refeq{grishin}, which
uses twice the equivalence $(A \limp B) \lor C \semequiv A \limp (B \lor C)$. It
turns out that this equivalence is true in \kl{classical} logic, but \emph{not} in
\kl{intuitionistic} logic. More precisely, it is the implication $G \defeq (A \limp
(B \lor C)) \limp ((A \limp B) \lor C)$ which is not provable
\kl{intuitionistically}, since it can easily be shown equivalent to the \kl{law of
excluded middle}\sidenote{This was already noticed in
\cite{clouston-annotation-free-2013}, with the linear version $(A \multimap (B
\parr C)) \multimap ((A \multimap B) \parr C)$ of $G$ called Grishin (a) and its
converse Grishin (b). More precisely, it is affirmed that while Grishin (b) is
valid in \kl{FILL}, the restriction of the classical multiplicative linear
logic \kl{MLL} to single-conclusion sequents, adding Grishin (a) makes
\kl{FILL} collapse to \kl{MLL}.}. Thus according to this interpretation, $S$
entails $T$ but $T$ does not entail $S$, which means that it is not able to
account for the \emph{factorization} of common conclusions in distinct \kl{subgoals}.

To remedy this situation, we opted for a different strategy: instead of finding
a logical formula capturing the distributive semantics of conclusions over
sub\kl{goals}, we hardcode the latter by defining the interpretation function on
\kl{saturated} \kl{solutions} through \emph{non-structural} recursion. This gives the
following final definitions:

\begin{definition}[Mix operator]\labdef{mixop}
  The commutative \emph{mix operator} $\mix$ on \kl{solutions} is defined by:
  \begin{align*}
    (\Gamma \J \Delta) \mix (\Gamma' \seq \Delta') &=
      \Gamma, \Gamma' \J \Delta, \Delta' \\
    (\Gamma \piq{\cS} \Delta) \mix (\Gamma' \piq{\mathcal{S'}} \Delta') &=
      \Gamma, \Gamma' \piq{\cS \sep \mathcal{S'}} \Delta, \Delta' \\
  \end{align*}
\end{definition}

\begin{definition}[Symmetric interpretation]\labdef{sinterp}
  The \emph{symmetric interpretation} of a \kl{solution} is defined recursively by:
  \begin{align*}
    \sint{\Gamma \piq{\cS} \Delta} &=
      \bigwedge_{S \in \cS} \sint{S \mix (\Gamma \seq \Delta)} \\
    \sint{\Gamma \seq \Delta} &=
      \bigwedge \Gamma \limp \bigvee \Delta
  \end{align*}
\end{definition}

This is the right approach for interpreting \kl{solutions} with multiple conclusions,
as will be demonstrated formally in \refsec{bubbles-soundness}.

\section{Coloring bubbles}\labsec{colors}

\subsection{Red bubbles}

\begin{marginfigure}
  $$
  \R[\mathsf{{\limp}{+}c}]
    {\Gamma, A \J B, \Delta}
    {\Gamma \J A \limp B, \Delta}
  $$
  \caption{\kl{Classical} multi-conclusion version of ${\limp}{+}$}
  \labfig{wrong-imp-pos}
\end{marginfigure}

With our new symmetric interpretation, we can start generalizing the rules of
\kl{BJ} to multiple conclusions. While for most rules one just has to replace
\kl{single-conclusion} (resp. no-conclusion) \kl{solutions} with \kl{unsaturated} (resp.
\kl{saturated}) ones (more details will be given in the next section), the ${\limp}{+}$
rule stands out as particularly problematic. Indeed if we content ourselves with
the natural generalization {\rsf{{\limp}{+}c}} of \reffig{wrong-imp-pos}, then
we can easily build a proof of the excluded middle like in \reffig{lk-tnd}, and
thus collapse to \kl{classical} logic. This fact is well-known in the literature
on multi-conclusion \kl{intuitionistic} \kl{sequent calculi}, and the solution
is usually to discard the \kl(sequent){context} of conclusions $\Delta$, as in
the {\rnm{{\limp}R{*}i}} rule of \reffig{multi-imp-intro}. But this would make
our rule both non-local and non-\kl{invertible}.

\begin{marginfigure}
  $$
  \begin{array}{rclr}
    \hypo{A}~~~\cbubble{\color{black}S} &\step{} &\cbubble{\hypo{A}~~~\color{black}S} &\mathsf{f}{-}{+}{\da} \vspace{1em}\\
    % \conc{A}~~~\cbubble{\color{black}S} &\step{} &\cbubble{\conc{A}~~~\color{black}S} &\mathsf{f}{+}{+}{\da} \\
  \end{array}
  $$
  \caption{$\mathbb{F}$-rule for red bubbles}
  \labfig{flow-red-bubbles}
\end{marginfigure}

A better solution comes from the \kl{nested sequent} systems of Fitting
\sidecite{fitting-nested-2014} and Clouston et al.
\sidecite{clouston-annotation-free-2013}, where \kl{sequents} can appear as
\emph{conclusions} of other sequents. In our chemical \kl{metaphor}, this corresponds
to having \emph{red bubbles}. Then the key idea is to allow hypotheses to flow
into \kl{sequents} that appear as conclusions\sidenote{This corresponds to the
{\rnm{Lift}} rule of \cite{fitting-nested-2014} and {\rnm{pl_1}} rule of
\cite{clouston-annotation-free-2013}.}, but \emph{not other conclusions}.
Graphically, this means that blue \kl{items} can enter red \kl{bubbles} (rule
{\rsf{f{-}{+}}} of \reffig{flow-red-bubbles}), but red \kl{items} cannot: this is
reminiscent of the electromagnetic phenomemon of \emph{repulsion} between
objects charged with the same polarity.

\begin{figure*}
  \input{figures/bubbles-grishin.tex}
  \caption{Proof attempts for Grishin (a) and Grishin (b)}
  \labfig{bubbles-grishin}
\end{figure*}

To illustrate why this works, let us consider how one can manipulate with red
\kl{bubbles} the \kl{classical} equivalence $ (A \limp B) \lor C \semequiv A \limp (B \lor
C)$, that we already stumbled upon in the previous section. The begginings of
the proofs for both directions of the equivalence are depicted parallely in
\reffig{bubbles-grishin}. Indeed both proofs have a very similar structure:
\begin{enumerate}
  \item the first step is to decompose the conclusion with the new version of
  the rules {\rnm{{\lor}{+}}} and {\rnm{{\limp}{+}}}. While the former simply
  splits disjunctions in two, the latter encapsulates the antecedant and
  consequent of implications in a red bubble: the \kl{goal} is to forbid the use of
  the antecedant to prove conclusions other than the consequent, as will become
  apparent later;
  \item then in both cases we want to apply the hypothesis $\hypo{A}$ in a
  \kl(dnd){forward} step, either with $\hypo{A \limp B}$ or $\hypo{A \limp (B \lor C)}$.
  To do so, we need to bring the two hypotheses together in the same \kl{solution}.
  And since \kl{items} are trapped within bubbles, the only way to go is to move the
  blue $\hypo{A}$ inside the red \kl{bubble} with the {\rsf{f{-}{+}}} rule;
  \item this time we decompose the hypothesis with the new version of the rules
  {\rnm{{\lor}{-}}} and {\rnm{{\limp}{-}}}. They are basically a local variant
  of those of \kl{BJ}: we encapsulate both subformulas in separate bubbles, but
  without touching to the conclusions of the ambient \kl{solution};
  \item now that all formulas have been decomposed, it only remains to bring
  together dual atoms for annihilation, and pop all empty bubbles. In Grishin
  (b) this is easy, because all necessary movements (indicated by green arrows)
  are valid: they only cross gray \kl{bubbles} inward. In Grishin (a) this works for
  $\hypo{A}$ and $\conc{B}$, but not for $\conc{C}$ (orange dotted arrow): it
  would cross the red bubble, which is expressedly forbidden.
\end{enumerate}
Thus in order to prove Grishin (a) and recover \kl{classical} logic, it suffices
either to add the {\rsf{f{+}{+}}} rule allowing red \kl{items} to enter red \kl{bubbles}
(\reffig{flow-red-bubbles}), or to use the {\rsf{{\limp}{+}c}} rule which
avoids red \kl{bubbles} altogether. In the following we will settle for the first
option: we find it more elegant, because it explains the distinction between
\kl{intuitionistic} and \kl{classical} logic as a kind of \emph{physical law} independent
of logical connectives.

\subsection{Blue bubbles}

Now it is only natural to wonder: since \kl{bubbles} can be colored in red, or
charged \kl{positively}, would it also make sense to have \emph{blue} \kl{bubbles} charged
\emph{\kl{negatively}}? The answer is \emph{yes}, but we need to broaden our logical
view and consider more exotic beasts: the adequately named
\emph{\kl{dual-intuitionistic}} logic, and \emph{\kl{bi-intuitionistic} logic}.

\begin{marginfigure}
  $$
  \begin{array}{rclr}
    \conc{A}~~~\hbubble{\color{black}S} &\step{} &\hbubble{\conc{A}~~~\color{black}S} &\mathsf{f}{+}{-}{\da} \vspace{1em}\\
    % \hypo{A}~~~\hbubble{\color{black}S} &\step{} &\hbubble{\hypo{A}~~~\color{black}S} &\mathsf{f}{-}{-}{\da} \\
  \end{array}
  $$
  \caption{$\mathbb{F}$-rule for blue bubbles}
  \labfig{flow-blue-bubbles}
\end{marginfigure}

But for now let us stay at a purely syntactic level. The idea is very simple,
and can be summarized in two words: \emph{color swap}. Thus the law that ``blue
items can enter red bubbles, but red \kl{items} cannot'' becomes a new law that ``red
items can enter blue bubbles, but blue \kl{items} cannot'', which is enforced by
allowing only the use of the {\rsf{f{+}{-}}} rule in
\reffig{flow-blue-bubbles}. Well this is neat, but will not be of much use if
there is no way to spawn blue bubbles. Be it as it may: we can just craft a new
logical connective! Since red \kl{bubbles} are produced by the implication connective
$A \limp B$, we define a dual \emph{exclusion} connective $A \lsub B$ (read
``$A$ excludes $B$''\sidenote{We ask for the reader's leniency regarding our
choice of \kl{symbol} and terminology: in \kl{set theory} this would be total nonsense,
since $A \subset B$ would read ``$A$ is included in $B$''. Even worse, in the
boolean algebra induced by set operations, $A \subset B$ is interpreted as $A$
\emph{implies} $B$\ldots~But all the arrow \kl{symbols} were already taken, and we
want to emphasize the duality between exclusion and implication by mirroring the
\kl{symbol}, as it is traditionally done with conjunction $\land$ and disjunction
$\lor$.}), whose heating rules are those of $\limp$ with swapped colors
(\reffig{heating-exclusion}).

\begin{marginfigure}
  $$
  \begin{array}{rclr}
    \hypo{A \lsub B} &\step{} &\hbubble{\hypo{A}~~~\conc{B}} &{\lsub}{-}\vspace{1em}\\
    \conc{A \lsub B} &\step{} &{\bubble{\conc{A}}}~~~\bubble{\hypo{B}} &{\lsub}{+}
  \end{array}
  $$
  \caption{$\mathbb{H}$-rules for exclusion $\lsub$}
  \labfig{heating-exclusion}
\end{marginfigure}

Not very surprisingly, the exclusion connective has already been studied in the
literature on \kl{intuitionistic} logic, starting with the seminal paper of
Rauszer on \emph{Heyting-Brouwer logic}, i.e. \kl{intuitionistic} logic to which
we add exclusion \sidecite{Rauszer1974-RAUSAA}. In this paper, exclusion was
called \emph{pseudo-difference}, to evoke its close connection with
\kl{set-theoretical} difference. Indeed given two sets $A$ and $B$, one can
define the set $A \setminus B$ by comprehension as $\{x \mid x \in A \land x
\not\in B\}$, which is the set $A$ from which all elements of $B$ have been
\emph{excluded}. With an interpretation in boolean algebras, this corresponds to
the \kl{classical} connective defined by the truth table of $A \land \neg B$,
which is dual to the truth table of $\neg A \lor B$ defining material
implication.

While the first paper of Rauszer \cite{Rauszer1974-RAUSAA} belongs to the Polish
tradition of algebraic logic, she also explored in later works the
\kl{proof-theoretic} \sidecite{rauszer_formalization_1974} and \kl{model-theoretic}
\sidecite{rauszer_applications_1977} sides of the question. Many authors have
then deepened the \kl{proof theory} of exclusion, whether in isolation from
implication in \intro{dual-intuitionistic} logic
\sidecite{urbas_dual-intuitionistic_1996,gore_dual_2000}, or with both
connectives in \intro{bi-intuitionistic} logic as in Rauszer's original
work\sidenote{Crolard \cite{crolard_subtractive_2001} and Aschieri
\cite{aschieri_natural_2018} have also explored the computational counterpart of
exclusion through the \kl{Curry-Howard correspondence}, which is claimed by the first
author to be a typing operator for \emph{first-class coroutines}.}
\sidecite{postniece_proof_2010,pinto_relating_2011}. In particular, we are going
to rely in \refsec{bubbles-completeness} on the \kl{deep inference} calculus
developed by Postniece in her thesis \cite{postniece_proof_2010} to get
completeness and cut admissibility of our symmetric \kl{bubble calculus} introduced
in the next section.

\subsection{Polarized interpretation}

\begin{scope}\knowledgeimport{symm}

Let us now extend the formal definition of \kl{bubbles} so that they can be colored:

\begin{definition}[Bubble]\labdef{pol-bubble}
  A \intro{bubble} is a \kl{solution} enclosed in a membrane, which can be either
  \intro{unpolarized} (\reintro{neutral}), charged \reintro{positively}, or
  charged \reintro{negatively}.
\end{definition}

\kl{Neutral} \kl{bubbles} are the usual ones depicted in gray, while \kl{positive} and \kl{negative}
\kl{bubbles} correspond respectively to red and blue bubbles. We also update the
definition of \kl{solutions}, which can now be \kl{unsaturated} or \kl{saturated}:

\begin{definition}[Solution]\labdef{pol-solution}
  
  A \intro{solution} is a multiset of \kl{ions} and bubbles. It can be either
  \intro{saturated} or \intro{unsaturated}, and \kl{unsaturated} \kl{solutions} cannot contain
  \kl{neutral} bubbles. \kl{Solutions} $S$ can be represented textually with the
  following syntax:
  \begin{align*}
    S, T, U &\Coloneq \Gamma \J \Delta &
    \cS &\Coloneq S_1 \sep \ldots \sep S_n \\
    I, J, K &\Coloneq A \mid S &
    \Gamma, \Delta &\Coloneq I_1, \ldots, I_n \\
    \J, \JB &\Coloneq {\seq} \mid {\piq{\cS}} &&
  \end{align*}
\end{definition}

Note that in the textual syntax, \kl{bubbles} are identified with \emph{\kl{subsolutions}}
(\refdef{subsolution}), and their \kl{polarity} is determined by their position
relative to branching operators; that is, for any \kl{solutions} $S, T, U$ such that
$T \subsol U$, $S$ is either:
\begin{itemize}
  \item \emph{\kl{neutral}} if $T = \Gamma \piq{\cS} \Delta$ and $S \in
  \cS$;
  \item \emph{\kl{positive}} if $T = \Gamma \J \Delta$ and $S \in \Delta$;
  \item \emph{\kl{negative}} if $T = \Gamma \J \Delta$ and $S \in \Gamma$.
\end{itemize}

Then we need to split our symmetric interpretation accordingly, so that \kl{positive}
\kl{bubbles} are mapped to implications, and \kl{negative} \kl{bubbles} to
exclusions\sidenote{Here we took inspiration from the work of Clouston et al. on
\kl{nested sequents} for \kl{FILL} \cite{clouston-annotation-free-2013}.}:

\begin{definition}[Polarized symmetric interpretation]\labdef{pol-sinterp}
  The \emph{positive} and \emph{negative symmetric interpretations} of \kl{solutions}
  $\psint{-}$ and $\nsint{-}$ are defined by mutual recursion as
  follows:
  \begin{align*}
    \psint{A} &= A &
    \nsint{A} &= A \\
    \psint{\Gamma \piq{\cS} \Delta} &=
      \bigwedge_{S \in \cS} \psint{S \mix \Gamma \seq \Delta} &
    \nsint{\Gamma \piq{\cS} \Delta} &=
      \bigvee_{S \in \cS} \nsint{S \mix \Gamma \seq \Delta} \\
    \psint{\Gamma \seq \Delta} &=
      \nsint{\Gamma} \limp \psint{\Delta} &
    \nsint{\Gamma \seq \Delta} &=
      \nsint{\Gamma} \lsub \psint{\Delta} \\
    \psint{\Gamma} &= \bigvee_{I \in \Gamma}{\psint{I}} &
    \nsint{\Gamma} &= \bigwedge_{I \in \Gamma}{\nsint{I}}
  \end{align*}
\end{definition}

One can easily check that the interpretation of a \kl{solution} that has no \kl{negative}
(resp. \kl{positive}) \kl{subsolution} will not contain any occurrence of the exclusion
(resp. implication) connective. This will be crucial later to represent proofs
of both \kl{intuitionistic}, \kl{dual-intuitionistic} and \kl{bi-intuitionistic} logic in the
same system.

\section{Designing for properties}\labsec{design-props}

With our new syntax and interpretation of \kl{solutions} at hand, we can design a new
proof calculus including the rules previously discussed for manipulating
\kl{polarized} bubbles. The rich structure of \kl{solutions} offers many possibilities in
the precise formulation of rules, depending on the properties we expect from the
calculus. We identified \emph{six} of these properties, whose consequences range
from aesthetic and theoretical considerations on paper, to concrete usability
matters in a graphical proof building interface. Let us summarize them in order
of priorization relatively to the latter:
\begin{description}
  \item[Invertibility]
    A rule is \kl{invertible} when it could in principle be applied in the converse
    direction, while staying logically sound\sidenote{The \textit{``in
    principle''} part is important: more often than not, adding the converse of
    a rule only brings unnecessary complexity in proof search, especially in a
    user interface that aims for simplicity.}. In other words, it corresponds to
    a logical \emph{equivalence}: when all rules in a (bubble) calculus are
    \kl{invertible}, we get that $S \step{} T$ implies $\sint{S} \semequiv
    \sint{T}$. This entails in particular that a user can apply the rule
    without fear of turning a provable \kl{goal} into an unprovable
    one\sidenote{Assuming that the calculus is \emph{complete}
    (\refsec{bubbles-completeness}).}, eliminating an important source of
    non-determinism in proof search: the need for
    \emph{backtracking}\sidenote{See also \refsec{sfl-backtracking} for a
    discussion on this matter.}.
  \item[Decomposability]
    We already mentioned this property in \refsec{non-determinism} as one of the
    main motivations for this chapter: the ability to decompose all logical
    connectives ``for free'', and thus reason solely on \kl{solutions} that comprise
    only \kl{bubbles} and atomic formulas. As far as we know, it has never been
    identified explicitly in the literature before, although it can loosely be
    seen as an extension of the decomposition procedures of existing \kl{deep
    inference} systems\sidenote{One could argue that more ``semantic'' approaches
    in \kl{proof theory} have achieved connective-free explanations of proofs, like
    strategies in game semantics or the combinatorial proofs of D. Hughes
    \cite{heijltjes_intuitionistic_2019}. But this is more of a side effect than
    a goal of these approaches, which intentionally abstract from the syntactic
    process of building proofs. A notable exception is the Girardian line of
    works starting from \emph{ludics} \cite{girard_locus_2001} and culminating
    in \emph{transcendental syntax} \cite{eng_exegesis_2023}, where both
    frameworks are founded upon the syntactic mechanisms of proof search
    (\kl{focusing} in \kl{sequent calculus}, and unification in the resolution algorithm
    of Robinson, respectively). Here the aim to rid proofs of connectives is
    greatly emphasized by Girard, but the focus is again on \emph{proofs} and
    not \emph{\kl{proof states}}. Also Girard embraces the full space of incomplete
    but also \emph{incorrect} proofs, while we still want a framework where
    proofs are correct by construction.}. One reason is that logical connectives
    are widely considered as \emph{primitive} in the tradition of \kl{mathematical
    logic}: they \emph{are} the objects of the reasoning activity, rather than a
    tool for representing and structuring arguments. Thus the idea of an
    alternative does not even occur. But even if it does, it is not clear that
    it would bring any interesting viewpoint on the problems usually studied in
    \kl{proof theory}. In our case, it was brought by a very concrete application:
    making formal proofs accessible to a broader audience, by replacing \kl{symbolic}
    and linguistic means of representation by \kl{iconic} and directly manipulable
    ones.
  \item[Factorizability]
    We say that a proof calculus is \emph{factorizable} when it makes it easier
    to avoid duplicating arguments in subproofs. In \refsec{bubbles-pba}, we
    already remarked that the ability to share hypotheses between \kl{subgoals}
    in \kl{BJ} enables the factorization of \emph{\kl{forward}} reasoning steps
    at any stage of the proof construction. With our new symmetric
    interpretation of multi-conclusion \kl{solutions}, we will now be able to
    factorize \emph{\kl{backward}} reasoning steps as well, which was in fact
    the main motivation behind Example \ref{eq:concdistr} in \refsec{branching}.
  \item[Locality]
    There does not seem to be a general consensus on what it means precisely for
    an \kl{inference rule} to be \emph{local}. This terminology has been
    employed by various authors in \kl{proof theory}, in ways that are often
    hard to compare. For instance in \sidecite{negri_structural_2001}, rules are
    said to be local because the \kl(sequent){contexts} of hypotheses involved in a rule are
    located in the \kl{sequents} of that rule, by opposition to \kl{natural
    deduction} rules in their labelled presentation where hypotheses are located
    in arbitrary distant leaves of the derivation. In the setting of \kl{deep
    inference}, local rules are those that can be applied without ``inspection
    of expressions of arbitrary size''\sidenote{Definition 2.1.1 in
    \cite{tubella:hal-02390267}. The same definition is used in
    \cite{tiu_local_2006}.}. Finally in his transcendental syntax, Girard evokes
    a related but more elusive notion, concerned with the \emph{genericity} of
    logical objects involved in a rule\sidenote{See the section \emph{Globality
    and locality in logical systems} in \cite[Chapter 6]{eng_exegesis_2023}.}.
    
    Our conception of locality is related to all the previous ones, although it
    is guided by the idea of \kl{direct manipulation} of logical entities by humans,
    rather than purely \kl{proof-theoretical} considerations. For instance,
    \kl{BJ} has some locality in the \kl{deep inference} sense because all rules
    are applicable in arbitrary \kl{contexts}; but we relax the \emph{atomicity}
    constraint that reduces $\mathbb{I}$-rules and $\mathbb{R}$-rules to their
    atomic version, because it would be unnecessarily restrictive for the
    purpose of building proofs manually. Still, we want to avoid as much as
    possible referring to generic objects that are not directly related to the
    manipulated data, in the spirit of Girard's locality. A typical example is
    the \kl{elimination rule} \kl{\lor e} for disjunction in \kl{natural
    deduction}, corresponding to the {\rsf{{\lor}{-}}} rule of \kl{BJ} that
    involves an arbitrary conclusion $\Delta$. The benefits of locality from a
    \kl{UX} point of view have already been discussed at the end of
    \refsec{bubbles-pba}.
  \item[Linearity] 
    We consider an \kl{inference rule} to be \emph{linear} when it preserves the
    number of atomic formulas in \kl{solutions}. This is a strong requirement, which
    for instance excludes the identity rules of \kl{BJ} since they can insert
    or remove (even numbers of) atoms. Thus we cannot achieve full linearity in
    that sense, but it is still interesting to maximize it. The first reason is
    \emph{methodological}: by the words of its creator A. Guglielmi,
    \textit{``[...] \kl{deep inference} is obtained by applying some of the main
    concepts behind linear logic to the formalisms, i.e., to the rules by which
    \kl{proof systems} are designed.''} \sidecite{deep_inference}. The second reason
    is \emph{computational}: it can enable a measure on \kl{solutions} that is
    strictly decreasing with the application of rules, avoiding infinite loops
    during proof search as in the calculus \kl{LJT} of R. Dyckhoff
    \cite{dyckhoff_contraction-free_1992}. The third reason is ergonomical: as
    already remarked by the authors of the \kl{Proof-by-Pointing}
    paradigm\sidenote{Section 4.1 of \cite{PbP}.}, rules that systematically
    duplicate formulas can quickly overload the \kl{goal} with useless copies, making
    it harder to read and navigate.
  \item[Symmetry] 
    In \kl{classical} logic, both \kl{sequent calculi} like \kl{LK} and \kl{deep
    inference} systems like \kl{CoS} are known for their very rich
    \emph{symmetries}. In fact, one of our ambitions with \kl{bubbles} was to bring
    back the symmetry of \kl{classical} logic in a constructive setting, without
    resorting to linear logic. This chapter stems in great part from our lack of
    satisfaction with the asymmetry at work in the \kl{BJ} calculus, which
    looked quite unnatural. Of course we will not be able to completely
    eliminate it, but it will be distilled into the flow rules governing the
    \emph{porosity} of \kl{bubbles} that were hinted at in \refsec{colors}, rather
    than through the arbitrary restriction of \kl{sequents} to one
    conclusion\sidenote{Whether it is enforced in the syntax of \kl{sequents} themselves, or through restriction on rules that manipulate conclusions like
    \kl{contraction} or the \kl{right introduction rule} for $\limp$.}. Our
    treatment of \kl{dual-intuitionistic} and \kl{bi-intuitionistic} logic
    through blue \kl{bubbles} is also motivated by this quest for symmetry. It should
    be noted that although we use naming conventions for rules that resemble
    those of \kl{CoS} (e.g. with the identity rules), we do not aim for a
    perfect symmetry where one can get a complete calculus by simply taking the
    dual of each rule.
    % \sidenote{In fact it is not even clear what would be the dual of a
    % solution, but the {\rsf{i{\da}}} and {\rsf{i{\ua}}} rules
    % suggest that open and closed solutions may be dual to eachother.}
    Thus we will content ourselves with the hypothesis/conclusion symmetry
    coming from \kl{sequent calculus}. Interestingly, the calculus \kl{ISgq} of Tiu
    for \kl{intuitionistic} \kl{predicate logic} does the opposite, by having a perfect
    dual system \kl{cISgq} but no symmetries among its \kl{switch rules} (the
    equivalent of our flow rules) \cite{tiu_local_2006}.
\end{description}

In the next section we present a core calculus called \kl{system~B} that
maximizes \emph{symmetry}, \emph{linearity} and \emph{locality}. In our opinion
this makes for a good \kl{proof-theoretical} foundation, around which variant
calculi with different tradeoffs can be designed.

% In \refsec{invertible-calculus} we introduce such a variant that focuses on
% \emph{invertibility} at the cost of \emph{linearity}, and in
% \refsec{decomposable-calculus} on a refinement of the latter that achieves
% \emph{decomposability} and \emph{factorizability}, losing some of its
% \emph{locality} and \emph{symmetry} along the way.

\section{Symmetric calculus}\labsec{symmetric-calculus}

\input{sections/bubbles-symmetric-calculus}

\section{Soundness}\labsec{bubbles-soundness}

\input{sections/bubbles-soundness.tex}

\section{Completeness}\labsec{bubbles-completeness}

\input{sections/bubbles-completeness.tex}

\section{Invertible calculus}\labsec{invertible-calculus}

\input{sections/bubbles-invertible.tex}


% \section{Decomposable calculus}\labsec{decomposable-calculus}

% \begin{figure*}
%   \input{figures/sequent-B-dec.tex}
%   \caption{Rules for the decomposable bubble calculus \kl{B_{dec}}}
%   \labfig{sequent-B-dec}
% \end{figure*}

% \todo{Talk about factorizability}

% \todo{ Tradeoff between perfectly local rules, where many are restricted to
%   open solutions, and factorizing rules that are uniformly applicable to any
%   kind of solution, but are neither local nor linear (because they rely on
%   duplicating the abstract proof in all subgoals) }

% \todo{IDEA: add (duplicating variants of) the {\rnm{pl_2}} and {\rnm{pr_2}}
% rules of \cite{clouston-annotation-free-2013} into the calculus. Indeed, they
% allow taking red items outside of red bubbles: thus if the proof can be made
% outside with a smaller context, it is more general and immediately solves all
% subgoals, improving \emph{factorizability}.}


\end{scope}
\end{scope}