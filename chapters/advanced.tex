% !TEX root =index.tex
\setchapterpreamble[u]{\margintoc}
\chapter{Proof-by-Action in Practice}
\labch{advanced}

In the previous chapters, we explained the core principles of our so-called
\kl{Proof-by-Action} paradigm and especially its drag-and-drop actions, first through
basic and abstract examples in \refch{pba}, and then from a \kl{proof-theoretical}
perspective in \refch{sfl}. The goal of this chapter is to provide a better
sense of what proofs by action/\kl{DnD} look like in practice, and how they compare
to more traditional approaches to interactive theorem proving. To that effect,
we perform a case study of a few select examples, unrolling and commenting in
details one or many of their proofs. Although still basic, they are fully
fledged, concrete logical riddles or mathematical problems that one might give
as exercise to an undergraduate student learning formal proofs. Note that our
analysis will stay quite informal and opinionated: a more systematic approach
such as a user study would allow for a better evaluation of our paradigm, but at
the time of writing of this thesis the \kl{Actema} prototype is not mature enough to
conduct a project of this scale.

The chapter is organized as follows: \refsec{edukera} studies a proof of a small
logical riddle in \kl{Actema}, highlighting some benefits of our approach compared to
textual systems. \refsec{funcs} explores how basic properties about functions
between sets can be proved graphically, introducing the use of definitions in
addition to logical reasoning steps. In \refsec{arith} we prove equations in
Peano arithmetic, showing how one can incorporate additional actions into the
paradigm to deal with more specialized forms of reasoning: \emph{induction} and
\emph{automatic computation}.

\todo{ Explain that for all examples, we provide a \kl{Coq} \kl{proof script} that tries
  to follow the structure of the graphical proof, for the sake of comparison
  with a more standard text-based interface. But this would obviously compare
  differently with other textual approaches, e.g. \kl{Isar} which is more
  declarative, and thus farther from the \kl{Proof-by-Action} paradigm. }

\todo{ Maybe advise the reader to reproduce the examples herself? Supposes an
  easy way to setup and use coq-actema: nix seems like a good option, but maybe
  JsCoq could be doable with some efforts, and would provide an even more
  out-of-the-box experience.}
  
\todo{ Real numbered equations for intermediate proof states. }

\section{Forward reasoning}\labsec{edukera}

% It is too early to perform a detailed case study comparing our approach
% to interactive theorem proving with others --- tactic-based,
% declarative, {\em etc}\dots~This is due primarily to the fact that
% our prototype is not mature enough; it cannot handle lemmas and
% implements a limited formalism. However some examples allow to get a
% glimpse of specificities and possible advantages of proofs by actions.

Our first example is a small logical riddle, which we borrow from a textual
educational system, Edukera~\sidecite{edukera}. One considers a population of
people, with at least one individual $h$, together with a single function
$\mother$ and one predicate $\rich$. The aim is to show that the two following
assumptions are incompatible:
\begin{itemize}
\item[(1)] $\forall x. \neg\rich(x)\lor \neg\rich(\mother(\mother(x)))$,
\item[(2)] $\forall x. \neg\rich(x) \limp \rich(\mother(x)).$
\end{itemize}
The original \kl{goal} thus corresponds to the illustration of \reffig{edukera}.

\begin{figure*}
  \fbox{\includegraphics[width=1.3\textwidth]{edukera.png}}
  \caption{The beginning of an example due to Edukera}
  \labfig{edukera}
\end{figure*}

It is quite natural to approach this problem in a \kl{forward} manner, by starting
from the hypotheses to establish new facts. And a first point illustrated by
this example is that \kl{DnD} actions allow to do this in a smooth and precise
manner. A possible first step is to bring $h$ to the first hypothesis, to obtain
a new fact:

\medskip
$(3) ~\neg\rich(h)\lor \neg\rich(\mother(\mother(h))).$
\medskip

\noindent Double clicking on this new fact yields two cases:
\begin{itemize}
 \item[(4)~] $ \neg\rich(h)$,
 \item[(4')] $ \neg\rich(\mother(\mother(h)))$.
 \end{itemize}
Let us detail how one solves the
second one.

By bringing 
$\neg\rich(\mother(\mother(h)))$ on the premise of $\forall
x. \select{\neg\rich(x)} \limp \rich(\mother(x))$
one obtains

\medskip
$(6) ~\rich(\mother(\mother(\mother(h)))).$
\medskip

The next step is a good example where \kl{DnD} actions are useful. By bringing this
new fact to the right-hand part of

\medskip
$(1)~\forall x. \neg\rich(x)\lor \neg\select{\rich(\mother(\mother(x)))}$
\medskip

\noindent
one immediately obtains a new fact

\medskip
$(7) ~\neg{\rich(\mother(h))}$.
\medskip

\noindent In other \kl{proof systems}, this last step requires a somewhat intricate
\kl{tactic} line and/or writing down at least the statement of the new fact.

One can then finish the case by combining $(7)$ and $(2)$ which yields
$$\rich(\mother(\mother(h)))$$ contradicting $(4')$. These two last steps each
correspond to a simple \kl{DnD}. The other case, $\neg\rich(h)$, is quite similar.

% Such a simple example is not sufficient to provide significant metrics.
Note that once a user has understood the proof, the riddle is routinely solved
in less than a minute in \kl{Actema}, which seems out of reach for about any user in
a \kl{tactic} based prover. At least as important is the fact that the proof can be
performed without typing any text, especially no intermediate statement. 

To conclude this example, we propose in \reffig{edukera-coq} a complete proof of
the riddle formalized in the \kl{Coq} \kl{proof assistant}, which follows very closely the
structure of the graphical proof just outlined. To make the correspondence more
visible and ease the comparison, we interspersed the \kl{proof script} with comments
of the form \texttt{(** [actions] *)}, where \texttt{[actions]} is a
sentence describing a sequence of actions in \kl{Actema} that produces the same goal
transformation as the \kl{tactics} preceding the comment. There are a few interesting
things to note:
\begin{itemize}
  \item We chose to name manually all the hypotheses introduced in the course of
  the proof. This is generally considered good practice in the \kl{Coq} community,
  because it makes \kl{proof scripts} easier to maintain. In our case it also has the
  advantage of expliciting which hypotheses are used exactly in the reasoning,
  something that an \kl{Actema} user does with her pointing device when designating
  the blue items involved in an action. It appears clearly in
  \reffig{edukera-coq} that in a moderately long proof like this based mostly on
  \kl{forward} reasoning, one needs to keep track of \emph{a lot} of names, which can
  be overwhelming for many users. This is especially true for beginners
  discovering \kl{Coq}, because the syntax for assigning names, based on patterns
  like \texttt{[H | H]} that reproduce the \kl{subgoal} structure, can induce a steep
  learning curve. Of course this problem is mitigated trivially in \kl{Actema}, since
  names are not needed.

  \item There is no exact correspondence between the \kl{tactics} of \kl{Coq} and the
  actions of \kl{Actema}: some \kl{tactics} are simulated by multiple actions, and often a
  complex sequence of \kl{tactics} can be simulated by a single action\sidenote{This
  was already noticed in \cite{PbP}, where clicking on a subformula can simulate
  a sequence of \kl{introduction rules} of arbitrary length.}.
  
  For instance, line 23 does at the same time a specialization of the hypothesis
  $H_2 : \forall x. \neg \rich(\mother(\mother(x))) \lor \neg \rich(x)$ to the
  individual $h$ with the application \texttt{(H2 h)}, and a case analysis with
  the \texttt{destruct} \kl{tactic}. In \kl{Actema} this is performed in two steps, first
  by drag-and-dropping $h$ on $H_2$, and then by clicking on the resulting
  hypothesis\sidenote{This could also be achieved in two steps in \kl{Coq}, by using
  the \texttt{specialize} \kl{tactic} instead of the inlined application.}.

  In the other direction, a pattern of reasoning that occurs multiple times in
  the proof is the combination of $H_2$ with another hypothesis which
  contradicts one of the two cases, in order to deduce the truth of the other
  case. While it is captured straightforwardly in \kl{Actema} with a single \kl{DnD}
  between the contradictory statements, it requires in \kl{Coq} a decomposition into
  many administrative steps:
  \begin{enumerate}
    \item first a case analysis with \texttt{destruct}, where the expression
    instantiating $H_2$ (e.g. $\mother(mother(h))$) needs to be written down
    explicitly, instead of being inferred automatically from unification;
    \item optionally focusing on the \kl{subgoal} corresponding to the contradictory
    case if it is the right disjunct (line 56), which requires to know a
    somewhat idiosyncratic and infrequently used syntax of the \kl{tactic} language;
    \item and finally expliciting the contradiction with \texttt{apply} and
    \texttt{exact}.
  \end{enumerate}

  \item More generally, the actions of \kl{Actema} are more \emph{versatile} and
  \emph{context-dependent} than the \kl{tactics} of \kl{Coq}. For instance, click actions
  have a different effect depending on the main connective of the formula being
  clicked, but provide a unique interface for applying rules of natural
  deduction/\kl{sequent calculus}. On the contrary, there is almost one \kl{tactic} for
  dealing with each logical connective in \kl{Coq}, e.g. \texttt{intros} for $\limp$
  and $\forall$, \texttt{split} for $\land$, \texttt{left} and \texttt{right}
  for $\lor$, \texttt{exists} for $\exists$, etc. The same remark applies to \kl{DnD}
  actions, whose functionalities are provided in \kl{Coq} by many different \kl{tactics}:
  \texttt{apply \_}, \texttt{apply \_ in \_}, \texttt{pose proof},
  \texttt{specialize}, etc.
\end{itemize}

\begin{figure}
  % \fontsize{8}{8.5}\selectfont
  % \input{listings/coq-actema-edukera.tex}
  \input{listings/Edukera.tex}
  \caption{\kl{Coq} \kl{proof script} formalizing Edukera's riddle}
  \labfig{edukera-coq}
\end{figure}

From this detailed comparison, it appears that the interface offered by the
\kl{PbA} paradigm might be more suited to \kl{forward} reasoning than the
\kl{tactic} language of \kl{Coq}, at least in some respects. It makes the flow of
argumentation more straightforward to express with \kl{DnD} actions, and avoids the
overheads of name management and syntax memorization. This altogether shall
prove to be particularly helpful to beginners and learners of the \kl{proof
assistant}.


\section{Sets and functions}\labsec{funcs}

Our second example comes from a preprint of Bartzia et al.
\cite{bartzia:hal-04087080}, where it is chosen specifically for a case study
aiming to compare the features of different \kl{proof assistants}' interfaces in an
educational setting. It is ``a typical exercise about sets, relations and
functions, as commonly found in introductory courses about reasoning and
proof.'' (p. 6):

\begin{exercise}
  Given three sets $A$, $B$ and $C$ such that $C \subseteq A$ and a function $f
  : A \to B$, show that:
  \begin{enumerate}
    \item $C \subseteq f^{-1}(f(C))$.
    \item If $f$ is injective then $f^{-1}(f(C)) \subseteq C$.
  \end{enumerate}
  where $f(D)$ and $f^{-1}(E)$ denote respectively the direct and inverse image
  (or preimage) of sets $D \subseteq A$ and $E \subseteq B$ by $f$.
\end{exercise}

Compared to our previous example, this exercise has the particularity of
involving multiple \emph{definitions}, here about sets and functions between
them. There are many possible ways to handle definitions in a formal \kl{proof
system}. A common one is to decompose the definition into a new function or
predicate symbol, the definition's \emph{head}, and a universally parametrized
equality or equivalence between the head and the \emph{body} of the definition.
For instance, the concept of injectivity can be encoded as a unary predicate
$\injective(\cdot)$ on functions, satisfying the following equivalence:
$$\forall A.\ \forall B.\ \forall f{:}A \to B.~\ \injective(f) ~\lequiv~ \forall x
\in A.\ \forall y \in A.\ f(x) = f(y) \limp x = y$$

Notice that $\injective(\cdot)$ is a \emph{\kl{higher-order}} predicate, since it
takes any function as argument. Depending on the underlying logical framework,
this might have an impact on the exact way the definition is encoded. Here we do
not want to bother with such implementation details, and simply assume that
\kl{higher-order} definitions are possible, even though \kl{Actema} is currently limited
to \kl{first-order logic}. In practice this does not affect the semantics of
graphical actions, and we can imagine having a \kl{first-order} \kl{set theory} such as
\kl{ZF} to make everything work behind the scenes\sidenote{See also
\refsec{pluginfuture} for a discussion on a \kl{higher-order} extension of \kl{Actema}.}.

Let us now describe how to prove the second question of the exercise in the
\kl{PbA} paradigm. The first thing we want to do is to unfold the
definition of set inclusion in the conclusion $f^{-1}(f(C)) \subseteq C$, so
that we can see how to prove logically such an inclusion. One might imagine
multiple kinds of graphical actions for doing this. In \kl{Actema} we implemented a
general \emph{subterm selection} mechanism, where the user can successively
point at different subterms appearing in the \kl{goal} --- either in the context or
the conclusion --- and then choose from a list of available actions taking the
selection as argument. In our case we can select the whole conclusion, and then
choose to apply the \action{Unfold} action:
$$\select{f^{-1}(f(C)) \subseteq C} \qquad \text{(\action{Unfold})}$$
The system will be able to tell that we
selected an instance of the two-place inclusion predicate $\cdot \subseteq
\cdot$, and thus will replace the head of this definition by its body,
instantiating parameters accordingly. This gives us a new conclusion
$$\forall x. x \in f^{-1}(f(C)) \limp x \in C$$
on which we can click twice to introduce a new variable $x$ in the context,
together with the hypothesis:
\begin{itemize}
  \item[(1)] $x \in f^{-1}(f(C))$
\end{itemize}

Now there is no available action on the conclusion $x \in C$, because set
membership is a \emph{primitive} predicate in \kl{set theory}: it does not have
any associated definition in the sense mentioned above\sidenote{Formally, the
meaning of $\in$ in a \kl{set theory} such as \kl{ZF} comes from the various
\kl{axioms} involving it. One might call such a definition \emph{behavioral},
since the meaning of the \kl{symbol} emerges from the way it can be used in
proofs through \kl{axioms}. In contrast, the usual notion of mathematical
definition we tackle in this chapter might be called \emph{nominal}, because it
essentially amounts to giving a name (the head) to a reoccurring pattern of
statement (the body). Note that the syntax of \kl{first-order logic} is unaware
of this distinction, since in both cases the defined concepts are encoded as
\emph{atomic} predicates. This is usually not the case of logical frameworks
found in \kl{proof assistants}: for instance, the duality between
\emph{judgmental} (nominal) and \emph{propositional} (behavioral) equality is at
the heart of \kl{Martin-LÃ¶f type theory}, and it is used extensively in \kl{Coq} to
perform automation, both in the computation of expressions and the matching of
statements modulo definitions.}. But we can still unfold some definitions in the
context, which might suggest further possible interactions. First we can unfold
the definition of preimage used in $(1)$ by selecting the precise corresponding
subterm:
$$x \in \select{f^{-1}(f(C))} \qquad \text{(\action{Unfold})}$$
which, assuming a definition based on set comprehension, gives:
\begin{itemize}
  \item[(1)] $x \in \compr{a \in A}{f(a) \in f(C)}$
\end{itemize}
At this stage, we would like to make the set comprehension in $(1)$ disappear,
by simply deducing $f(x) \in f(C)$ from it. But depending on the underlying
logical framework, the way to perform this deduction step in \kl{PbA}
will vary:

\begin{description}
  \item[In \kl{ZF} set theory]
    We would need to invoke explicitly the \emph{axiom of comprehension}, which
    states the following:
    $$\forall \phi.\ \forall D.\ \forall y.\ y \in \compr{d \in D}{\phi}
    ~~\lequiv~~ (y \in D \land \subst{\phi}{y}{d})$$ Note that this is again a
    \kl{higher-order} statement, but this time because it quantifies over every
    formula $\phi$\sidenote{Traditionnally, logicians preferred to speak of
    \emph{axiom schemas}, that is countable sets of \kl{axioms}, rather than
    \kl{higher-order} \kl{axioms}, in order to stay purely in a \kl{first-order}
    setting. But this does not make much sense from an implementation point of
    view, as a proof engine will only be able to manipulate a finite amount of
    \kl{axioms}.}. Thus we assume that the underlying proof engine can handle
    such \kl{higher-order} statements, and in particular that the axiom of
    comprehension is available in its database of lemmas.
    
    In \kl{Actema}, one can freely search in this database by typing text in a search
    bar, typically in this case the keyword ``comprehension''. Then the system
    will show a list of lemmas whose names match the keywords, and the user can
    click on the lemma she is interested in, in order to add it as a blue item
    in the current context. An alternative and more precise way of retrieving a
    lemma is to search by \emph{content} of the statement instead of searching
    by name. State-of-the-art \kl{proof assistants} usually provide facilities for
    this: for instance \kl{Coq} has a \texttt{Search} command which can take
    \emph{patterns}, i.e. \kl{terms} with holes or so-called \emph{metavariables}, in
    order to filter out results that do not match the given pattern. In \kl{Actema},
    we implemented a novel feature which replaces patterns by a selection of
    subterms in the current \kl{goal}, similarly to what is given as argument to
    contextual actions like \action{Unfold}. Then the system will only look for
    lemmas which can be used in a \kl{DnD} action involving precisely the current
    selection of subterms. In this case, selecting the full statement of $(1)$
    and searching:
    $$\select{x \in \compr{a \in A}{f(a) \in f(C)}} \qquad
    \text{(\action{Search})}$$
    should return the comprehension axiom among other lemmas, because this axiom
    and $(1)$ can interact through the following \kl(dnd){forward} \kl{DnD}:
    $$\select{x \in \compr{a \in A}{f(a) \in f(C)}} ~~\forw~~ \forall \phi.\
    \forall D.\ \forall y.\ \select{y \in \compr{d \in D}{\phi}} ~~\lequiv~~ (y
    \in D \land \subst{\phi}{y}{d})$$ by substituting $D$ with $A$, $d$ with
    $a$, $y$ with $x$ and $\phi$ with $f(a) \in f(C)$. Performing this \kl{DnD} will
    finally result in a new hypothesis corresponding to the intended unfolding
    of the definition of set comprehension\sidenote{Here in the sense of a
    \emph{behavioral} definition.}:
    \begin{itemize}
      \item[(2)] $x \in A \land f(x) \in f(C)$
    \end{itemize}
  
  \item[In higher-order type theory] In \kl{type theory}, every mathematical
  object or statement is ultimately encoded as a function, in the sense of the
  \kl{$\lambda$-calculus}. It is Alonzo Church who first got the idea of representing
  a set by its \emph{characteristic function} in his \intro{higher-order logic}
  (\reintro{HOL}), as a \kl{$\lambda$-term} of \kl{type} $\iota \to \omicron$ where
  $\iota$ is the \kl{type} of individuals, and $\omicron$ the \kl{type} of
  propositions\todo{add citation}. With this encoding, the only way to construct
  a set is by comprehension, and set membership corresponds to function
  application; that is, $\compr{x \in A}{\phi}$ is identified with the
  characteristic function $\lambda x{:}A.\ \phi$, and $x \in t$ is the
  application $t\ x$\sidenote{Note that this induces a strict hierarchical
  notion of set as in Russell's type theory, where sets containing other sets
  have a \kl{higher-order} \kl{type}, i.e. they correspond to functions taking other
  functions as arguments.}. Then if we consider \kl{$\lambda$-terms} modulo
  $\beta$-equivalence, unfolding the ``definition'' of set comprehension just
  amounts to performing one step of $\beta$-reduction\sidenote{One can consider
  this as a third kind of definition qualified of \emph{computational}. In
  \kl{MLTT}, it is merged with nominal definitions in the concept of judgmental
  equality. In \kl{Coq} they are distinguished: computational and nominal definitions
  correspond respectively to $\beta$-reduction and $\delta$-reduction.}:
  hypothesis $(1)$ becomes
  $$(\lambda a{:}A.\ f(C)\ f(a))\ x$$
  which $\beta$-reduces to
  $$f(C)\ f(x)$$ which we can translate back as $f(x) \in f(C)$. This encoding
  has now found its way in the libraries of many \kl{proof assistants} based on \kl{type
  theory}, and is the one used in the \kl{Coq} solution to the exercise provided in
  annex of \cite{bartzia:hal-04087080}. To perform $\beta$-reduction in \kl{Coq},
  there is a \kl{tactic} called \texttt{simpl} as in ``simplify''\sidenote{There are
  also \texttt{simp} \kl{tactics} available in \kl{Isabelle} and \kl{Lean}, although they are
  not restricted to $\beta$-reduction and can perform rewriting of arbitrary
  equalities and equivalences present in the lemma database, as long as they are
  flagged as simplification rules.}. Coming back to \kl{PbA}, one can
  easily imagine a corresponding \action{Simplify} or \action{Compute}
  contextual action, which performs $\beta$-reduction inside of the selected
  subterm. Then the previous transormation is achieved by applying this action
  on hypothesis $(1)$:
  $$\select{x \in \compr{a \in A}{f(a) \in f(C)}} \qquad \text{(\action{Simplify})}$$
\end{description}
From a user perspective, the two styles of actions induced by the two types of
logical frameworks differ mainly in one aspect: while the definition of set
comprehension is \emph{implicit} in the \kl{type-theoretical} encoding, it must be
manipulated \emph{explicitly} when using the axiom of comprehension\sidenote{In
fact one could also use the axiom of comprehension implicitly by relying on
stronger automation. For example in \kl{Isabelle}/\kl{Isar}, one would write explicitly
the desired \kl{goal} $f(x) \in f(C)$, refer to the \kl{axiom} by its name in the
library, and then let the engine find the details of how to apply it. But
writing statements manually goes against the philosophy of \kl{PbA}, which
explores to what extent proofs can be carried by pure manipulation of the \kl{proof
state}. Of course there is still an escape hatch for doing this when strictly
necessary or more convenient.}. Depending on the user's background and context
of usage, one might prefer one style over the other. Typically in an educational
setting, having to manipulate explicitly the axiomatic definition might be more
instructive, but also more confusing when carrying formal proofs for the first
time.

Going back to the proof, we now have the following context of hypotheses:
\begin{itemize}
  \item[(0)] $\injective(f)$
  \item[(2)] $f(x) \in f(C)$
\end{itemize}
We can unfold the definition of direct image in $(2)$ the same way we did for
the inverse image in $(1)$: first perform the contextual action
$$f(x) \in \select{f(C)} \qquad \text{(\action{Unfold})}$$
which gives us
\begin{itemize}
  \item[(2)] $f(x) \in \compr{b \in B}{\exists a \in A.\ a \in C \land b = f(a)}$
\end{itemize}
Then we can simplify the set comprehension with
$$\select{f(x) \in \compr{b \in B}{\exists a \in A.\ a \in C \land b = f(a)}} \qquad \text{(\action{Simplify})}$$
which gives us
\begin{itemize}
  \item[(3)] $\exists a \in A.\ a \in C \land f(x) = f(a)$
\end{itemize}
Now since $f$ is injective, we should be able to deduce that $x = a$. First we
unfold the definition of injectivity in $(0)$:
$$\select{\injective(f)} \qquad \text{(\action{Unfold})}$$
which gives us
\begin{itemize}
  \item[(0)] $\forall y \in A.\ \forall z \in A.\ f(y) = f(z) \limp y = z$
\end{itemize}
Then we can use injectivity with the following \kl(dnd){forward} \kl{DnD} between $(0)$ and
$(3)$:
$$\forall y \in A.\ \forall z \in A.\ \select{f(y) = f(z)} \limp y = z ~~\forw~~ \exists a \in A.\ a \in C \land \select{f(x) = f(a)}$$
which gives us immediately that $x = a$ in
\begin{itemize}
  \item[(4)] $\exists a \in A.\ a \in C \land x = a$
\end{itemize}
The last steps consist in clicking twice on $(4)$ to introduce $a$ in the
context together with
\begin{itemize}
  \item[(5)] $a \in C \land x = a$
\end{itemize}
doing a \kl(dnd){backward} \kl{DnD} with $(5)$ to rewrite $x$ in the conclusion
into $a$:
$$a \in C \land \select{x} = a ~~\back~~ \select{x} \in C$$ and finally a
\kl(dnd){backward} \kl{DnD} with $(5)$ to conclude the proof:
$$\select{a \in C} \land x = a ~~\back~~ \select{a \in C}$$

For the sake of completeness, we included in \reffig{funset-defs},
\reffig{funset-q1} and \reffig{funset-q2} a \kl{Coq} formalization of the
definitions, solution to the first question, and solution to the second question
of the exercise, respectively. We simply took the data provided in
\cite{bartzia:hal-04087080}, and added corresponding \kl{Actema} actions below \kl{tactic}
invokations, as in the previous section. It is quite close to the graphical proof
just outlined for the second question, hence we do not add further commentary.

\begin{figure}
  \input{listings/funset-defs.tex}
  \caption{Preliminary definitions in \kl{Coq} of an exercise on abstract functions}
  \labfig{funset-defs}
\end{figure}

\begin{figure}
  \input{listings/funset-q1.tex}
  \caption{Solution in \kl{Coq} to the first question of an exercise on abstract functions}
  \labfig{funset-q1}
\end{figure}

\begin{figure}
  \input{listings/funset-q2.tex}
  \caption{Solution in \kl{Coq} to the second question of an exercise on abstract functions}
  \labfig{funset-q2}
\end{figure}


\section{Peano arithmetic}\labsec{arith}

In our last example, we will analyse a common proof often taught in logic
courses: the commutativity of addition in Peano arithmetic. The novelty compared
to previous examples is that it involves reasoning by \emph{induction}, which
usually has special support in mainstream \kl{proof assistants}. In the
\kl{PbA} paradigm, it seems natural to map it to a special contextual
action \action{Induction}, whose availability and effect will depend on the
selected subterm. One could also imagine manipulating explicitly induction
schemes as blue items, in the same way we did for the axiom of comprehension in
the previous section. In this section we focus on describing features of the
more convenient contextual action.

First and foremost, it only makes sense to apply induction to a variable which
is quantified \emph{universally}, either because it appears in the context, or
because it is bound by a $\forall$ in the conclusion. In the first case, one can
access the contextual action in \kl{Actema} by selecting the green item corresponding
to the variable; in the latter case, by selecting the subterm of the conclusion
whose head connective is the binding $\forall$\sidenote{In the standalone
version of \kl{Actema}, induction is performed by clicking directly on green items,
rather than through a contextual action.}. This could also work by selecting any
occurrence of the variable regardless of its binding point, since the system can
always infer it. The only condition is that if the variable is bound by a
$\forall$, it must occur in a \emph{strictly positive} location, i.e. in the
conclusion and not on the left of an implication $\limp$. Obviously the variable
should also be of an \emph{inductive} \kl{type}, i.e. one which is mapped to an
induction scheme in the system\sidenote{The standalone version of \kl{Actema} only
supports induction on natural numbers, but in a \kl{proof assistant} like \kl{Coq} or Lean
one can easily check if a given \kl{type} is inductive.}. Then the \action{Induction}
action will simply apply the associated induction scheme. In our commutativity
example, we can thus start the proof like so:
$$\select{\forall n \in \nats.\ \forall m \in \nats.\ n + m = m + n} \qquad
\text{(\action{Induction})}$$
which performs an induction on $n$, generating the two following \kl{subgoals}:
$$\forall m \in \nats.\ 0 + m = m + 0 \qquad \text{and} \qquad \forall m \in \nats.\ \suc{n} + m = m + \suc{n}$$
where $S(n)$ denotes the successor of $n$, and the second \kl{subgoal} has a new
variable $n \in \nats$ in its context, together with the induction hypothesis
\begin{itemize}
  \item[(1)] $\forall x \in \nats.\ n + x = x + n$
\end{itemize}
The proofs of the two \kl{subgoals} can be done by induction on $m$. We focus on the
second one, which is a bit more involved. As mentioned above, an alternative way
of performing induction is to first introduce $m$ in the context by clicking on
the conclusion, and then selecting it to access the contextual action:
$$\select{m \in \nats} \qquad \text{(\action{Induction})}$$
which generates again two new \kl{subgoals}:
$$S(n) + 0 = 0 + S(n) \qquad \text{and} \qquad S(n) + S(m) = S(m) + S(n)$$ where
the second \kl{subgoal} has a new variable $m \in \nats$ in its context, together
with the induction hypothesis
\begin{itemize}
  \item[(2)] $S(n) + m = m + S(n)$
\end{itemize}
Let us now focus on the first \kl{subgoal}. Once again, as with set comprehension in
the previous section, the addition operation may have a more \emph{axiomatic} or
more \emph{computational} definition, depending on the underlying logical
framework and library used. For instance in \kl{Coq}'s standard library, it is
implemented as a \emph{program} built by recursion on the left-hand argument.
Thus in this setting, if one performs computation in the whole conclusion like
so:
$$\select{S(n) + 0 = 0 + S(n)} \qquad \text{(\action{Simplify})}$$
this will give a new conclusion
$$S(n + 0) = S(n)$$
where the addition program was able to automatically evaluate $S(n) + 0$ to $S(n
+ 0)$ on the left-hand side of the equality, and $0 + S(n)$ to $S(n)$ on the
right-hand side. If the proof engine does not offer such a level of automation,
one can always fallback to using Peano axioms manually, provided they are
available in the lemma database. As we have already seen, the most convenient
way to do this in the \kl{PbA} paradigm is to perform a \action{Search}
action. For example to evaluate $S(n) + 0$, one might first select it in the
conclusion and then make a search query:
$$\select{S(n) + 0} = 0 + S(n) \qquad \text{(\action{Search})}$$
Among the results which are Peano axioms, one will only find the following
ones:
\begin{itemize}
  \item[(a)] $\forall x.\ 0 \not= S(x)$
  \item[(b)] $\forall x.\ \forall y.\ S(x) = S(y) \limp x = y$
  \item[(c)] $\forall x.\ \forall y.\ S(x) + y = S(x + y)$
\end{itemize}
because the other \kl{axioms} do not contain any subterm that could form a
\kl(dnd){valid} \kl(dnd){backward} \kl{linkage} with the selection\sidenote{See
\refsec{validity} for the notion of \kl[valid@dnd]{validity} of a \kl{linkage}.}. Of
course we are interested in \kl{axiom} $(c)$, which we can use through the following
\kl(dnd){backward} \kl{DnD}:
$$\forall x.\ \forall y.\ \select{S(x) + y} = S(x + y) ~~\back~~ \select{S(n) + 0} = 0 + S(n)$$
in order to rewrite $S(n) + 0$ into $S(n + 0)$ in the conclusion.

Now notice that the addition program earlier was not able to evaluate $n + 0$ to
$n$. This is because $0$ occurs on the right-hand side of $+$, and the program
is not aware of the commutativity of addition, which is precisely what we are
trying to prove. Fortunately, we can apply our induction hypothesis on $n$
$(1)$, with the following \kl(dnd){backward} \kl{DnD}:
$$\forall x \in \nats.\ \select{n + x} = x + n ~~\back~~ S(\select{n + 0}) = S(n)$$
which rewrites $n + 0$ into $0 + n$ in the conclusion:
$$S(0 + n) = S(n)$$
Now we can continue the computation:
$$S(\select{0 + n}) = S(n) \qquad \text{(\action{Simplify})}$$
and conclude the base case of the induction on $m$ by reflexivity, by clicking
on the conclusion $S(n) = S(n)$.

The inductive case of the induction on $m$ works similarly, but obviously we
will also need to use the induction hypothesis on $m$ $(2)$. First we compute
everywhere we can in the conclusion:
$$\select{S(n) + S(m) = S(m) + S(n)} \qquad \text{\action{Simplify}}$$
% which gives the new conclusion
% $$\select{S(n + S(m)) = S(m + S(n))} \qquad \text{\action{Simplify}}$$
Then we can apply the induction hypothesis on $n$ $(1)$:
$$\forall x.\ \select{n + x} = x + n ~~\back~~ S(\select{n + S(m)}) = S(m + S(n))$$
and also the induction hypothesis on $m$ $(2)$:
$$S(n) + m = \select{m + S(n)} ~~\back~~ S(S(m) + n) = S(\select{m + S(n)})$$
Again we compute everywhere:
$$\select{S(S(m) + n) = S(S(n) + m)} \qquad \text{(\action{Simplify})}$$
apply the induction hypothesis on $n$ $(1)$ once again:
$$\forall x.\ n + x = \select{x + n} ~~\back~~ S(S(\select{m + n})) = S(S(n + m))$$
and conclude by reflexivity on $S(S(n + m)) = S(S(n + m))$.

\begin{figure}
  \input{listings/coq-peano.tex}
  \caption{Proof of commutativity of addition on natural numbers in \kl{Coq}}
  \labfig{coq-peano}
\end{figure}

As in previous sections, the interested reader can find a complete Coq
formalization in \reffig{coq-peano}, which follows the same structure as the
graphical proof just outlined. In this case the correspondence between Coq
\kl{tactics} and graphical actions is almost exact. This suggests that designing a
compiler from proofs-by-action to \kl{Coq} \kl{proof scripts} might be a reasonable
endeavor. It will indeed be one of the subjects of \refch{plugin}.