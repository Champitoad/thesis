\setchapterpreamble[u]{\margintoc}
\chapter{Parallel Conclusions and Classical Logic}
\labch{sfl-classical}

In virtually every proof assistant, the goals the user is faced with are
sequents of the form $\Gamma \seq C$, with a \emph{single} conclusion $C$ to be
proved under many hypotheses in $\Gamma$. Historically, this form of sequent was
introduced by Gentzen to formalize the rules of intuitionistic logic in his
sequent calculus \kl{LJ}. But his main interest was in classical logic, as
intuitionistic logic was still in its infancy and almost all of mathematics had
been developed in a classical setting. Interestingly, he found that the right
syntax to develop a rich metatheory of his classical sequent calculus \kl{LK}
consisted in \emph{multi-conclusion} sequents of the form $\Gamma \seq \Delta$,
where $\Delta$ is a list of conclusions that should be read
\emph{disjunctively}. That is, a sequent
$$A_1, \ldots, A_n \seq C_1, \ldots, C_m$$
has the same meaning as the formula
$$\bigwedge_{i=1}^{n}{A_i} \limp \bigvee_{j=1}^{m}{C_j}$$

\begin{marginfigure}
  \begin{mathpar}
    \R[\lor R]
      {\Gamma \seq A, B, \Delta}
      {\Gamma \seq A \lor B, \Delta}
  \end{mathpar}
  \caption{Multiplicative right introduction rule for disjunction}
  \labfig{multintro}
\end{marginfigure}

\begin{marginfigure}
  \begin{mathpar}
    \R[\lor R]
      {\R[{\limp} R]
        {\R[ax]
          {}
          {A \seq \select{A}, \bot}}
        {\seq A, \select{\neg A}}}
      {\seq \select{A \lor \neg A}}
  \end{mathpar}
  \caption{Proof of the excluded middle in \kl{LK}}
  \labfig{lk-tnd}
\end{marginfigure}

One way to get a multi-conclusion sequent in \kl{LK} is to apply the
``multiplicative''\sidenote{Terminology borrowed from linear logic, where
{\rnm{\lor R}} is exactly the right introduction rule for multiplicative
disjunction $\parr$.} introduction rule {\rnm{\lor R}} (\reffig{multintro}). For
instance, \reffig{lk-tnd} shows a proof of the law of excluded middle, where for
each rule we squared the principal formula.
% Following the mapping of click actions to sequent calculus rules
% (\reftab{click-rules}),
One could imagine performing the same proof in Actema by successively clicking
on these principal formulas, following a bottom-up reading of the sequent
calculus derivation seen as the trace of a proof search process. First we decide
to prove $A \lor \neg A$: this amounts to proving alternatively $A$ or $\neg
A$, which now appear as two separate red items in the same tab. Then we try to
prove $\neg A$, with the usual method of supposing $A$ to find a contradiction.
However instead of a contradiction, we decide to backtrack and prove the
alternative conclusion $A$, which is now trivial by assumption. We come back to
these multi-conclusion click actions in \refsec{classical-click}.

It is clear in the proof that the negative occurrence of $A$ in $\neg A$ is the
one that becomes the assumption $A$ that justifies the conclusion $A$ in the
last step. It would be natural to specify this causal relationship by linking
directly the two occurrences of $A$, as we do with DnD actions in Actema.
However for this to be possible, we need to introduce a new linking operator ---
let us note it $\para$ --- that works between two conclusions, where $A \para B$
is obviously interpreted as $A \lor B$. Then after clicking on $A \lor \neg A$
we can just finish the proof by connecting $A$ and $\neg A$:
$$\select{A} \para \neg \select{A} ~~\steps{}~~ \top$$

This would avoid the additional step of clicking on $\neg A$ to turn it into an
hypothesis, and suggests the possibility of a more general behavior
associated to this $\para$ operator for arbitrary logical connectives. This is
what we explore in \refsec{classical-dnd}.

\section{Backtracking}\labsec{sfl-backtracking}

% \begin{marginfigure}
%   \begin{mathpar}
%     \R[raa]
%       {\Gamma, \neg A \seq \bot}
%       {\Gamma \seq A}
%   \end{mathpar}
%   \caption{Rule of \textit{reductio ad absurdum}}
%   \labfig{raa}
% \end{marginfigure}

Interestingly, the classical aspect of the proof of $A \lor \neg A$ in
\reffig{lk-tnd} comes exclusively from the \emph{backtracking} operation during
the last step, a phenomemon which is well known in the literature on
constructive/computational properties of classical logic\todo{add references}.
Then one can see the introduction rules {\rnm{\lor R_1}} and {\rnm{\lor R_2}},
and the restriction of intuitionistic sequents to one conclusion, as ways to
prevent such backtracking by forcing the choice of disjunct to prove at an early
stage.
% \sidenote{Although the ability to backtrack can be reintroduced in other
% ways, for example with the rule of \textit{reductio ad absurdum} (\reffig{raa})
% (TODO: add reference).}.

In fact backtracking can still be performed in intuitionistic logic, but at the
meta-level of the proof search process instead of the object-level of inference
rules. In an interactive theorem prover, this corresponds to the ability for the
user to \emph{undo} an inference and go back to a previous proof state. However
keeping track of the times we undo/redo inferences is very hard to do as humans,
and the user interfaces of current proof assistants do not provide any mechanism
for it either. This has already been noted by Ayers\sidenote{Section 3.1.3 of
his thesis \cite{ayers_thesis}.}, and is a good motivation for trying to design
proof systems where the need for meta-level backtracking is reduced, or even
removed. One way to do this is to maximize the proportion of inference rules
that are \emph{invertible}, meaning that their premisses always follow from
their conclusion. Indeed when looking at rules as tactics (see \refsec{itps}),
it means that they will always reduce a provable goal to provable subgoals, and
thus can never induce a backtracking point\sidenote{Except of course if the user
deems the subgoal too complex to prove in its current form, and explicitly wants
to backtrack to shape it differently.}. The {\rnm{\lor R}} rule is an example of
invertible rule, and in \kl{LK} it can replace the other, non-invertible rules
{\rnm{\lor R_1}} and {\rnm{\lor R_2}}.

But {\rnm{\lor R}} requires multi-conclusion sequents, and Gentzen restricted
their use to classical logic. It turns out that logicians after Gentzen have
proposed various multi-conclusion sequent calculi that work for intuitionistic
logic, the most famous being \kl{GHCP} from Dragalin
\sidecite{dragalin_mathematical_1990}, which uses {\rnm{\lor R}}. In the rest of
this chapter, we will consider to what extent one can benefit from having
multiple conclusions in an intuitionistic setting.

\section{Implementation in theorem provers}

Despite the aforementioned benefits of multi-conclusion sequents, we do not know
of any proof assistant, whether classical or intuitionistic, that exposes them
in its user interface. One reason is that most proof/tactic languages are based
on the rules of natural deduction, which use single-conclusion sequents. Another
reason is that having one conclusion removes the need to designate it with an
explicit name or number, as is the case with hypotheses\sidenote{The current
trend is to have user-chosen or automatically generated strings for names as in
Coq and Lean, but some provers like HOL Light ask for the position in the list
as an integer to designate a particular hypothesis.}. And the explicit handling
of names in tactic invokations is known to be tedious and time-consuming, to the
point that some tactic languages like \ssreflect have been designed around this
problem \sidecite{SSR}. Thus having multiple conclusions would only double the
effort for no compelling reason.

However in our graphical paradigm based on direct manipulation, hypotheses and
conclusions are designated by the act of \emph{pointing} at them with a mouse,
finger or any other pointing device\sidenote{With the recent advances in natural
language processing and voice recognition, one could also imagine a system based
on the selection of subterms by spelling their content. Then click and DnD
actions could be triggered by voice commands once the subterms they apply to
have been selected. This could be an important alternative for users with
impaired vision and/or motricity.}. This opens up the possibility of exposing
multiple conclusions in the interface with associated graphical proof actions,
as outlined in the introductory example on the excluded middle. While we did not
implement such an extension, we explore in the following sections its design,
and the theoretical foundations behind it.

\section{Click actions}\labsec{classical-click}

In \reftab{click-rules}, we showed how click actions in Actema are in direct
correspondance with the rules of the single-conclusion sequent calculus \kl{LJ}
for intuitionistic logic. Following the literature mentioned earlier, we just
need to replace two actions/introduction rules to get a multi-conclusion system
capturing either intuitionistic or classical first-order logic:

\begin{marginfigure}
  \begin{mathpar}
    \R[{\limp}R*c]
      {\Gamma, A \seq B, \Delta}
      {\Gamma \seq A \limp B, \Delta}
    \and
    \R[{\limp}R*i]
      {\Gamma, A \seq B}
      {\Gamma \seq A \limp B, \Delta}
  \end{mathpar}
  \caption{Multi-conclusion right introduction rules for implication}
  \labfig{multi-imp-intro}
\end{marginfigure}

\begin{itemize}
  \item clicking on a red disjunction $A \lor B$ breaks it into two conclusions
  $A$ and $B$. This is the dual behavior to click actions on blue conjunctions,
  and corresponds to the {\rsf{\lor R}} rule of \reffig{multintro}, which is
  common to both the intuitionistic and classical variants;
  \item as before, clicking on a red implication $A \limp B$ breaks it into an
  hypothesis $A$ and a conclusion $B$. Without further changes, this corresponds
  to the right introduction rule from the classical sequent calculus \kl{LK} of
  Gentzen (named {\rsf{{\limp}R*c}} in \reffig{multi-imp-intro}), and
  our set of actions becomes a proof system for classical logic. To go back to
  intuitionistic logic, one needs the additional behavior that all the other
  conclusions of the goal are removed. This corresponds to the right
  introduction rule from the \kl{GHCP} calculus of Dragalin (named
  {\rsf{{\limp}R*i}} in \reffig{multi-imp-intro}).
\end{itemize}

\begin{remark}
  In the special case of intuitionistic sequents with one conclusion, the two
  variants {\rsf{{\limp}R*c}} and {\rsf{{\limp}R*i}} collapse into the usual
  {\rsf{{\limp}R}} rule.
\end{remark}
Note that we only modified the behavior of the disjunction $\lor$ and
implication $\limp$ connectives; and for the latter, only in the case when there
are at least two parallel conclusions, and thus implicitly a disjunction. Then
it is interesting to notice that the classical behavior of the other connectives
($\bot, \land, \forall, \exists$) essentially arises from their interaction with
(positive) disjunctive statements.

If we stick to intuitionistic logic, the benefits of having multiple conclusions
are unclear. Indeed while the {\rsf{\lor R}} rule is invertible, the
{\rsf{{\limp}R*i}} rule is not, and thus at some point the choice of which
conclusion to prove must be made by the user irreversibly, even if the choice is
delayed\sidenote{In \refsec{colors}, we will see how to overcome this limitation
by using a \emph{nested sequent} system.}. On the other hand the
{\rsf{{\limp}R*c}} rule \emph{is} invertible: this is known to allow the
formulation of sequent calculi for classical logic where \emph{all} rules are
invertible, like the \kl{G3c} calculus of \sidecite{negri_structural_2001}. In
the propositional case, this gives a constructive decision procedure for the
question of provability: given a sequent $\Gamma \seq \Delta$, one just has to
choose any formula in $\Gamma$ or $\Delta$ and apply the introduction rule
associated to its main connective, or the axiom rule whenever possible. In
Actema, this would correspond to having the user click randomly on blue and red
items until all goals are solved. The procedure ends because all introduction
rules destroy the main connective, and none of them duplicate formulas: thus the
total size of the sequent decreases strictly after each rule application.

\begin{marginfigure}
  \begin{mathpar}
    \R[\forall L*]
      {\Gamma, \forall x. A, \subst{A}{t}{x} \seq \Delta}
      {\Gamma, \forall x. A \seq \Delta}
    \and
    \R[\exists R*]
      {\Gamma \seq \subst{A}{t}{x}, \exists x. A, \Delta}
      {\Gamma \seq \exists x. A, \Delta}
  \end{mathpar}
  \caption{Multi-conclusion instantiation rules for quantifiers}
  \labfig{multi-inst}
\end{marginfigure}

When dealing with quantifiers, the situation is not so simple: if one wants
invertible introduction rules, it is necessary to duplicate the quantified
formula being instantiated, which can be seen as the root cause of
undecidability in predicate logic as noted by
Girard\cite[Section~3.3.2]{girard:hal-01322183}. This is already what happens in
Actema for the universal quantifier: dropping a term $t$ on a blue item $\forall
x. A$ will produce a new hypothesis $\subst{A}{t}{x}$, while keeping the
original $\forall x. A$ item. This corresponds to the invertible left
introduction rule of \kl{G3c} ({\rsf{\forall L*}} in \reffig{multi-inst}).
But in the single-conclusion framework, dropping a term $t$ on a red item
$\exists x. A$ necessarily replaces it by the instantiated conclusion
$\subst{A}{t}{x}$. Allowing multiple conclusions circumvents this problem and
restores the symmetry between $\forall$ and $\exists$, since we can create a new
conclusion for $\subst{A}{t}{x}$ while preserving the old one. This corresponds
to the invertible right introduction rule of \kl{G3c} ({\rsf{\exists R*}} in
\reffig{multi-inst}).

\section{DnD actions}\labsec{classical-dnd}

Once we allow for more than one conclusion, it is natural to wonder whether it
makes sense to also allow for DnD actions between two conclusions. But we
already capture \emph{backward} reasoning with the $A \back B$ operator between
a hypothesis $A$ and a conclusion $B$, and \emph{forward} reasoning with the $A
\forw B$ operator between two hypotheses. There does not seem to be room for a
third mode of reasoning, at least in the traditional way of building proofs we
are used to, either on paper or with proof assistants. However from a purely
formal point of view, there is nothing preventing us from trying to design
rewrite rules for a new linking operator, by following the same recipe we used
for $\back$ and $\forw$. Furthermore, we already saw earlier in the excluded
middle example that such an operator did seem useful.

When looking for a proof of a sequent with multiple conclusions, unless we
commit to proving one conclusion and give up on the others by applying the
{\rsf{{\limp}R*i}} rule, we can switch freely our focus between the different
conclusions. Thus in a way, we are looking for proofs of all the conclusions
\emph{in parallel}, and we stop as soon as we find one\sidenote{This is also
related to the $\parr$ connective of linear logic which uses the {\rsf{\lor
R}} rule of \reffig{multintro}, and whose spelling ``par'' is historically
motivated by an understanding of the multiplicative fragment of \kl{LL} as a
logic of parallel computation \cite{girard-linear-1987}.}. Hence we chose to
call this third kind of interaction between two conclusions \emph{parallel}
reasoning. This justifies the choice of notation for the parallel linking
operator $\para$, which is suggestive of the parallel composition $\mid$ from
process calculi.

The rules governing $\para$ are presented in \reffig{parallel}. A parallel
linkage can be created either by drag-and-dropping two conclusions together, or
through an instance of the new backward rule {\rsf{L{\limp}_1}}. It is
important to note that this rule is only sound \emph{classically}; indeed we can
now come back to the example of \refsubsec{polarity} and give the following
derivation of Peirce's law with it:

$$
\begin{array}{llll}
  (\select{A} \limp B) \limp A \back \select{A}
  &\step{}& (\select{A} \limp B \para \select{A}) \land (A \limp A) &\mathsf{L{\limp}_1} \\
  &\step{}& ((\select{A} \back \select{A}) \lor B) \land (A \limp A) &\mathsf{P{\limp}_1} \\
  &\step{}& (\top \lor B) \land (A \limp A) &\mathsf{id} \\
  &\step{}& \top \land (A \limp A) &\mathsf{absl} \\
  &\step{}& A \limp A &\mathsf{neul}
\end{array}
$$

\begin{marginfigure}
  \fontsize{9}{9.5}\selectfont
    \renewcommand{\arraystretch}{1.25}
  \begin{mathpar}
    \begin{array}{r@{\,}c@{\,}lr}
      \multicolumn{4}{c}{\textsc{Backward}} \\[2em]
      {B \limp C \back A}   &\step{}&   {(B \para A) \land (C \limp A)} &\mathsf{L{\limp}_1} \\[2em]
    \end{array}
    \\
    \begin{array}{r@{\,}c@{\,}lr}
      \multicolumn{4}{c}{\textsc{Parallel}} \\[2em]
      % \R[\mathsf{lnn}]
      %   {\ifill{\eta}{\efill{A}{A} \ast \efill{B}{B}}}
      %   {\ifill{\eta}{\ifill{A}{A} \land \ifill{B}{B}}}
      % \\
      {A \para (B \land C)}   &\step{}&   {(A \para B) \land C}   &\mathsf{P\land_1}\\
      {A \para (C \land B)}   &\step{}&   {C \land (A \para B)}   &\mathsf{P\land_2}\\[1em]

      {A \para (B \lor C)}   &\step{}&   {A \para B}   &\mathsf{P\lor_1}\\
      {A \para (C \lor B)}   &\step{}&   {A \para B}   &\mathsf{P\lor_2}\\[1em]

      {A \para (B \limp C)}   &\step{}&    {(B \back A) \lor C}   &\mathsf{P\!\!\limp_1}\rever\\
      {A \para (C \limp B)}   &\step{}&    {C \limp (A \para B)}   &\mathsf{P\!\!\limp_2}\rever\\[1em]

      % {A \para \neg B}   &\step{}&   {B \back A}   &\mathsf{P\neg}\rever\\[1em]

      {A \para (\forall x. B)}   &\step{}&{\forall x. (A \para B)}   &\mathsf{P\forall s}\rever\\[1em]

      {A \para (\exists x. B)}   &\step{}&   {A \para \subst{B}{x}{t}}   &\mathsf{P\exists i}\\
      {A \para (\exists x. B)}   &\step{}&   {\exists x. (A \para B)}   &\mathsf{P\exists s}\rever\\[1em]
            
      {B \para A}   &\step{}&   {A \para B}   &\mathsf{Pcomm}\\
    \end{array}
  \end{mathpar}
  ~\\[1em]
  In the rules $\{\mathsf{P \forall s}, \mathsf{P \exists s}\}$, $x$ is not free
  in $A$.
  ~\\[1em]
  \caption{Parallel linking rules}
  \labfig{parallel}
\end{marginfigure}

\begin{marginfigure}
  \begin{center}
  % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRADEQBfU9TXfIRQAmclVqMWbAArdeIDNjwEiARjHV6zVohAAhbuJhQA5vCKgAZgCcIAWyRkQOCElEgARjDBQkAZicGOi8GaX5lIRAGGEscEE1JHQ5AYKJVOStbB0R3FyR1T29fRACE7TYAGVT0kBt7POpc7OovH38nLSldaSqeDLqm51dEJxaikoky3QAlHoouIA
  \tikzset{/tikz/commutative diagrams/labels={outer sep=4pt}}
  \begin{tikzcd}[ampersand replacement=\&]
    \large
    \forw \arrow[r, "\mathsf{F{\limp}_1}", bend left] \&
    \back \arrow[r, "\mathsf{L{\limp}_1}", bend left] \arrow[l, "\mathsf{R{\limp}_1}", bend left] \&
    \para \arrow[l, "\mathsf{P{\limp}_1}", bend left]
  \end{tikzcd}
  \end{center}
  \caption{Alternating structure between reasoning modes}
  \labfig{modes-schema}
\end{marginfigure}

The other rules of \reffig{parallel} handle the rewriting of parallel linkages,
and were conceived as the dual counterpart of forward rules. Indeed, while a
forward linkage combines two negative subformulas in the same context to produce
a new \emph{hypothesis}, a parallel linkage combines two positive subformulas in
the same context to produce a new \emph{conclusion}. Backward linkages can then
be seen as mediating between these two opposite modes of reasoning, by handling
the interaction of a positive and a negative subformula in the same context. A
schematic view of the back and forth between the different modes through the 4
rewriting rules that change linking operators is provided in
\reffig{modes-schema}. Notice that the latter correspond exactly to the rules
that handle interaction with the antecedant of an implication: this is because
it is the only way to switch polarity when descending into a direct subformula,
which is what triggers the change of mode.

\section{Metatheory of parallel reasoning}

Like backward rules, a parallel rule $A \step{} B$ will be logically sound if $B$
entails $A$. Then if one wants to stick to an intuitionistic setting, one has to
remove the rules {\rsf{P{\limp}_1}}, {\rsf{P{\limp}_2}} and {\rsf{P\forall
s}} from the system, in addition to the {\rsf{L{\limp}_1}} rule. Indeed those
are all sound classically but not intuitionistically\sidenote{We do not prove
this formally here, but this can be done by exhibiting intuitionistic
counter-models in which the entailments are false, i.e. Kripke structures or
Heyting algebras.}.

Now if we look back at the schema from \reffig{modes-schema}, removing
{\rsf{L{\limp}_1}} and {\rsf{P{\limp}_1}} in particular has the consequence
of isolating completely parallel reasoning from the other modes. But remember
from \refsec{action} that we are only interested in \emph{valid} linkages, that
is those linkages who satisfy productivity (\refthm{productivity}) and thus will
always terminate on an instance of either the {\rsf{id}} rule (backward mode)
or the equality rules (backward/forward modes). Thus if there is no way to reach
either forward or backward mode from a parallel linkage, it has no meaning in
our paradigm. Then if we trust that rules {\rsf{L{\limp}_1}} and
{\rsf{P{\limp}_1}} are necessary to get the intended semantics, it seems that
parallel reasoning only makes sense in a classical setting. In the following, we
only show that the rules of \reffig{parallel} are sufficient for our purpose, by
extending the results of \refch{sfl} to the classical, multi-conclusion setting.

We start by updating the validity criterion on linkages, more specifically we
drop Clause \ref{clause:intuit} of Condition \ref{cond:pol} about the polarities
of linked subformulas. Indeed it was introduced precisely to forbid behaviors
which only make sense in classical logic, but are now given a semantics with the
{\rsf{L{\limp}_1}} rule. We also need to add a case for the $\para$ operator
in the other clauses of Condition \ref{cond:pol}, which gives the following
updated condition:

\begin{condition}[Classical Polarity]\label{cond:pol-classical}
  
  The following must be true for a logical linkage $B\select{A}\link
  D\select{A'}$ to be \emph{classically valid}:
  \begin{enumerate}
    \item the parity of $\inv(B\hole)$ is:
      \begin{enumerate}
        \item the same as $\inv(D\hole)$ if $\link = \back$
        \item the opposite of $\inv(D\hole)$ if $\link = \forw$
        \item the opposite of $\inv(D\hole)$ if $\link = \para$
      \end{enumerate}\label{clause:opposite}
  \end{enumerate}

  The following must be true for a rewrite linkage $B\select{t} @ D\select{t'}$
  to be \emph{classically valid}:
  \begin{enumerate}
    \item if $B\hole$ holds the equality, then it must be:
      \begin{enumerate}
        \item positive if $\link = \back$;
        \item positive if $\link = \forw$;
        \item negative if $\link = \para$;
      \end{enumerate}
    \item if $D\hole$ holds the equality, then it must be:
      \begin{enumerate} 
        \item negative if $\link = \back$;
        \item positive if $\link = \forw$.
        \item negative if $\link = \para$.
      \end{enumerate}
  \end{enumerate}
\end{condition}

Then we add the following case to the statement of Theorem \ref{prop:soundness}:
  $$\text{If $A \para B \steps{} C$, then $C \seq A, B$.}$$
and we interpret $\para$ as disjunction:
  $$\lint{A \para B} = \lint{A} \lor \lint{B}$$
We add the two following cases to Lemmas \ref{lemma:rules-valid-in-context} and
\ref{lemma:rewriting-valid-in-context}:
\begin{itemize}
  \item If $C^+\select{A\para B}\step{} D$ then $\lint{D} \seq C^+\select{A\lor B}$.
  \item If $C^-\select{A\para B}\step{} D$ then $C^-\select{A\lor B}\seq \lint{D}$.
\end{itemize}
The proof of Lemma \ref{lemma:rules-valid-in-context} is easily extended by
inspecting each parallel rule, and we already mentioned that the backward rule
{\rsf{L{\limp}_1}} is sound classically. Note that now sequents have multiple
conclusions, thus one needs to use rules from a multi-succedant calculus such as
\kl{G3c} \cite{negri_structural_2001}.

Polarity preservation (Fact \ref{prop:rules-preserve-polarity}) is also true
with $\para$, we just need to add the missing cases from \reffig{modes-schema}:
\begin{itemize}
  \item If $C\select{A \para B} \step{} C'\select{A' \para B'}$ then $C\hole$ and
  $C'\hole$ have the same polarity.
  \item If $C\select{A \back B} \step{} C'\select{A' \para B'}$ (resp. $C\select{A
  \para B} \step{} C'\select{A' \back B'}$) then $C\hole$ and $C'\hole$ have the
  same polarity.
\end{itemize}
The proof of Lemma \ref{lemma:rewriting-valid-in-context} is also extended
straightforwardly. We only write the added case for $\para$ in the proof of the
first statement:
\begin{itemize}
  \item $\link = \para$: by Fact \ref{prop:rules-preserve-polarity}, $C'$ must
  be positive. Therefore by induction hypothesis $\lint{D} \seq C'\select{A'
  \lor B'}$. By Lemma \ref{lemma:rules-valid-in-context} we have
  $C'\select{A' \lor B'} \seq C^+\select{A \limp B}$. Thus by transitivity
  $\lint{D} \seq C^+\select{A \limp B}$.
\end{itemize}

Regarding completeness (\refthm{sfl-completeness}), we already noticed that our
rules now allow us to prove Peirce's law, which is known to be sufficient to
recover classical logic from intuitionistic logic.

The proof of productivity (\refthm{productivity}) is again extended
straightforwardedly, by considering the additional case of parallel linkages and
using arguments ``dual'' to those used for forward linkages. There is even less
work to do regarding the preservation of Condition \ref{cond:pol} since we
dropped the intuitionistic restriction.

Finally about focusing (\refsec{invert}), we can just remark that some rules
that were not invertible in intuitionistic logic become invertible in classical
logic. Therefore the dynamics of focusing should be different, and it might be
interesting to compare the behaviors of intuitionistic and classical DnD actions
on specific examples.